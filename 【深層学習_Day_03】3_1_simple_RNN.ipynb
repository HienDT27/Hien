{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "【深層学習  Day 03】3_1_simple_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HienDT27/Rabbit-Challenge/blob/master/%E3%80%90%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92_Day_03%E3%80%913_1_simple_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cNl2QA_Rnv5",
        "colab_type": "text"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkwjN1jNVAYy",
        "colab_type": "text"
      },
      "source": [
        "## Googleドライブのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvFXpiH3EVC1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "001ddaa6-ccd8-4a64-e258-c88d44241e04"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ub7RYdeY6pK",
        "colab_type": "text"
      },
      "source": [
        "## sys.pathの設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oql7L19rEsWi",
        "colab_type": "text"
      },
      "source": [
        "以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ic2JzkvFX59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/【E資格】深層学習/DNN_code')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feXB1SiLP4OL",
        "colab_type": "text"
      },
      "source": [
        "# simple RNN\n",
        "### バイナリ加算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tzSWNYwxP4OM",
        "colab_type": "code",
        "outputId": "24216bb4-8f61-46c0-be1f-7db7e5813998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "\n",
        "\n",
        "# He\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "\n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:0.6926974497169389\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "40 + 88 = 1\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.8303804710865027\n",
            "Pred:[0 0 0 0 0 1 0 1]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "96 + 101 = 5\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.0539011589855714\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "71 + 109 = 255\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.0572075513394068\n",
            "Pred:[1 1 0 1 1 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "63 + 37 = 221\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.03568114422637\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "64 + 97 = 255\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.0560213605204987\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "48 + 85 = 255\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.0078346589279439\n",
            "Pred:[1 1 1 0 1 1 1 0]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "81 + 50 = 238\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.1261973312128049\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "92 + 24 = 0\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.9174317860491588\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "50 + 3 = 127\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.9118659869303365\n",
            "Pred:[0 0 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "82 + 21 = 37\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.8202454288056106\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "16 + 116 = 0\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.8932834426333262\n",
            "Pred:[0 0 0 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "83 + 16 = 7\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.8299381161244994\n",
            "Pred:[0 1 0 0 1 1 1 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "1 + 74 = 79\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.8216657274418389\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "60 + 66 = 254\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.8672214039666641\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 1 1 0 0]\n",
            "69 + 119 = 255\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.6840692366411345\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 0 0 1 0 1 1]\n",
            "8 + 3 = 0\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.8804990550536016\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "69 + 116 = 255\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.8599334186471955\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "98 + 111 = 223\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.6853076006215179\n",
            "Pred:[0 1 0 1 0 1 0 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "74 + 11 = 85\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.9839005022761868\n",
            "Pred:[0 0 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 0 0 0]\n",
            "71 + 1 = 14\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.8074966628830286\n",
            "Pred:[1 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "91 + 28 = 247\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.9514979143444415\n",
            "Pred:[1 1 1 1 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "72 + 63 = 247\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.6264688843072087\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "62 + 0 = 126\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.6589149167067136\n",
            "Pred:[0 0 1 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "16 + 62 = 46\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.5377268926043628\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "111 + 8 = 119\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.8784129130138847\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 1 0 1 0 1 1 0]\n",
            "95 + 119 = 158\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.6607260475713403\n",
            "Pred:[1 1 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "122 + 48 = 234\n",
            "------------\n",
            "iters:2700\n",
            "Loss:1.3817415196058587\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 1 0 0 0 0 1 0]\n",
            "127 + 67 = 190\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.4210133391123694\n",
            "Pred:[0 1 1 0 1 1 0 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "83 + 26 = 109\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.6288558285142639\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "26 + 79 = 125\n",
            "------------\n",
            "iters:3000\n",
            "Loss:1.050509777240066\n",
            "Pred:[0 0 1 1 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "55 + 78 = 53\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.9091870819210454\n",
            "Pred:[1 0 1 0 1 1 1 0]\n",
            "True:[1 0 1 1 1 1 1 1]\n",
            "111 + 80 = 174\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.5150982312882258\n",
            "Pred:[1 1 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "82 + 55 = 201\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.20919317589641\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "3 + 110 = 113\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.541418485536564\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 0 0 0 0]\n",
            "44 + 4 = 56\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.5118659098455767\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "12 + 52 = 72\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.6131720413366434\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "125 + 47 = 252\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.46409572229595664\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "93 + 5 = 122\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.3276863765809724\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "60 + 13 = 105\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.3203921670559254\n",
            "Pred:[1 1 0 1 1 1 0 1]\n",
            "True:[1 1 0 1 1 1 0 1]\n",
            "127 + 94 = 221\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.3402056020222065\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "71 + 81 = 158\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.3584652252423379\n",
            "Pred:[1 1 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "94 + 39 = 197\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.1317735197005404\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "82 + 31 = 113\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.13211622268434425\n",
            "Pred:[0 0 0 1 1 1 0 1]\n",
            "True:[0 0 0 1 1 1 0 1]\n",
            "17 + 12 = 29\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.2562582239129508\n",
            "Pred:[1 0 1 0 0 1 0 1]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "119 + 46 = 165\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.13676464328151203\n",
            "Pred:[0 1 0 0 0 0 0 1]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "22 + 43 = 65\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.04829802349360923\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "4 + 125 = 129\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.24355527290816165\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "57 + 23 = 80\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.04113975640277276\n",
            "Pred:[1 0 1 0 0 1 1 1]\n",
            "True:[1 0 1 0 0 1 1 1]\n",
            "48 + 119 = 167\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.042261438203690715\n",
            "Pred:[0 0 1 1 1 1 0 0]\n",
            "True:[0 0 1 1 1 1 0 0]\n",
            "6 + 54 = 60\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.04417106355959942\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "42 + 124 = 166\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.043429541611831914\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "16 + 60 = 76\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.039101031192417986\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "82 + 84 = 166\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.12432538899352913\n",
            "Pred:[0 1 0 0 0 0 1 1]\n",
            "True:[0 1 0 0 0 0 1 1]\n",
            "31 + 36 = 67\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.07906673469551136\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "107 + 77 = 184\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.028035984856197797\n",
            "Pred:[1 0 0 1 0 0 1 1]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "110 + 37 = 147\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.02962239373672705\n",
            "Pred:[1 1 1 0 1 0 1 1]\n",
            "True:[1 1 1 0 1 0 1 1]\n",
            "121 + 114 = 235\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.030959568266408024\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "50 + 60 = 110\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.028530071729579744\n",
            "Pred:[0 1 0 0 1 0 1 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "69 + 6 = 75\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.058484399491806685\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "62 + 122 = 184\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.03063962156416111\n",
            "Pred:[0 0 0 1 1 0 1 1]\n",
            "True:[0 0 0 1 1 0 1 1]\n",
            "15 + 12 = 27\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.021558582105915193\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "112 + 42 = 154\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.021965748945544754\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "67 + 116 = 183\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.026318167471522096\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "60 + 44 = 104\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.02094550564366975\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "91 + 17 = 108\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.007659876399311931\n",
            "Pred:[0 0 1 1 1 0 1 1]\n",
            "True:[0 0 1 1 1 0 1 1]\n",
            "56 + 3 = 59\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.025107206405252377\n",
            "Pred:[1 0 0 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "109 + 30 = 139\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.01547319028400163\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "81 + 68 = 149\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.011773617309120259\n",
            "Pred:[1 1 1 1 1 1 0 0]\n",
            "True:[1 1 1 1 1 1 0 0]\n",
            "125 + 127 = 252\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.028979222441761654\n",
            "Pred:[1 0 1 1 0 0 0 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "71 + 105 = 176\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.047121998981453375\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "63 + 35 = 98\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.028525510766743027\n",
            "Pred:[0 0 1 0 0 0 0 0]\n",
            "True:[0 0 1 0 0 0 0 0]\n",
            "15 + 17 = 32\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.003946335129280781\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "10 + 53 = 63\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.012513966853749439\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "64 + 22 = 86\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.0038649915266106265\n",
            "Pred:[1 0 0 1 0 1 1 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "29 + 121 = 150\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.014759262065409461\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "77 + 52 = 129\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.004326335273548423\n",
            "Pred:[1 0 0 1 1 0 1 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "109 + 45 = 154\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.01099070858204579\n",
            "Pred:[0 1 0 1 0 1 0 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "24 + 60 = 84\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.01089065687585321\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "23 + 120 = 143\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.011976508323701054\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "90 + 12 = 102\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.008043358263201078\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "119 + 54 = 173\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.0029996821428374403\n",
            "Pred:[1 0 1 0 1 1 0 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "93 + 79 = 172\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.007518893352020493\n",
            "Pred:[1 0 1 0 1 1 1 1]\n",
            "True:[1 0 1 0 1 1 1 1]\n",
            "113 + 62 = 175\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.008458203735465887\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "108 + 12 = 120\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.007910321441711101\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "40 + 24 = 64\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.003420196558402549\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "34 + 65 = 99\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.005100804530337901\n",
            "Pred:[1 1 0 1 0 1 0 1]\n",
            "True:[1 1 0 1 0 1 0 1]\n",
            "111 + 102 = 213\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.0019046381585642853\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "37 + 121 = 158\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.005086390751333623\n",
            "Pred:[1 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "41 + 87 = 128\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.003465912534809262\n",
            "Pred:[1 1 0 0 1 1 0 0]\n",
            "True:[1 1 0 0 1 1 0 0]\n",
            "125 + 79 = 204\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.0016618534245748566\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "37 + 57 = 94\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.0019691395621545616\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "48 + 71 = 119\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.007128003231085155\n",
            "Pred:[1 0 0 0 0 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "108 + 26 = 134\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.005857849869608455\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "2 + 78 = 80\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.0028417048649123883\n",
            "Pred:[0 0 1 1 1 0 1 0]\n",
            "True:[0 0 1 1 1 0 1 0]\n",
            "47 + 11 = 58\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.005337609069477638\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "103 + 29 = 132\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0028888131606127597\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "28 + 109 = 137\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.005432163955905973\n",
            "Pred:[1 0 0 1 0 1 1 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "110 + 40 = 150\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.003795945557953574\n",
            "Pred:[1 1 0 1 0 0 1 1]\n",
            "True:[1 1 0 1 0 0 1 1]\n",
            "107 + 104 = 211\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.004132419169179206\n",
            "Pred:[1 0 0 1 1 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "58 + 100 = 158\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7zQEPrtP4OP",
        "colab_type": "text"
      },
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "## [try] weight_init_stdやlearning_rate, hidden_layer_sizeを変更してみよう\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INeFusBxSGLx",
        "colab_type": "code",
        "outputId": "82b96add-9efb-43e7-9486-3d1a6903f52f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 3\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "\n",
        "\n",
        "# He\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "\n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:2.9999869230542338\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "85 + 44 = 255\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.5706371451783394\n",
            "Pred:[0 0 1 0 0 0 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "59 + 92 = 35\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.240283594391134\n",
            "Pred:[0 0 1 0 1 0 0 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "96 + 63 = 41\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.198878861095366\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[0 0 1 1 1 0 0 1]\n",
            "22 + 35 = 129\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.2673408662400887\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[0 1 0 1 1 1 1 0]\n",
            "19 + 75 = 168\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.9415012268004523\n",
            "Pred:[1 0 1 1 0 1 1 0]\n",
            "True:[0 1 0 1 0 0 1 0]\n",
            "73 + 9 = 182\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.8069858932336196\n",
            "Pred:[1 1 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "102 + 47 = 209\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.0601516360968537\n",
            "Pred:[1 0 1 0 0 1 0 1]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "58 + 122 = 165\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.6345070123970564\n",
            "Pred:[1 0 0 1 0 1 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "53 + 105 = 150\n",
            "------------\n",
            "iters:900\n",
            "Loss:0.6494922982750804\n",
            "Pred:[1 0 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "27 + 122 = 157\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.2703945511126162\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "66 + 120 = 137\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.6867508817235959\n",
            "Pred:[0 1 0 1 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "57 + 40 = 81\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.9629951474260375\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[1 1 1 0 0 0 0 1]\n",
            "102 + 123 = 253\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.9233995638721417\n",
            "Pred:[0 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "100 + 55 = 25\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.6769445113307799\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "8 + 54 = 127\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.3730945004089472\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 0 0 1 0 1 1]\n",
            "35 + 40 = 91\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.5343120441484454\n",
            "Pred:[0 1 1 0 0 1 1 1]\n",
            "True:[0 1 0 0 0 1 1 1]\n",
            "46 + 25 = 103\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.6799375821465717\n",
            "Pred:[1 0 1 1 1 1 1 1]\n",
            "True:[1 1 0 1 1 0 1 1]\n",
            "125 + 94 = 191\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.4013495727857108\n",
            "Pred:[1 1 1 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "9 + 127 = 236\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.4254646848333401\n",
            "Pred:[1 0 0 1 1 0 1 1]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "80 + 74 = 155\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.12988256968253659\n",
            "Pred:[0 0 0 1 0 1 1 0]\n",
            "True:[0 0 0 1 0 1 1 0]\n",
            "9 + 13 = 22\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.8038876207417693\n",
            "Pred:[1 1 1 1 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "95 + 46 = 253\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.27456545297226653\n",
            "Pred:[0 0 1 0 1 0 1 1]\n",
            "True:[0 0 1 0 1 0 1 1]\n",
            "15 + 28 = 43\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.16228679352549366\n",
            "Pred:[1 1 1 1 0 1 1 0]\n",
            "True:[1 1 1 1 0 1 1 0]\n",
            "125 + 121 = 246\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.5171678691346017\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 1 0 0 1 0]\n",
            "119 + 59 = 162\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.4540245835217067\n",
            "Pred:[1 0 0 0 0 0 1 1]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "114 + 33 = 131\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.359036629624742\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "12 + 56 = 64\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.4620653818882479\n",
            "Pred:[1 1 0 0 1 1 1 1]\n",
            "True:[1 1 0 0 1 0 1 1]\n",
            "85 + 118 = 207\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.6049196712327343\n",
            "Pred:[1 1 0 1 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "92 + 45 = 217\n",
            "------------\n",
            "iters:2900\n",
            "Loss:0.5493912424759839\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "87 + 9 = 112\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.402730427424044\n",
            "Pred:[1 0 1 1 0 1 0 1]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "127 + 54 = 181\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.11886525773489881\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "6 + 57 = 63\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.11253462104334415\n",
            "Pred:[1 0 1 1 0 1 1 1]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "72 + 111 = 183\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.348289855662562\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "63 + 47 = 78\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.29160028837100366\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "42 + 87 = 129\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.10908705558348926\n",
            "Pred:[1 0 1 1 0 1 1 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "113 + 69 = 182\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.18936159757994608\n",
            "Pred:[0 0 1 0 0 1 1 0]\n",
            "True:[0 0 1 0 0 1 1 0]\n",
            "10 + 28 = 38\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.23018844799986335\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "88 + 35 = 123\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.03861810980427533\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "77 + 89 = 166\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.21690751175734904\n",
            "Pred:[1 0 1 0 0 1 0 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "81 + 80 = 165\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.1207112200851637\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "57 + 43 = 100\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.10392124721923511\n",
            "Pred:[0 0 1 0 0 1 1 0]\n",
            "True:[0 0 1 0 0 1 1 0]\n",
            "31 + 7 = 38\n",
            "------------\n",
            "iters:4200\n",
            "Loss:1.7705653756240038\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "63 + 64 = 129\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.1098393014537788\n",
            "Pred:[1 0 0 1 0 0 1 1]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "98 + 49 = 147\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.2330055425195121\n",
            "Pred:[1 0 1 1 0 0 1 0]\n",
            "True:[1 0 1 1 0 0 1 0]\n",
            "110 + 68 = 178\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.057784348082680674\n",
            "Pred:[1 0 1 1 0 1 1 0]\n",
            "True:[1 0 1 1 0 1 1 0]\n",
            "55 + 127 = 182\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.11022021037553381\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "87 + 31 = 118\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.11378661669489934\n",
            "Pred:[0 0 0 1 0 0 1 0]\n",
            "True:[0 0 0 1 0 0 1 0]\n",
            "12 + 6 = 18\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.18418794385313075\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 0 1 0]\n",
            "100 + 62 = 162\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.03240256313660261\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "81 + 21 = 102\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.03109463630326521\n",
            "Pred:[0 0 1 0 0 1 1 0]\n",
            "True:[0 0 1 0 0 1 1 0]\n",
            "5 + 33 = 38\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.029552468057349648\n",
            "Pred:[0 0 1 1 0 0 1 1]\n",
            "True:[0 0 1 1 0 0 1 1]\n",
            "50 + 1 = 51\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.04151061005655921\n",
            "Pred:[0 0 1 1 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 0 0]\n",
            "5 + 43 = 48\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.08883250714833171\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "111 + 5 = 116\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.07472995836928707\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "77 + 107 = 184\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.047079845725438864\n",
            "Pred:[0 1 0 0 1 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "70 + 9 = 79\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.055249457976599435\n",
            "Pred:[1 0 1 0 0 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "58 + 105 = 163\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.09554182434946128\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "113 + 40 = 153\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.1855535520739569\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "122 + 44 = 166\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.013358137856676477\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "66 + 67 = 133\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.14744727930647478\n",
            "Pred:[1 0 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "124 + 21 = 145\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.06212306374092089\n",
            "Pred:[1 0 1 1 0 0 1 0]\n",
            "True:[1 0 1 1 0 0 1 0]\n",
            "66 + 112 = 178\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.006983820274102522\n",
            "Pred:[0 0 1 1 0 1 1 0]\n",
            "True:[0 0 1 1 0 1 1 0]\n",
            "5 + 49 = 54\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.28432363210776473\n",
            "Pred:[1 1 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "101 + 55 = 220\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.03608347844817182\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "61 + 92 = 153\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.06750354152429261\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "123 + 33 = 156\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.05347883725156732\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "56 + 56 = 112\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.05783581659945098\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "78 + 22 = 100\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.052710083318356374\n",
            "Pred:[1 0 1 1 0 1 0 1]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "116 + 65 = 181\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.026390072398891073\n",
            "Pred:[1 1 0 0 1 0 0 0]\n",
            "True:[1 1 0 0 1 0 0 0]\n",
            "75 + 125 = 200\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.05521995906245639\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "23 + 33 = 56\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.05265792626897285\n",
            "Pred:[1 1 1 0 0 1 0 0]\n",
            "True:[1 1 1 0 0 1 0 0]\n",
            "118 + 110 = 228\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.04607974785450133\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "94 + 23 = 117\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.2775233043288602\n",
            "Pred:[1 0 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "55 + 104 = 157\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.16409628217243657\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "75 + 20 = 93\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.022006069226910212\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "0 + 80 = 80\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.00761040881743051\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "53 + 33 = 86\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.017571848477338742\n",
            "Pred:[0 1 0 0 1 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "68 + 11 = 79\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.004970365598231019\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "9 + 105 = 114\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.11433631042600707\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "51 + 44 = 95\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.020966955860647177\n",
            "Pred:[0 1 1 0 0 1 0 0]\n",
            "True:[0 1 1 0 0 1 0 0]\n",
            "80 + 20 = 100\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.14509706051788873\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "39 + 104 = 143\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.02449506393588035\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "2 + 125 = 127\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.021882038002856173\n",
            "Pred:[1 0 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "96 + 61 = 157\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.01697020774063044\n",
            "Pred:[1 1 0 0 1 1 1 0]\n",
            "True:[1 1 0 0 1 1 1 0]\n",
            "121 + 85 = 206\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.02614228742098694\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "82 + 14 = 96\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.010621331984130889\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[0 0 1 0 0 1 0 0]\n",
            "7 + 29 = 36\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.027546081634564106\n",
            "Pred:[1 0 1 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "70 + 90 = 160\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.011454764915967999\n",
            "Pred:[1 0 1 1 1 0 1 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "87 + 99 = 186\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.010028231250697878\n",
            "Pred:[0 0 1 0 0 0 0 1]\n",
            "True:[0 0 1 0 0 0 0 1]\n",
            "6 + 27 = 33\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.019059800925304432\n",
            "Pred:[0 1 1 1 1 0 1 0]\n",
            "True:[0 1 1 1 1 0 1 0]\n",
            "31 + 91 = 122\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.024977810571748093\n",
            "Pred:[1 0 1 0 0 0 0 1]\n",
            "True:[1 0 1 0 0 0 0 1]\n",
            "116 + 45 = 161\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.013423161373320867\n",
            "Pred:[0 0 1 0 1 1 0 0]\n",
            "True:[0 0 1 0 1 1 0 0]\n",
            "14 + 30 = 44\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.06164304424675295\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "67 + 52 = 119\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.011492460531337427\n",
            "Pred:[0 1 0 1 0 1 0 1]\n",
            "True:[0 1 0 1 0 1 0 1]\n",
            "67 + 18 = 85\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.0078017949302482455\n",
            "Pred:[1 0 0 0 1 0 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "20 + 116 = 136\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.09091527103756802\n",
            "Pred:[1 1 0 1 0 1 1 1]\n",
            "True:[1 1 0 1 0 1 1 1]\n",
            "123 + 92 = 215\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.005068929408178186\n",
            "Pred:[1 1 0 1 0 1 0 1]\n",
            "True:[1 1 0 1 0 1 0 1]\n",
            "104 + 109 = 213\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.00956127535524106\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "44 + 60 = 104\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.004622942818314887\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "23 + 126 = 149\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFKTkAZ3pZSahDS4K6XUJPT/Ab7WoqkMYOpgAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-buBw-Qe4t1",
        "colab_type": "text"
      },
      "source": [
        "## [try] 重みの初期化方法を変更してみよう(Xavier)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbkJgYmbe5ZZ",
        "colab_type": "code",
        "outputId": "ec281331-bb53-4220-ba42-31d668b1ce28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "#W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "#W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "#W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "\n",
        "# He\n",
        "#W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "#W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "#W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)# Xavier\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1]) \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1]) \n",
        "\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:0.9515563259022051\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "125 + 39 = 0\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.053514683737145\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 0 1 0 1 0 0 1]\n",
            "3 + 38 = 254\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.008895370169364\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "48 + 40 = 254\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.1174524462798632\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "40 + 55 = 0\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.005386092187624\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "77 + 29 = 0\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.1139236192527626\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 0 1 0 1]\n",
            "102 + 79 = 0\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.029928929168094\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 1 1 1 0 0]\n",
            "43 + 49 = 127\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.9928805640539976\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 1 0 0 1]\n",
            "105 + 96 = 255\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.153840907991623\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "45 + 126 = 0\n",
            "------------\n",
            "iters:900\n",
            "Loss:1.0961256636832553\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 0 0 1 0]\n",
            "46 + 4 = 255\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.0317254731053158\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "120 + 23 = 1\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.0072879784463582\n",
            "Pred:[0 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "8 + 125 = 25\n",
            "------------\n",
            "iters:1200\n",
            "Loss:1.008857887994664\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 1 0 0 0 0 1]\n",
            "122 + 103 = 0\n",
            "------------\n",
            "iters:1300\n",
            "Loss:1.0497799533938945\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 1 1 0 0 1]\n",
            "115 + 102 = 0\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.9290908954075812\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "34 + 97 = 0\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.9558679082334565\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 1 0 0 0]\n",
            "114 + 86 = 0\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.203222684598861\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "62 + 2 = 255\n",
            "------------\n",
            "iters:1700\n",
            "Loss:1.0587436019892233\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 0 1 1 1 1 1]\n",
            "17 + 14 = 0\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.923583088425002\n",
            "Pred:[0 1 0 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "29 + 33 = 95\n",
            "------------\n",
            "iters:1900\n",
            "Loss:1.0330816010223665\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "50 + 23 = 111\n",
            "------------\n",
            "iters:2000\n",
            "Loss:1.1441682570604048\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "48 + 107 = 0\n",
            "------------\n",
            "iters:2100\n",
            "Loss:1.0381644233502048\n",
            "Pred:[0 0 0 0 0 1 1 1]\n",
            "True:[0 0 1 0 1 1 0 0]\n",
            "1 + 43 = 7\n",
            "------------\n",
            "iters:2200\n",
            "Loss:1.058068542860298\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "52 + 90 = 255\n",
            "------------\n",
            "iters:2300\n",
            "Loss:1.1713157824823885\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "45 + 99 = 255\n",
            "------------\n",
            "iters:2400\n",
            "Loss:1.0484158767706642\n",
            "Pred:[1 1 0 1 1 0 1 1]\n",
            "True:[0 1 1 1 0 0 0 1]\n",
            "101 + 12 = 219\n",
            "------------\n",
            "iters:2500\n",
            "Loss:1.0727808000035266\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "8 + 110 = 0\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.999894435177718\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "125 + 77 = 255\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.9528249989461137\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "18 + 127 = 0\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.9175641807936542\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "56 + 60 = 0\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.8972755136783794\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "66 + 106 = 132\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.935701579744326\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "35 + 115 = 68\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.801764509323574\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 1 0 1 1 0 1 0]\n",
            "109 + 109 = 146\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.9752833476875524\n",
            "Pred:[0 0 0 1 1 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "77 + 21 = 26\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.9222337507542139\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "6 + 84 = 254\n",
            "------------\n",
            "iters:3800\n",
            "Loss:1.026835093967085\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "19 + 120 = 99\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.8907839427091794\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 0 1]\n",
            "34 + 75 = 239\n",
            "------------\n",
            "iters:4000\n",
            "Loss:1.0061400710509876\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "83 + 21 = 111\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.7447613643029798\n",
            "Pred:[1 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "50 + 65 = 247\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.7848226537683238\n",
            "Pred:[0 0 0 0 1 1 1 0]\n",
            "True:[0 0 1 0 1 0 1 0]\n",
            "3 + 39 = 14\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.7897671859917701\n",
            "Pred:[1 0 0 0 1 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "71 + 92 = 139\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.722952269886988\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "64 + 79 = 159\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.8157598980588974\n",
            "Pred:[0 1 0 0 0 1 1 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "0 + 101 = 71\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.7741819006119407\n",
            "Pred:[1 1 0 1 1 0 1 0]\n",
            "True:[1 1 0 1 0 0 1 0]\n",
            "108 + 102 = 218\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.6563700131904167\n",
            "Pred:[1 1 0 0 0 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "35 + 99 = 198\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.2569558831141332\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "65 + 65 = 130\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.4383794567055666\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 1 0 1 0 1 0 0]\n",
            "104 + 108 = 144\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.3287540955991094\n",
            "Pred:[0 1 0 1 0 1 1 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "37 + 49 = 86\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.4488653152858836\n",
            "Pred:[1 1 0 1 1 0 1 1]\n",
            "True:[1 1 0 1 1 0 0 1]\n",
            "117 + 100 = 219\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.711355851528789\n",
            "Pred:[1 0 1 1 1 1 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "78 + 82 = 188\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.47126540676550904\n",
            "Pred:[0 1 0 0 1 1 0 1]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "56 + 21 = 77\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.41396959203338207\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "106 + 15 = 121\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.4933952905528521\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "112 + 61 = 173\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.34683248831635805\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "44 + 113 = 159\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.2999961220928564\n",
            "Pred:[0 1 0 0 1 0 0 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "14 + 59 = 73\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.5511672105959309\n",
            "Pred:[1 0 1 1 1 1 1 0]\n",
            "True:[1 0 1 1 0 0 1 0]\n",
            "75 + 103 = 190\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.18786757396209064\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "13 + 43 = 56\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.1956972041803581\n",
            "Pred:[1 0 1 0 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 0]\n",
            "67 + 101 = 168\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.060919739608389756\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "41 + 73 = 114\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.11603028668078258\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "28 + 113 = 141\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.3853499169344157\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "33 + 82 = 115\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.12793841909831075\n",
            "Pred:[1 0 1 1 1 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "87 + 97 = 184\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.03913293170589365\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "100 + 48 = 148\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.04011408274539407\n",
            "Pred:[0 0 1 0 1 0 1 0]\n",
            "True:[0 0 1 0 1 0 1 0]\n",
            "12 + 30 = 42\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.07747357263676596\n",
            "Pred:[1 1 0 1 0 0 0 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "108 + 101 = 209\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.04059861447306426\n",
            "Pred:[0 1 0 1 1 0 1 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "30 + 60 = 90\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.05196132767392709\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "75 + 32 = 107\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.0875181629427508\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "54 + 76 = 130\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.03355844338156149\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "111 + 14 = 125\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.11728566951378769\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "63 + 89 = 152\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.021260752889757612\n",
            "Pred:[1 0 0 1 1 0 0 1]\n",
            "True:[1 0 0 1 1 0 0 1]\n",
            "54 + 99 = 153\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.044994883758003694\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "83 + 35 = 118\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.02190453980664816\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 0 0]\n",
            "40 + 12 = 52\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.02357477205206962\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "37 + 54 = 91\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.01863716376970392\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "117 + 8 = 125\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.015805573278260782\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[0 0 1 0 0 1 0 0]\n",
            "24 + 12 = 36\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.03419944589429923\n",
            "Pred:[1 1 0 0 1 0 0 0]\n",
            "True:[1 1 0 0 1 0 0 0]\n",
            "109 + 91 = 200\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.017777663731372503\n",
            "Pred:[0 1 1 0 1 1 0 0]\n",
            "True:[0 1 1 0 1 1 0 0]\n",
            "7 + 101 = 108\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.011860560110176855\n",
            "Pred:[0 0 1 1 0 1 1 0]\n",
            "True:[0 0 1 1 0 1 1 0]\n",
            "12 + 42 = 54\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.013456356583538227\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "87 + 83 = 170\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.011244658711539054\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "2 + 72 = 74\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.013978240789258021\n",
            "Pred:[0 0 0 1 1 1 0 1]\n",
            "True:[0 0 0 1 1 1 0 1]\n",
            "17 + 12 = 29\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.012662808184264743\n",
            "Pred:[1 0 0 0 1 0 0 1]\n",
            "True:[1 0 0 0 1 0 0 1]\n",
            "115 + 22 = 137\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.017552058265883113\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "34 + 54 = 88\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.01163218186293514\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "63 + 107 = 170\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.009956529796157644\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "30 + 113 = 143\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.001974633433548057\n",
            "Pred:[1 1 0 0 0 1 1 0]\n",
            "True:[1 1 0 0 0 1 1 0]\n",
            "81 + 117 = 198\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.008020850995046038\n",
            "Pred:[0 1 1 0 0 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "90 + 7 = 97\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.007513375002348309\n",
            "Pred:[1 0 1 0 1 0 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "51 + 120 = 171\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.006598106276327837\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "60 + 45 = 105\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.005985319996341174\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "102 + 3 = 105\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.010238966196609666\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 0 0 0 0]\n",
            "62 + 18 = 80\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.00535752967296427\n",
            "Pred:[0 1 0 1 1 0 1 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "54 + 36 = 90\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.0044734306020744715\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "69 + 43 = 112\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0032205611725453606\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "43 + 67 = 110\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.007292653625935689\n",
            "Pred:[1 1 0 0 1 0 0 0]\n",
            "True:[1 1 0 0 1 0 0 0]\n",
            "90 + 110 = 200\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.005352359677059119\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[0 0 0 0 0 0 0 1]\n",
            "1 + 0 = 1\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F0YFAwVruB0",
        "colab_type": "text"
      },
      "source": [
        "## [try] 重みの初期化方法を変更してみよう(He)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY6IfVgcrvul",
        "colab_type": "code",
        "outputId": "079e5480-f9dc-4e92-dc9e-8d0aed8d986b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "#W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "#W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "#W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "#W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "#W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "#W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "\n",
        "# He\n",
        "W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)# Xavier\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#         z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#         z[:,t+1] = np.tanh(u[:,t+1]) \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#         delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1]) \n",
        "\n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:0.8134697711956698\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[1 1 0 1 1 1 1 0]\n",
            "105 + 117 = 255\n",
            "------------\n",
            "iters:100\n",
            "Loss:0.9846057765148719\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 0 1 1 0 1 1]\n",
            "61 + 94 = 173\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.0998511648298916\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "12 + 100 = 255\n",
            "------------\n",
            "iters:300\n",
            "Loss:1.0049771461120198\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "33 + 114 = 0\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.0049975328676677\n",
            "Pred:[1 1 0 0 1 1 0 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "44 + 126 = 204\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.115482928468852\n",
            "Pred:[1 1 1 1 1 1 1 1]\n",
            "True:[0 0 1 0 1 0 0 1]\n",
            "2 + 39 = 255\n",
            "------------\n",
            "iters:600\n",
            "Loss:0.8758513692074916\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 1 1 0 0]\n",
            "42 + 34 = 68\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.0594067713404263\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "38 + 108 = 72\n",
            "------------\n",
            "iters:800\n",
            "Loss:1.0588183845992425\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "5 + 120 = 0\n",
            "------------\n",
            "iters:900\n",
            "Loss:1.0137421028729512\n",
            "Pred:[1 1 1 0 1 1 1 0]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "110 + 87 = 238\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.8858765567230731\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[0 1 1 1 1 0 0 0]\n",
            "84 + 36 = 72\n",
            "------------\n",
            "iters:1100\n",
            "Loss:1.0032679787145904\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "63 + 127 = 0\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.979773894481919\n",
            "Pred:[1 1 0 1 0 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "34 + 105 = 211\n",
            "------------\n",
            "iters:1300\n",
            "Loss:1.0053044871442351\n",
            "Pred:[0 0 1 0 0 0 0 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "84 + 118 = 32\n",
            "------------\n",
            "iters:1400\n",
            "Loss:1.166528950960385\n",
            "Pred:[1 1 0 1 1 1 0 1]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "38 + 108 = 221\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.8438387345776166\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[0 0 0 1 0 1 1 0]\n",
            "0 + 22 = 4\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.0555409407727694\n",
            "Pred:[0 0 1 1 0 0 0 0]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "77 + 24 = 48\n",
            "------------\n",
            "iters:1700\n",
            "Loss:0.7730722669312021\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "70 + 76 = 152\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.5863026400088316\n",
            "Pred:[0 0 1 0 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 0 0]\n",
            "48 + 0 = 32\n",
            "------------\n",
            "iters:1900\n",
            "Loss:1.202887450703235\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "57 + 79 = 118\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.6043667546478204\n",
            "Pred:[1 0 1 0 1 1 1 1]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "87 + 84 = 175\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.5781449771448652\n",
            "Pred:[0 0 1 0 1 1 1 0]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "55 + 7 = 46\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.8453197958859199\n",
            "Pred:[0 1 1 1 0 0 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "61 + 40 = 113\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.633886270752159\n",
            "Pred:[1 0 0 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 1 0]\n",
            "76 + 74 = 148\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.9266199709798049\n",
            "Pred:[0 1 0 1 0 0 0 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "64 + 63 = 81\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.7601451495860656\n",
            "Pred:[0 1 0 1 1 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "55 + 46 = 93\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.7888058017361965\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 1 0 1 0 0]\n",
            "13 + 71 = 94\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.5064385217177075\n",
            "Pred:[0 0 1 1 1 0 1 0]\n",
            "True:[0 0 1 1 0 0 1 0]\n",
            "13 + 37 = 58\n",
            "------------\n",
            "iters:2800\n",
            "Loss:1.045932542290742\n",
            "Pred:[1 1 1 1 1 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "55 + 76 = 251\n",
            "------------\n",
            "iters:2900\n",
            "Loss:1.0801217734950472\n",
            "Pred:[0 0 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "79 + 40 = 48\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.550677425342531\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "46 + 20 = 98\n",
            "------------\n",
            "iters:3100\n",
            "Loss:0.31652978420940275\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "109 + 8 = 117\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.209526495219155\n",
            "Pred:[0 0 1 0 1 1 0 0]\n",
            "True:[0 0 1 0 1 1 0 0]\n",
            "18 + 26 = 44\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.2818560146507228\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "36 + 42 = 78\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.21804316052611006\n",
            "Pred:[1 1 1 0 0 0 0 1]\n",
            "True:[1 1 1 0 0 0 0 1]\n",
            "99 + 126 = 225\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.3155737481194287\n",
            "Pred:[0 0 1 1 0 1 1 1]\n",
            "True:[0 0 1 1 0 1 1 1]\n",
            "46 + 9 = 55\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.03975221264015695\n",
            "Pred:[0 0 0 0 0 1 1 0]\n",
            "True:[0 0 0 0 0 1 1 0]\n",
            "1 + 5 = 6\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.25530919755980497\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 0 0 0 1 0 0]\n",
            "29 + 39 = 68\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.12292233760804283\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "40 + 104 = 144\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.025537942986017033\n",
            "Pred:[1 0 1 1 1 1 0 0]\n",
            "True:[1 0 1 1 1 1 0 0]\n",
            "93 + 95 = 188\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.05581010623015482\n",
            "Pred:[0 1 0 0 0 1 0 1]\n",
            "True:[0 1 0 0 0 1 0 1]\n",
            "38 + 31 = 69\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.2394392205866317\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "61 + 65 = 126\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.07678067669470988\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "114 + 29 = 143\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.04603039591992485\n",
            "Pred:[0 0 1 1 1 1 1 0]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "45 + 17 = 62\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.04086844892647965\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "43 + 78 = 121\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.06318627932602375\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "45 + 78 = 123\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.03349197383682982\n",
            "Pred:[0 1 1 0 1 0 1 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "21 + 85 = 106\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.05296411745093045\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "76 + 39 = 115\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.03689470293192414\n",
            "Pred:[1 1 0 0 1 1 0 0]\n",
            "True:[1 1 0 0 1 1 0 0]\n",
            "114 + 90 = 204\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.026338031910323828\n",
            "Pred:[0 0 1 0 0 1 1 1]\n",
            "True:[0 0 1 0 0 1 1 1]\n",
            "27 + 12 = 39\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.02667516143220419\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 0 0]\n",
            "16 + 48 = 64\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.007293696479602563\n",
            "Pred:[1 0 0 0 1 1 1 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "81 + 61 = 142\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.010741842145889387\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "106 + 1 = 107\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.01660058422811154\n",
            "Pred:[1 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 0 0 0 0 1]\n",
            "45 + 84 = 129\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.005060270408016091\n",
            "Pred:[1 0 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "117 + 27 = 144\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.014088492392801792\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "43 + 56 = 99\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.010042994429607198\n",
            "Pred:[0 1 1 1 0 0 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "76 + 39 = 115\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.01267170683163777\n",
            "Pred:[1 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "67 + 92 = 159\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.0026129544662401045\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "3 + 111 = 114\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.0037064715537440504\n",
            "Pred:[0 0 1 0 0 0 0 0]\n",
            "True:[0 0 1 0 0 0 0 0]\n",
            "27 + 5 = 32\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.008734329527715027\n",
            "Pred:[1 0 1 0 1 1 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "46 + 127 = 173\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.01126129516115557\n",
            "Pred:[0 0 1 1 1 0 1 1]\n",
            "True:[0 0 1 1 1 0 1 1]\n",
            "39 + 20 = 59\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.011210428496660846\n",
            "Pred:[0 1 1 0 1 0 0 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "16 + 88 = 104\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.006319397755367434\n",
            "Pred:[0 1 1 1 1 1 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "82 + 45 = 127\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.006531932942836696\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "1 + 104 = 105\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.005529814766942779\n",
            "Pred:[1 0 1 1 1 0 1 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "88 + 99 = 187\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.007894271501922625\n",
            "Pred:[0 1 0 1 1 0 1 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "54 + 36 = 90\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.006641625508459365\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "99 + 52 = 151\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.005052855321980307\n",
            "Pred:[0 0 1 1 0 1 0 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "6 + 47 = 53\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.0016451279394187636\n",
            "Pred:[0 1 1 0 0 0 0 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "13 + 83 = 96\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.0013521604032257959\n",
            "Pred:[0 1 0 1 1 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "87 + 1 = 88\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.0011298146361985015\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "83 + 73 = 156\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.0019994107660302597\n",
            "Pred:[1 0 0 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "91 + 39 = 130\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.006583812699076443\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "86 + 32 = 118\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.004971828582915903\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "24 + 32 = 56\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.0035345148685246896\n",
            "Pred:[0 1 0 1 1 0 0 1]\n",
            "True:[0 1 0 1 1 0 0 1]\n",
            "84 + 5 = 89\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.003677255164547488\n",
            "Pred:[1 0 0 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "124 + 17 = 141\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.0036481435378021166\n",
            "Pred:[0 1 0 0 1 0 0 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "41 + 32 = 73\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.003132472525507755\n",
            "Pred:[0 1 0 1 1 0 1 1]\n",
            "True:[0 1 0 1 1 0 1 1]\n",
            "62 + 29 = 91\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.0048005082623568465\n",
            "Pred:[1 0 0 1 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "72 + 84 = 156\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.0024562994204337324\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "0 + 87 = 87\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.0024637104325064695\n",
            "Pred:[1 0 1 0 0 0 1 1]\n",
            "True:[1 0 1 0 0 0 1 1]\n",
            "112 + 51 = 163\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.0005146942803797068\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "97 + 73 = 170\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.0006225165637453144\n",
            "Pred:[1 1 1 0 0 1 0 0]\n",
            "True:[1 1 1 0 0 1 0 0]\n",
            "123 + 105 = 228\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.0023456481123246163\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "103 + 16 = 119\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.0027635139084341244\n",
            "Pred:[1 0 0 1 0 0 1 1]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "77 + 70 = 147\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.0005772080361453043\n",
            "Pred:[1 0 1 0 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "81 + 93 = 174\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.003861366856647612\n",
            "Pred:[1 0 0 0 0 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "62 + 72 = 134\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.0013196044939686104\n",
            "Pred:[0 0 1 0 1 1 0 1]\n",
            "True:[0 0 1 0 1 1 0 1]\n",
            "0 + 45 = 45\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.0019889162764879066\n",
            "Pred:[0 0 1 1 0 1 0 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "35 + 18 = 53\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.0016867637017529053\n",
            "Pred:[0 0 0 0 0 1 0 1]\n",
            "True:[0 0 0 0 0 1 0 1]\n",
            "5 + 0 = 5\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.003012294436963192\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "82 + 88 = 170\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.002836127805765894\n",
            "Pred:[1 0 0 1 1 0 0 0]\n",
            "True:[1 0 0 1 1 0 0 0]\n",
            "48 + 104 = 152\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.003024625434113121\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "78 + 54 = 132\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.0015464920012182466\n",
            "Pred:[1 1 0 1 1 0 1 1]\n",
            "True:[1 1 0 1 1 0 1 1]\n",
            "111 + 108 = 219\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.0016214860446270235\n",
            "Pred:[0 1 0 0 1 1 0 1]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "19 + 58 = 77\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.00032063919374484493\n",
            "Pred:[0 1 1 1 1 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 0]\n",
            "55 + 69 = 124\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.0011224502568805627\n",
            "Pred:[0 0 0 1 1 1 0 1]\n",
            "True:[0 0 0 1 1 1 0 1]\n",
            "8 + 21 = 29\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.00024902057970718327\n",
            "Pred:[0 0 1 0 0 1 1 0]\n",
            "True:[0 0 1 0 0 1 1 0]\n",
            "19 + 19 = 38\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.001846487587208856\n",
            "Pred:[0 1 0 0 1 1 1 1]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "23 + 56 = 79\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO2deXRkV33nP7/aVaUq7VLv7r3tto2x\naYwNzMTsxsOSbYxNEiCDx4dkPJNJOEnwJONMSGayAkkOnhBDyEICBJIM6SEmJmCDAWPH7cFpd9u9\nqDd3t3appVJJtdedP957papSlaqk1vZKv885Ol313q1X9+mpv+/3vvd3f1eMMSiKoijNhWetO6Ao\niqIsPyruiqIoTYiKu6IoShOi4q4oitKEqLgriqI0Ib61+uLu7m6zc+fOtfp6RVEUV/Lcc8+NGWN6\n6rVbM3HfuXMnR44cWauvVxRFcSUicqGRdmrLKIqiNCEq7oqiKE2IiruiKEoTouKuKIrShKi4K4qi\nNCEq7oqiKE1IXXEXkc+KyIiIHKux/ydE5KiIvCAiT4nITcvfTUVRFGUxNBK5/zlw5wL7zwE/ZIy5\nEfgN4JFl6JcCPHlqlJfHZ9e6G4qiuJC64m6MeRKYWGD/U8aYK/bbp4Fty9S3Dc/P/83zfOa7Z9e6\nG4qiuJDl9tw/CHyt1k4RuV9EjojIkdHR0WX+6uZjJpNjNpNf624oiuJClk3cReQNWOL+y7XaGGMe\nMcYcMsYc6umpWxphQ2OMIZMrkM4V1roriqK4kGWpLSMirwA+A7zdGDO+HMfc6OQKhoKBdFYjd0VR\nFs9VR+4isgP4e+CnjDGnrr5LClCM2DVyVxRlKTSSCvkF4PvAARG5JCIfFJEPiciH7CYPAV3A/xaR\n50VESz3apHN5Pvf0BfKFxS9C7kTs6ZxG7oqiLJ66towx5t46++8D7lu2HjURj780wn//yjGu3xLj\nlh0di/psJq+Ru6IoS0dnqK4glyeTAEwls4v+bDpbKPtXURRlMai4ryCOuCdSuUV/ds5zV1tGUZTF\no+K+ggzY4j69JHF3PHeN3BVFWTwq7ivI4FQKgOnU4m2ZjGbLKIpyFai4ryBXF7k7nrvaMoqiLB4V\n9xUilc0zlsgAS4vc1ZZRFOVq2HDinsrmKSwh73yxDNmWDCwxcs/O2TLGrHx/FUVpLjaUuBcKhjf+\n/rdWpdKiY8kATKeXbsvAXM67oihKo2wocb88mWRgKsWZkZlV+S6AvljwqgZUQa0ZRVEWT9OIey5f\n4NNPniWxQJR8emQagInZzIr3x8mU2d8XvapUSNCJTIqiLJ6mEfcjF67wPx99icPPD9Rsc3IoAcCV\nmZUX94HJJN2tQboigavKlrFea8aMoiiLo2nE/fSIJdzHBqZqtxlevcj98mSSre0hoiH/ErNl1JZR\nFGXpNI24n7HF/fjl2uJ+yrZlVity39LeQjTkYzqVW3TGS5m4r4Et8/zFSXI6kKsorqVpxN3x018a\nmiZbRZTyBcPp4QQiMJnMLqkMb6MYYxicSrGlvYXWkI9cwSw6+i7z3FfZlvnaC4P88MPf48nTuhSi\noriVphH3/pEE0aCPTK7A6eHEvP0XJ2ZJ5wpctymGMUur1NgoU8kss5k8m9ssWwYgvkhrpjRaX01b\nJpsv8Dv/dAKAydmV+x0pirKyNIW4x1NZhuNp3n7jJqC6737K9ttfs7sTgIkVtGacNMit7S3EQlbJ\n/MUOqq6V5/6Ff3mZ8+OzAKQ0S0dRXEtTiHu/7be/5eAmIgEvx6r47kVx32WJ+5WKQdX/9n9e4NBv\nfoPX/fbjvPFj3+LjXz+55P4MTlppkI7nDvPFvX9kesGZsmV57qtUX2Y6leUPv3Ga67fEAGs2r6Io\n7qQ5xN22Yfb3tXL9lrYa4p5ga3sL2zrCwPzI/YkTI7S1+LhtdxeRgI8//vYZRqfTS+rPwJQVuW9u\nn7NlSjNmLk8mecsnnuSfXxqueYxyz311IuhHnjzL+EyGX3vn9QCkNAVTUVxLU4j76ZFpgj4P2zrC\nXL81xouD8XmZHqeGp9nf10pnJACUZ8wUCoaR6TR33rCJj919E39wzyvJ5g1fOnJxSf25PJkk4PXQ\nHQlWjdwvTcxiDAyWlCioJJ0r0Br0FV+vNKPTaT79nbO886YtvHqntSSg2jKK4l6aQtz7RxLs7mnF\n6xFu3NpGKlvg7NhciYFcvsDZ0Rn290XpCFviXprrPj6TIV8w9MVCAOzpaeX1e7v566cvLCkdcHAy\nxeb2EB6PFAW6dDWmcfvGMpWs7cOnc4WiX78a2TInhuKksgXuvXU7IkLQ59Fyw4riYppC3E+PJNjX\n2wrAjVvbAHjh0pw1c358lky+wP6+KC0BLy1+b1nkPhy3PPLeaKi47Sdvu4aBqRSPnxhZdH8GJpNs\naWsBqJotM5aw7J6FMnbS2TyxFr/9euUjaCdKd25GIb9XPXdFcTGuF/fZTI7Lk0n22uK+u6eVFr+3\nLGPGmZm6vy8KQGckwMTMnLCOTFvi3hcLFre9+bpeNsVCfO7pC4vu08Bkks3t1o3CEctSW2Zsur64\nZ/IFYvaNYTVsGUfIQ36v/a9HbRlFcTGuF/ezozMYQzFy93qEg1tiHL8cL7Y5OTyNCMUbQEfEX5Yt\nMxy3xNaxZQB8Xg/vfc0OvnN6jHNjjVeRzOULDE+n2dreUuxPa9BXLu5FW2ahyL1A6yraMkVx9zni\n7tUBVUVxMXXFXUQ+KyIjInKsxn4RkT8SkX4ROSoityx/N2vjpEHu62stbrthS4zjA1PFVMPTwwm2\nd4RpCVjC1REOlGXLDMdTiEBPNEgp99y6HZ9H+KtFRO8j02nyBcMWW9wBuwRBiS1jR+7xhcQ9l6fF\n7yXg9axO5G5/R8hv/UmEfGrLKIqbaSRy/3PgzgX2vx3YZ//cD/zx1XercU6PTOPzCNd0RYrbbtja\nxkwmz7lxK+K2MmWixf2dkcC8yL0rEsTvLf919EZDvOHaXr7+4lDD/XEW6Zgv7tUGVBcS9wJBn8ce\n2Fx5cXcGT4NqyyhKU1BX3I0xTwITCzR5N/CXxuJpoF1ENi9XB+vRP5JgZ3ekTJhvsAdV3/qJJ9n7\n3x7l9EiC/SWRfWXkPhJPlfntpVy3OcblK8l51sgPXr7C/3r0pXnZNM9fnARga/ucxdMa9JXVmW9k\nQDWTKxD0ewj6Patiy6QrIvegDqgqiqvxLcMxtgKlCeGX7G2Dy3DsupweSbC/N1q27dpNUR56x0HG\nZywR9Ypw72t2FPd32jXWs/kCfq+HoXiqzG8vZXd3hIKxatPsLfmeLx25xBf+5WUKBcOvvuMgYM06\n/f2vn+R1e7vY0zN3M4mG/EyWPCk0MqCazhUIeD0Efd5VG1AVgYB9kwz5vUytQmlkRVFWhuUQ94YR\nkfuxrBt27NhRp3V9MrkCF8Zn+Xc3lj8oiAj/4fW7an6uw5nINJuhNxpiOJ7mFdvaqrbd2W3ZPWdH\nZ8rE/cyIVWHyM989x43b2njb9Zt44PM/IBLw8Ym7X4mIFNtGQz4uTlj1WpKZPDOZPOGAl9lMnkyu\nQMA3/wEqncsT9HstW2aVxD3o8xT7HfJ5GFZbRlFcy3Jky1wGtpe832Zvm4cx5hFjzCFjzKGenp6r\n/uLz4zPkC6aYBdMonWFnlmqWbL7A+Ey6LMe9lF22l39+vDxj5sxogh+9eRu37uzkl//uKA98/gec\nGJrmY3ffRG/FU0A05Cdue+6OJbO7xzputejdGFP03AOrNJkolS0U0yABWgKaLaMobmY5xP0w8D47\na+Y2YMoYsyqWzAW7euHOksHURuiIWPnjEzMZxhJpjKGmLdMW9tMZCZSlQ16ZyTA+k+HaTVEe/olb\naG8J8I2Xhrn/3+7mjgO9844RK8mWccTdsW2qiXuuYDAGa0DVv3q2jJMGCZotoyhup64tIyJfAO4A\nukXkEvBrgB/AGPMp4FHgLqAfmAV+eqU6W8lQSYGuxdBZYsu0xC1BqzWgCrCzK1wm7v2jVvrl3t5W\neqJBPvuBV/OPLwzwc2/aX/Xz0ZCPdK5AJldgPGH52Lu7a4u7I+YBJ1tmNfLcc4XiYCpotoyiuJ26\n4m6MubfOfgP8p2Xr0SIYnErh8wjdkdrCXA3HlpmYyeD1WB5zrcgdYFd3K9/tn1uVyMmtd+ygg1ti\nHLTL5FbDKUGQSOfmIvde62mjWq57MS3RZ3nupZk2K0Uqmy+zZbT8gKK4G1fPUB2asrJcPB6p37iE\n9vBcZcgRp67MApH7ru4ww/E0M7bInhlJEPJ7irNQ6zFXgiBbzHFvJHK38ty9q1RbJl/McQeKdtBi\n135VFGV94GpxH5xKsbltcZYMWHZHNOhjYjbDcDyN1yN0LRD977KF2BlU7R9NsLu7teGbSmnZ39Hp\nNNGgr3gzWVDcVznPPeQrt2VK+6IoirtwtbgPxVNsWoK4g5UOeWUmw3A8RU9rsGjPVGNnt7XAx/kx\nawC3fyTBnkVk6JRWhhxLpOlqDdBmV3ysJu6ZYuS+eqmQ6Upbxh5cVWtGUdyJa8XdGMPgVHJJkTtY\n4j4xm2V4Ok1fnWM42TjnxhIkM3mrCmXPYsR9LnIfT2TobrVKHYQD3hqRuyWoqzuJyUq9dHCEXgdV\nFcWduFbcp5JZUtkCm9oa870r6Qz7i557X3ThAdlI0EdfLMi5sVnOjCYwhkXl1seKS+1ZA6rdrdb3\ntbX469syq5XnnqscULX+NDRyVxR34lpxH5yyBkKvKnK3bZmFMmUcdnZFODeW4MxoeaZMIziRe8Ie\nUO1qtQZ0a4p7tsSW8S/NljHGLLgAdyVWtkyVyF0nMimKK3GtuA/Z4r5Uz70zHGA0kebKbHbBHHeH\n3T0Rzo/PcmYkgUfmfPhGcOqyX5nNcmU2U4zcYzXEPZN3UiHnbJnFZq386XfP8eaPf7vh9pUzVOci\nd7VlFMWNuFbclyNydwYuK8sFVGNnV4SJmQzPvXyFHZ1hgiWzOevh93oI+T28bC+M3V0SuVfPcy+f\nxATWykyLoX8kwdmxmbI68gsxL89dB1QVxdW4VtyHppJ4BHpaFzeBycGZpQoLT2By2GUXEHvm7MSi\na9mAlTHjLNpd6rlXFfeyPPelpSQ6TwTOE85COLVsSlMhg34Vd0VxM64V98GpFL3RED7v0k6hI+wv\nvm7ElnHEPVcwi0qDdIiGfJx3xN0ewI2Fag2ozi2c4YjsYicyOQtyDzQg7nMDuGrLKEqz4Fpxv5oc\nd7AW7HDoq1ERspQdXWGcKr6LSYN0iJYIeVdkzpaZyeTJVlgumaqR++Ii6HjSmk07aK8MtRDOjaOy\n/MBSvldRlPWBa8V9qbNTHRxbJuD10F4Sxdci6PMWyw0sxZaJhebK+DiRe1uLta3SmqksHFa6rVGc\nG0kjkbuTEVM9z13FXVHciGvFfWjqKiN3W9x7Y8GyhTUWwrFmlmLLOPVlAl6r9AFY5YRh/izVytoy\nsHRbxqmcuRCOgJcPqKotoyhuZlVXYlouplNZEuncVUXu7fb0/0YGUx1edU0Ho9Pp4qSkxeDkune3\nBoo3k1olCJxJSwGvVVsGFmePGGOKTwODjUTuRVtGI3dFaRZcKe5zOe5Lm50K4PN6aGvxNzSY6vBz\nb9rHf37jviV9n1NfprtkNmxNcbdXYRKRJdkyiXQOZ/7SQAOeezFy98333DVyVxR34kpxv9ocd4cP\n/dAert0Urd/QRkTwLq66cBEncu8qScGsJ+7AnC2zCHF3lvRrDfoYnEphjFnQeqpmy3g9gt8rOkNV\nUVyKK8W9GLkvwlKpxs/csWc5utMQxci9JC8/Zot7tQHVgC3qxch9EfaIc7wDm6I8d+EK8VSueCOp\nRio335ax3ntJZlTcFcWNuHJA1YncF+OXrzXFyL21EVsmXxT1pdRVd463v896KhmsM6iarhK5O+81\nFVJR3IkrxX0onqS7NUjA557uOxkyTukBsCyXkN9T3ZaxRT3gXYItYx/vus22uE8uPKhaO3LXdVQV\nxa24Rx1LuNoc97XAsWV6KsoLV6sMmckVil57vWyZfzw6yF8/c6Fsm+O5H7Aj94E6kXuqZM3WUkI+\nXUdVUdyKK8XdWTvVTeztbWVzW4jrt7SVba8m7pbn7gyoOp579Qj68/9ygT/9zrmybc7x9vS24pH6\n9WWKC3JX8dxV3BXFnbhyQHVwKsWrd3audTcWxaa2EN9/8E3ztlcV92y+4WyZydkso4l02TbHlukI\nB+iLhRioZ8tUKT9gvVdbRlHciusi99lMjqlk9qpmp64nLHHPlW0rTYUM1KktMzmbZTqVK4uwp5JZ\nokEfXo+wuS1Ud0C1Wp472JG7DqgqiitxnbgPLVOO+3ohVqXsb6nn7uSb14rcnah/YiZT3BZPZYtp\nlpvbW+rOUk3l8ngE/BVJ/EGfVyN3RXEpDYm7iNwpIidFpF9EPlJl/w4ReUJEfiAiR0XkruXvqsXV\nrsC03qjuuefLingFfd6qnns2XyCRtqL+sRJrJp7MFVMvN8esyH2hlZycVZgqJzqF/KuzfquiKMtP\nXXEXES/wMPB24CBwr4gcrGj2q8CXjDE3A/cA/3u5O+owPpNBBDZfRemB9URbi59EOkeupOxvqS0D\n1qBqNVum9KZQLu7ZYg795vYWUtkCk7O1V2RKVyyO7aADqoriXhoZUL0V6DfGnAUQkS8C7wZeLGlj\ngJj9ug0YWM5OlvLOm7bwtus34fMssQ7AOsMR4XgqVyxDXJrnDo64z4/cSwV7LFFuy2zvtNZ43WI/\n4QxMJYuVMCtJZctXYXII+T3FHHhFUdxFI7bMVuBiyftL9rZS/gfwkyJyCXgU+M/VDiQi94vIERE5\nMjo6uoTuWgR8HjxNJu6lUbiVLTMXSQf93qri3mjkDgtPZKpcP9VB89wVxb0s14DqvcCfG2O2AXcB\nnxORecc2xjxijDlkjDnU09OzTF/tbpzywaVCnckXymbfBn3Vve+p5Fy0Pl4SuU8ls8XjOgPPg3FL\n3OOpLP90bKjsOKlsoepsX8eWWcivVxRlfdKIuF8Gtpe832ZvK+WDwJcAjDHfB0JA93J0sNmpXLDD\nWax6vude25bxeqQYuefyBWYyeWItTrmDID6PFJfb+6UvH+VDf/Vc2cSm2p67h4KBbF7FXVHcRiPi\n/iywT0R2iUgAa8D0cEWbl4E3AYjIdVjivnTfZQPRVlEZMps3GMP8bJkqA6qOuF/TFS6K+7RdesA5\nrtcj9MVCDE6lePSFQf7puBW1l6ZOWrZM9cgd0Fx3RXEhdQdUjTE5EXkAeAzwAp81xhwXkY8CR4wx\nh4EPA58WkZ/HGlz9gNFn+YZwRHjSFvd0bn6dl6DfU0x5LGUymUUEdndHuHTFisydJ4DS1aI2t4U4\nMTTNd06P0hr0kUjnymygVLZAV+v8wdZgyWpMS1l9SlGUtaOh8gPGmEexBkpLtz1U8vpF4HXL27WN\nQUfYEtVxO/LOOOunVmTLjCeqDKjOZoiF/PREQzx/cRKYWzs1VlK/fXN7C//3XwfweYTf+tEb+cW/\nPVoh7vl5s1Nhbh3Vxa7fqijK2uO6GarNRsDnoSsSYDhuibvjrQe8DdgyySztYT89rQEmZjLkC4Z4\nstyWgbl0yJ+5Yw+37e4CyhcISecKC9symjGjKK7DlYXDmo3eWIjRaWuAM10jcq81oNre4qerNUjB\nwJXZzJwt0zJ3ad92wyYmZjI88Ma9xePMi9xrTGKy9mvkrihuQ8V9HdAbDZZE7tU996rinszSFg4U\nl+4bS6TnbJkSj/yWHR3csqMDAL/Hg0caFXfrBqMDqoriPtSWWQf0xYKM2JF70XOfV1umSp77bIb2\nFn9xdaex6UzRbqm1ZqrHI8Qq6tmkKmbEOrSoLaMorkXFfR3QFwsxOp0mXzBznnsjee625+6syzo+\nk2YqmcXrEcKB+ZG4Q2mxskLBlFWhLEVtGUVxLyru64DeqOWZjyfSxcyUMlvGFvfS7NJCwRBPWp57\njy3uo9OWLRML+eZVeCylVNzTNdZPLd2W1MhdUVyHivs6oNdeMnBkOl3iuZdE7nYEnSmpHDmdzlEw\n0BYOEGvx4fcKY4kM8WSupiXjUCrutRbqsPqgtoyiuBUV93WAsx7scDxVM1sGypfam5qd89ZFhK5I\nkPGEZcvE6oh76QIhzmDpQtkyWtNdUdyHivs6oDdq2SrD8XRxQLU8z33+ZKJJu2hYuy3k3dFAMVum\nkcjdyapJZ+vbMuq5K4r7UHFfB/TY4j4ynZqzZfylnruzSPZcBO3UlWm3C491twYZS2TKKkLWwrFl\njDENRe5qyyiK+1BxXwf4vR66W61ZqulqqZD++baMU4vGEXfHloknc2UTmKrR1uInmzcks/liVF4t\ncvd7PXg9onnuiuJCVNzXCT1Ra5bqXLbMwrbM1Kxly7S1WDnuli1j5bnX89xLFwhZaEDV2u5RW0ZR\nXIjOUF0n9MWsWapORkygYhITVLdlHKHuaQ0WP9uILQPl4l5tEhPoOqqK4lY0cl8n9EVDVraMLaRV\nB1QrbJlIwFu8CZSW7G04cp/NFqPyapOYwBF3jdwVxW2ouK8TemNBxhJpZjN5gj5P2SSkqp77bJb2\n8JygO/VloHbpgcr9U8ls8Wmg2oCq893quSuK+1BbZp3QGwtRMDAwlSzz26HElimxR6aSmTIRLxX3\nWKj+gKp1jCwFe9ZrtQFVsLx4zXNXFPeh4r5O6LPTIS9OJMvSIKHGJCa7rozDYmyZWIm4O7ZOrcg9\n5NcBVUVxI2rLrBOcEgQXr8yW+e1QOqBaacvMiXhnOIDj5NSzZaJBHyLWgh3FbJma4q4DqoriRlTc\n1wl9MStyn5zNzstcmfPcS7JlktliGiSAz+uh0/bg62XLeDxCLOS3s2XsPHffAtky6rkriutQcV8n\ndLcGi5F3ZeZKZZ67MYapisgd5qyZepOYnDZOKqTPI/i8tcRdbRlFcSMq7usEv9daSxWoPaBq2zLJ\nbJ5MvlCsK+PQ3Rok5PfUTGssxSlBkMoWaloyYA2oqi2jKO5DxX0d0Ru1fPdAhbgHfOW2TOUEprnP\nB2kvsWoWoijuufy8m0kpQc1zVxRXotky64i+WJAXB+dH7l6P4PdKMXKvLBrm8MAb9/Jjr0o19F1t\nLX6GplI11091CPk9mgqpKC5ExX0d4UTu1WwVax1VW9yT5XVlHPb2RtnbG23ou6zIPUe6xvqpDi06\noKoorqQhW0ZE7hSRkyLSLyIfqdHmbhF5UUSOi8jnl7ebGwMnY6aa2FpL7VkiO1Ujcl8MzoId6Wy+\nZtEwsLJlsnlDvmBqtlEUZf1RN3IXES/wMPAW4BLwrIgcNsa8WNJmH/Ag8DpjzBUR6V2pDjczPXau\ne7BK5krpItmV5X6XQluLn0y+wORstubsVChdsCNPJKgPeoriFhqJ3G8F+o0xZ40xGeCLwLsr2vxH\n4GFjzBUAY8zI8nZzY+DMUq0WuUeCPvpHEhQKprj+aaODp9VwBmNHptN1PHddsENR3Egj4r4VuFjy\n/pK9rZT9wH4R+Z6IPC0id1Y7kIjcLyJHROTI6Ojo0nrcxDhrqVbz3O/7N7t4/uIkn/nuWSZnrbIB\nC0Xc9XDEfTieqpsKCZDKacaMoriJ5XrO9gH7gDuAbcCTInKjMWaytJEx5hHgEYBDhw6piVtBr+O5\nV0lNvPvQdp44McrvPXaS67e00W4vjL1UHHFP5woL3iScp4hkRiN3RXETjYR+l4HtJe+32dtKuQQc\nNsZkjTHngFNYYq8sAmcSUlsVL11E+O0fu5GuSJDnL05eld8O5TnyC016UltGUdxJI+L+LLBPRHaJ\nSAC4Bzhc0eYrWFE7ItKNZdOcXcZ+bgj8Xg+HH3g977t9Z9X97eEAH7/7JkTqFwerR+nnFx5Qnb8K\nlKIo65+6towxJiciDwCPAV7gs8aY4yLyUeCIMeawve+tIvIikAd+0RgzvpIdb1b29y2cp/7avd38\nrx+5cVnFfcHI3edky6jnrihuoiHP3RjzKPBoxbaHSl4b4BfsH2WFuffWHVd9jGioNHJXW0ZRmg2t\nLbNB8XqEqL1iUyO2jEbuiuIuVNw3MI41U6+2DGjkrihuQ8V9A1MU9wWqQrYELOGfVXFXFFeh4r6B\naSRyd2bBTs5kVqVPiqIsDyruGxhH3BeqChnweYgGfYyruCuKq1Bx38DM2TILr9zU2RrgyqyKu6K4\nCRX3DUwjtgxARzjAhEbuiuIqVNw3MLEGbBmAroiKu6K4DRX3DUzDkXskwBUVd0VxFSruG5iuiJUJ\n01pnEY6uSIDxmQzWRGRFUdyAivsG5k3X9fHJ997Mvt7WBdt1RAKkcwWSmuuuKK5BxX0DE/B5eMcr\nttStC98ZtiL88YRaM4riFlTclbp02vaNpkMqintQcVfq0mGLu05kUhT3oOKu1MUZeNWMGUVxDyru\nSl2cyF1z3RXFPai4K3WJhXz4PKLiriguQsVdqYuIWBOZdEBVUVyDirvSEF2RgKZCKoqLUHFXGqIj\nrJG7orgJFXelITrtEgSKorgDFXelITq1eJiiuAoVd6UhOiIBJpNZ8gUtHqYobkDFXWmIrkgAY2BS\nfXdFcQUNibuI3CkiJ0WkX0Q+skC7HxMRIyKHlq+LynpAJzIpiruoK+4i4gUeBt4OHATuFZGDVdpF\ngZ8DnlnuTiprT5eKu6K4ikYi91uBfmPMWWNMBvgi8O4q7X4D+B0gtYz9U9YJHWEVd0VxE42I+1bg\nYsn7S/a2IiJyC7DdGPOPCx1IRO4XkSMicmR0dHTRnVXWjq5WW9zVc1cUV3DVA6oi4gE+Dny4Xltj\nzCPGmEPGmEM9PT1X+9XKKtIettZb1XRIRXEHjYj7ZWB7yftt9jaHKHAD8C0ROQ/cBhzWQdXmIujz\n0hr06UQmRXEJjYj7s8A+EdklIgHgHuCws9MYM2WM6TbG7DTG7ASeBt5ljDmyIj1W1gydyKQo7qGu\nuBtjcsADwGPAS8CXjDHHReSjIvKule6gsn7o0BIEiuIafI00MsY8Cjxase2hGm3vuPpuKeuRrkiA\nkWlNhlIUN6AzVJWG6QgHmNCyv4riClTclYbpag1oKqSiuAQVd6VhOsIBUtkCs5ncWndFUZQ6qLgr\nDdMZsXLddZaqoqx/VNyVhgBEgg0AABVHSURBVOmMBAEVd0VxAyruSsNo5K4o7kHFXWkYJ3LXtVQV\nZf2j4q40TKddGXJ8EemQjx0f4tEXBleqS4qi1KChSUyKAhBr8REN+Tg/PtPwZz7+9VP4fcJdN25e\nwZ4pilKJRu5Kw4gIB/qinBpKNNQ+lc3TP5pgKpld4Z4pilKJiruyKPZvinJiKI4x9RfKPjk0Tb5g\nmJxVcVeU1UbFXVkU126KEk/lGIrXrzFzbGAKgOlUjnyh/s1AUZTlQ8VdWRQH+qIAnBiaLtuezuXn\nCfjxgXjx9XRKo3dFWU1U3JVFcWCTJe4nK8T93Z/8Hr/x1RfLtpWKu1ozirK6qLgri6I9HKAvFuRU\nibhfnJjlxNA0Xz06SMGO3nP5AicG4+zqjgDooKqirDIq7sqiObApVmbLPHVmDICxRLros58dmyGd\nK3D7ni5AxV1RVhsVd2XRXLspSv9ogly+AMBTZ8Zpa/EjAo+fGAHguC3yr9vTDcCkiruirCoq7sqi\nOdAXJZMrcH58BmMMT50Z544DPbxyeztPOOJ+OU7Q5+HmHe3A/Mj9yVOjfPyfT6163xVlo6Diriya\nuUHVBP0jCUan07x2TxdvPNDLv16aYnQ6zfGBONduitIZsUoWxCvE/SvPX+bhJ/rJ2tG/oijLi4q7\nsmj29rbiETg5FOepM+MAvHZPN2+4theAJ06OcHxgiuu3thHyewn5PUxWFBsbT2TIFwyXryQb/t6Z\ntC4SoiiNouKuLJqQ38vO7ggnhqZ56swY2ztb2N4Z5votMfpiQf7q6QvEUzmu3xIDoK3FP8+WGUuk\nARquU3P00iSv+PWvc3a0sdIHirLRUXFXlsS1m6K8NBTn6bMTvHa3NWgqIrzhQC9HL1mDqddvaQOg\nvSUwL8/dqSx5YXy2oe87YZcyqMyvVxSlOiruypLY3xfl4kSSqWSW1+7tKm53rBmvR7jW9uYrI3dj\nDOMzi4vcR+xyBwNT9cseKIqi4q4sEUe4AW7fPSfur9/bTcDrYU9PhJDfC0BbuFzc46kc2bw12en8\nWGPiPhy3bgYDk4179IqykWlI3EXkThE5KSL9IvKRKvt/QUReFJGjIvJNEblm+buqrCcObLL89L29\nrfTGQsXtkaCPn37dTu4+tL24rTJyH7f9dq9HGrZlhu3IfXBKxV1RGqHuYh0i4gUeBt4CXAKeFZHD\nxpjSQiI/AA4ZY2ZF5GeA3wXesxIdVtYHOzrDtIf93LG/Z96+B++6rux9pbiP2X77dZujnByaJpcv\n4PMuHGcMT1s3hMuTassoSiM0ErnfCvQbY84aYzLAF4F3lzYwxjxhjHFCsKeBbcvbTWW94fUI//hf\n/g0ffuuBum3bW/zMZvJkclZOuxO5H7qmk2zeMNiAj+547oNqyyhKQzQi7luBiyXvL9nbavFB4GvV\ndojI/SJyRESOjI6ONt5LZV2ytb2FloC3bru2sB+Ym6U6NmNF7rdc0wHUH1QtFAwj02l8HmE0kS7e\nJBRFqc2yDqiKyE8Ch4Dfq7bfGPOIMeaQMeZQT8/8x3mlOWlrKRd3J3K/xS5NcL6O7z42kyZfMFy3\nOYYxc/67oii1aUTcLwPbS95vs7eVISJvBn4FeJcxJr083VOagUpxH0uk6Qj72dLWQsjv4UKdjJkR\nO1Pmldutm4FmzChKfRoR92eBfSKyS0QCwD3A4dIGInIz8CdYwj6y/N1U3MycuFt2zHgiQ1drEI9H\nuKYzUteWcSJ1pwjZgGbMKEpd6oq7MSYHPAA8BrwEfMkYc1xEPioi77Kb/R7QCnxZRJ4XkcM1Dqds\nQObbMhm67IJi13SF69oyw/Mid7VlFKUedVMhAYwxjwKPVmx7qOT1m5e5X0oT0R62hNwpQTA2k+Y6\nO09+V3eEb50cJV8weD1S9fPD8RQisL0zTEfYr7aMojSAzlBVVpxYyIohSiP37lYnco+QyRcYWmCQ\ndGQ6RVckiN/rYXNbS0Opk4qy0VFxV1Ycn9dDNOhjKpklkyswlczS1RoEYGdXGGDBQdXheJq+mNV+\nS3uLRu6K0gAq7sqqEGvxMzWbZcLOce9yInd7Ae2FfPfheIo+u8TBlvaQiruiNICKu7IqOCUInDru\nXRErEt8cCxHwebiwQMZMZeQeT+VI6MIdirIgKu7KqtBuV4YctyN3x3P3eIQdnWHO1bBlsvkC4zNp\neqNW5L65zfpXyxAoysKouCurQluLn8lktjg7tdv23AF2dkVqVoccnU5jDGxqc2yZFgAuq7gryoKo\nuCurwjxbxo7cwRpUPT8+Q75g5n3OmcBUassAmjGjKHVQcVdWBWfBjrFEhoDPQ2twborF/k1R0rlC\n1ZmqzgQmx5bpiwbxiJYgUJR6qLgrq0Jbi59MrsDlK0m6IwFE5iYsOQtpHx+Iz/vcyLQTuVvi7vN6\n6IuFdJaqotRBxV1ZFdpbLBvmzGiimOPusK83it8rHB+Ymve54XgKr0eK5QrAGlTVyF1RFkbFXVkV\nnPoy58ZmipkyDgGfh/19UV6sErkPx9P0Rq0iYw5b2lt0uT1FqYOKu7IqOOKezhXmRe5gWTPHB+IY\nUz6oOhxPla3RCvYs1anUvLaKosyh4q6sCu32akxQninjcMPWNiZmMvOyYEbiafqi5TeDLW0hMrlC\nMWdeUZT5qLgrq4ITuQN0R6pH7jB/UHV4eq70gMNmJx1SB1UVpSYq7sqqEGtZOHK/dlMMEcoGVVPZ\nPJOz2WKOu8Pe3lYAvnZscIV6qyjuR8VdWRWiQR/OmGh3Fc89EvSxqztSFrmPTts57hWR+56eVn70\nlq18+jtnOTOaqPmdU8ms+vLKhkXFXVkVPB4pRu/VIneA67e0lWXMDMXLc9xLefDt1xHye3noH45V\nFfAXLk1x+299k1/9yrHl6L6iuA4Vd2XVaLfFvVrkDpbvfnkyyRV7oPTMiBWVV9oyAD3RIL/0tgN8\nr3+c/3u03J4Zjqe47y+fJZ0r8NfPvMwzZ8fL9j9xYoQfvHzlqs9HUdYzKu7KquEMqnaEq0fuN2xp\nA+DFwTiJdI4//OZprt0UZV9vtGr7977mGm7c2sZvfvVFzowmMMaQzOS57y+OkEjl+PKHbmdbRwsP\n/p8XSOfyAHz5yEV++s+f5d9/6vt86cjFFThLRVkfNLSGqqIsB7EWP20tfgK+6jGFkzFz7PIUj58Y\nYSie4pPvvaXm2qpej/CbP3wDP/6pp3jTx77Nto4WOsIBjg1M8emfOsQtOzr4zR++gQ/82bP88bfO\nsKenlV/+u6O8fm83IvBLf3uUl8dn+YW37C+bJKUozYCKu7Jq7O6OMJvJ19zfEQmwpS3E4X8d4KXB\nOPfeuoNXXdOx4DFv2t7O4x++g2+dGuXJU6M8e36CX/13B3nzwT4A7jjQyztv2sLDT/RjDBza2cmn\n33cIn1d46B+O8ckn+nlxMM5D7zjITntVKEVpBmStsgkOHTpkjhw5sibfrawNmVyBXKFAOFA7prjv\nL47wjZeG6YoEePzDd9BWMvlpqYxOp3nrJ77NNV0R/uq+1xQrUhpj+LPvnedjXz9JJl/g/bfv5N7X\n7ECAXMHQFwuV5ecrynpARJ4zxhyq207FXVlP/ME3TvEH3zjNJ95zEz9y87ZlO+7kbIZI0IffO98S\nGplO8fGvn+Jvjlyk9L9DW4ufL/zH2zho20WKsh5QcVdcyeh0mm+dHOHHX7WtrCzwanBqeJqjl6bw\ne63v/e2vnSCTK/DF+29jX1/5oG4qm+epM2O8PD7Lj75qG7FQeYSfSOeIBLyrfg5K87Os4i4idwJ/\nCHiBzxhjfrtifxD4S+BVwDjwHmPM+YWOqeKurHfOjc1w9598HwE++4FXk0jneGkwzpHzV/jWyRFm\n7PGD3miQX3vn9dx14yb+38uTfPLx0zxxcpSuSICbd7RzcHOMyWSWc2MzDE2lePPBPj70Q3uqWj7G\nGM6OzXBqaJqXJ2Z5eWK2uBi4AH1tIV67p5tX7+xY0N4CyOULTKdytIaqP7Eo7mTZxF1EvMAp4C3A\nJeBZ4F5jzIslbX4WeIUx5kMicg/wI8aY9yx0XBV3xQ2cHp7mPY88zURJkbLeaJA3H+zjrQf7iIZ8\nPPQPxzk+EGdHZ5iXJ2bpCPu5+9XbGZvO8PzFK5wZnSEasmbgRkM+vtc/TluLn5+9Yw/XbY6RSOeY\nSmb5fxeu8N3+sbLiaR1hK8PIAMbA0FSKTL6A3yts7wxjDOQLBq9HaA36iAS9gLXG7OBkipy9dGEk\n4KU9HKAzEqCrNUBPa5D9fVGu3Rxlf1+USNCHzyN4PYJXpJg9lM0XmE3niaeyHLs8xTPnJnj2/AS5\nvKGrNUBXa5CuSID2sJ/OSICQ34sxhoKhaHGJgFcEv08IeL0UjGEskWY8kSGVzbO5vYVtHS30xUJ4\n7Scdjwd6WoN0tQbnZUsVCqa4ZGMqWyBbKJDLGzrCfja3t9Aa9JHK5jk9nODk8DQ+j7CjK8w1nWEi\n9r5UtkDeGPz2OecKhsnZLFdmMySzeTwieAQ8IuQLhrwxeEToCPvpCAdoC/sRwGDddCMBX0MZV4WC\nYTKZxSuy5PGk5RT324H/YYx5m/3+QQBjzG+VtHnMbvN9EfEBQ0CPWeDgKu6KWzg7muCJk6Ps7olw\n/eYYPdFgmd2Syxf4y+9f4KtHB7jrxs289zU7yqLqdC5PwOspfub4wBS/+08n+fap0bLvaWvx87q9\nXbx+bw+v2NbGjq7wPLsnmcnz7PkJvndmjEsTSTwewSuQNzCTzpFI5SgYw9YOSzA7I0ESKevmMZnM\nMDGTYTyRYSieKpZ3qIVHoHJZ2xa/l1uuaScS8DE+k2E8kWZiJkM8lVv079XrEfxeIZUtLNimKxLA\n6xGMwRbhTPGmVY1oyMdMOjev7yuJR6xU32jIRzZnmM3kSOUKBL0ewkEvLX4viXSeK7MZ8gXDf3rD\nHn7xbdcu6buWU9x/HLjTGHOf/f6ngNcYYx4oaXPMbnPJfn/GbjNWcaz7gfsBduzY8aoLFy4s7qwU\npYk4PjDFbCZPNOQjGvKzKRaqmdO/EkzMZDgxGKd/NEE6WyBXMOTyVkRbsKPVkM9LOOgjEvCyry/K\njVvbqs5TyOULXJnNks45Ua8gMhe95woFsnlDJldABLoiATrCAURgcjbLpStJRqZTZe1Hp9MMxVOM\nTWco2JGzx2NNguuJWlF92O/F5xV8Hg8TsxkGJpMMTiZpCwe4dpP1VGKM4eWJWS6Mz5LK5Qn5vIT8\nXrwe62bhPPm0t1hPIC0BL8ZAwf49eD3Wk0yhYLgym+XKTIapZBawnkoKxjCdyjE5m2U6lSXg8xAO\n+Aj6PWRy1pPPbDZPa9BHl/3kdPOODl65vX1J161RcV/VPHdjzCPAI2BF7qv53Yqy3rjenpG7VnRG\nArx2bzev3dt91cfyeT30RKuXlahHRyRARyQArNzvo3JAfCPQyCjLZWB7yftt9raqbWxbpg1rYFVR\nFEVZAxoR92eBfSKyS0QCwD3A4Yo2h4H3269/HHh8Ib9dURRFWVnq2jLGmJyIPAA8hpUK+VljzHER\n+ShwxBhzGPhT4HMi0g9MYN0AFEVRlDWiIc/dGPMo8GjFtodKXqeAf7+8XVMURVGWis5sUBRFaUJU\n3BVFUZoQFXdFUZQmRMVdURSlCVmzqpAiMgosdYpqNzBWt1XzsRHPeyOeM2zM896I5wyLP+9rjDE9\n9RqtmbhfDSJypJHpt83GRjzvjXjOsDHPeyOeM6zceastoyiK0oSouCuKojQhbhX3R9a6A2vERjzv\njXjOsDHPeyOeM6zQebvSc1cURVEWxq2Ru6IoirIAKu6KoihNiOvEXUTuFJGTItIvIh9Z6/5cDSKy\nXUSeEJEXReS4iPycvb1TRP5ZRE7b/3bY20VE/sg+96MickvJsd5vtz8tIu+v9Z3rBRHxisgPROSr\n9vtdIvKMfW5/Y5eXRkSC9vt+e//OkmM8aG8/KSJvW5szaRwRaReRvxWREyLykojc3uzXWkR+3v7b\nPiYiXxCRUDNeaxH5rIiM2KvSOduW7dqKyKtE5AX7M38kIvWX7DLGuOYHq+TwGWA3EAD+FTi41v26\nivPZDNxiv45iLUR+EPhd4CP29o8Av2O/vgv4GtaavLcBz9jbO4Gz9r8d9uuOtT6/Ouf+C8Dnga/a\n778E3GO//hTwM/brnwU+Zb++B/gb+/VB+/oHgV3234V3rc+rzjn/BXCf/ToAtDfztQa2AueAlpJr\n/IFmvNbAvwVuAY6VbFu2awv8i91W7M++vW6f1vqXsshf4O3AYyXvHwQeXOt+LeP5/QPwFuAksNne\nthk4ab/+E+DekvYn7f33An9Ssr2s3Xr7wVrN65vAG4Gv2n+wY4Cv8jpjrSNwu/3aZ7eTymtf2m49\n/mCtTnYOO4mh8ho247W2xf2iLVY++1q/rVmvNbCzQtyX5dra+06UbC9rV+vHbbaM88ficMne5nrs\nR9CbgWeAPmPMoL1rCOizX9c6f7f9Xv4A+CXAWfa+C5g0xuTs96X9L56bvX/Kbu+2c94FjAJ/ZttR\nnxGRCE18rY0xl4HfB14GBrGu3XM0/7V2WK5ru9V+Xbl9Qdwm7k2JiLQCfwf8V2NMvHSfsW7VTZOv\nKiLvAEaMMc+tdV9WGR/WY/sfG2NuBmawHtWLNOG17gDejXVj2wJEgDvXtFNrxFpcW7eJeyOLdbsK\nEfFjCftfG2P+3t48LCKb7f2bgRF7e63zd9Pv5XXAu0TkPPBFLGvmD4F2sRZXh/L+11p83U3nDFa0\ndckY84z9/m+xxL6Zr/WbgXPGmFFjTBb4e6zr3+zX2mG5ru1l+3Xl9gVxm7g3sli3a7BHvP8UeMkY\n8/GSXaULjr8fy4t3tr/PHm2/DZiyH/seA94qIh12tPRWe9u6wxjzoDFmmzFmJ9b1e9wY8xPAE1iL\nq8P8c662+Pph4B47w2IXsA9r0GldYowZAi6KyAF705uAF2nia41lx9wmImH7b90556a+1iUsy7W1\n98VF5Db79/i+kmPVZq0HIZYwaHEXVlbJGeBX1ro/V3kur8d6VDsKPG//3IXlM34TOA18A+i02wvw\nsH3uLwCHSo71H4B+++en1/rcGjz/O5jLltmN9R+2H/gyELS3h+z3/fb+3SWf/xX7d3GSBrIH1voH\neCVwxL7eX8HKiGjqaw38OnACOAZ8DivjpemuNfAFrHGFLNZT2geX89oCh+zf4Rngk1QMzFf70fID\niqIoTYjbbBlFURSlAVTcFUVRmhAVd0VRlCZExV1RFKUJUXFXFEVpQlTcFUVRmhAVd0VRlCbk/wM+\nN1/rDgFR0AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_1JdGB-fh-9",
        "colab_type": "text"
      },
      "source": [
        "## [try] 中間層の活性化関数を変更してみよう(Sigmoid ➡ ReLU)\n",
        "ReLU(勾配爆発を確認しよう)<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGJ41UR-fkVi",
        "colab_type": "code",
        "outputId": "3859a3d0-1c7c-4e1e-858d-35f65dd1fc74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "def d_tanh(x):\n",
        "    return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "\n",
        "# He\n",
        "#W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "#W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "#W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)# Xavier\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "#        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "        z[:,t+1] = functions.relu(u[:,t+1])\n",
        "#        z[:,t+1] = np.tanh(u[:,t+1]) \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "#        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "#        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1]) \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:1.1463935269891867\n",
            "Pred:[1 1 1 1 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "116 + 58 = 254\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.0006923299540942\n",
            "Pred:[0 0 0 0 0 1 0 1]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "111 + 98 = 5\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.0046344308071202\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "2 + 95 = 2\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/【E資格】深層学習/DNN_code/common/functions.py:6: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1 + np.exp(-x))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iters:300\n",
            "Loss:1.1899275196059356\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[1 1 0 1 1 0 0 0]\n",
            "101 + 115 = 4\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.1713181572828402\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "67 + 97 = 2\n",
            "------------\n",
            "iters:500\n",
            "Loss:0.8113068938849222\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "76 + 51 = 68\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.158183402941313\n",
            "Pred:[0 0 1 0 0 0 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "113 + 28 = 33\n",
            "------------\n",
            "iters:700\n",
            "Loss:1.0001730527590387\n",
            "Pred:[0 0 0 1 0 0 0 0]\n",
            "True:[1 1 1 0 0 0 0 0]\n",
            "113 + 111 = 16\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.8454715492890295\n",
            "Pred:[0 0 0 1 0 0 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "23 + 102 = 17\n",
            "------------\n",
            "iters:900\n",
            "Loss:1.173361622758589\n",
            "Pred:[0 0 1 0 1 0 0 0]\n",
            "True:[1 0 0 0 0 0 0 0]\n",
            "42 + 86 = 40\n",
            "------------\n",
            "iters:1000\n",
            "Loss:1.2662877170766023\n",
            "Pred:[0 0 0 1 0 0 1 0]\n",
            "True:[0 1 1 0 1 0 0 0]\n",
            "63 + 41 = 18\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.9709704311285361\n",
            "Pred:[0 1 0 0 1 0 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "93 + 4 = 73\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.7836833120404786\n",
            "Pred:[0 1 0 0 1 0 1 0]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "78 + 1 = 74\n",
            "------------\n",
            "iters:1300\n",
            "Loss:1.0977493950131325\n",
            "Pred:[0 1 0 0 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "108 + 40 = 68\n",
            "------------\n",
            "iters:1400\n",
            "Loss:1.0645676735894394\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 1 0 0]\n",
            "124 + 64 = 0\n",
            "------------\n",
            "iters:1500\n",
            "Loss:1.0412155177259677\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "12 + 103 = 8\n",
            "------------\n",
            "iters:1600\n",
            "Loss:0.9078179241285859\n",
            "Pred:[0 0 1 0 0 0 0 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "32 + 14 = 32\n",
            "------------\n",
            "iters:1700\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 1 1 1 0]\n",
            "79 + 127 = 0\n",
            "------------\n",
            "iters:1800\n",
            "Loss:1.2593241591480353\n",
            "Pred:[0 0 1 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "41 + 25 = 32\n",
            "------------\n",
            "iters:1900\n",
            "Loss:1.1754252669187628\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 0 1 0]\n",
            "101 + 53 = 64\n",
            "------------\n",
            "iters:2000\n",
            "Loss:1.2418524392360124\n",
            "Pred:[0 0 1 0 1 0 0 0]\n",
            "True:[0 1 0 1 0 1 1 0]\n",
            "63 + 23 = 40\n",
            "------------\n",
            "iters:2100\n",
            "Loss:0.9818549237480038\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "124 + 61 = 0\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.8392847152255007\n",
            "Pred:[0 1 0 0 0 0 0 1]\n",
            "True:[0 1 0 1 0 0 1 1]\n",
            "73 + 10 = 65\n",
            "------------\n",
            "iters:2300\n",
            "Loss:1.0651249809581986\n",
            "Pred:[0 0 0 1 0 0 0 0]\n",
            "True:[1 0 1 0 0 1 0 1]\n",
            "56 + 109 = 16\n",
            "------------\n",
            "iters:2400\n",
            "Loss:1.1961738667336075\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "74 + 36 = 0\n",
            "------------\n",
            "iters:2500\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 0 1 0]\n",
            "43 + 47 = 0\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.8083460658380126\n",
            "Pred:[0 0 0 0 0 1 0 1]\n",
            "True:[1 1 1 0 1 1 1 1]\n",
            "125 + 114 = 5\n",
            "------------\n",
            "iters:2700\n",
            "Loss:1.019907267295904\n",
            "Pred:[0 0 1 0 0 0 0 0]\n",
            "True:[1 1 0 1 0 1 1 1]\n",
            "120 + 95 = 32\n",
            "------------\n",
            "iters:2800\n",
            "Loss:1.0084428125464986\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[1 0 1 1 1 0 0 0]\n",
            "67 + 117 = 2\n",
            "------------\n",
            "iters:2900\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "3 + 63 = 0\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.9250599482515209\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "6 + 89 = 2\n",
            "------------\n",
            "iters:3100\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "88 + 121 = 0\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.8733190523574914\n",
            "Pred:[0 0 1 0 1 0 1 0]\n",
            "True:[1 0 1 1 1 1 1 0]\n",
            "126 + 64 = 42\n",
            "------------\n",
            "iters:3300\n",
            "Loss:1.1669923611310047\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[0 1 0 0 0 0 0 1]\n",
            "26 + 39 = 8\n",
            "------------\n",
            "iters:3400\n",
            "Loss:1.1520294616280187\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 1 1 0 0]\n",
            "117 + 55 = 64\n",
            "------------\n",
            "iters:3500\n",
            "Loss:1.1184465970784967\n",
            "Pred:[0 0 0 1 0 0 1 0]\n",
            "True:[1 1 1 0 1 0 0 0]\n",
            "123 + 109 = 18\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.9748917799812007\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "69 + 75 = 0\n",
            "------------\n",
            "iters:3700\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 0 1 0 1 1 0]\n",
            "0 + 22 = 0\n",
            "------------\n",
            "iters:3800\n",
            "Loss:1.0425632777911096\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "75 + 13 = 66\n",
            "------------\n",
            "iters:3900\n",
            "Loss:1.053658580226681\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "15 + 103 = 8\n",
            "------------\n",
            "iters:4000\n",
            "Loss:1.144764821707662\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 1 0 0 0]\n",
            "22 + 114 = 4\n",
            "------------\n",
            "iters:4100\n",
            "Loss:1.003684966182811\n",
            "Pred:[0 0 0 1 0 0 0 1]\n",
            "True:[0 0 1 0 0 1 1 1]\n",
            "27 + 12 = 17\n",
            "------------\n",
            "iters:4200\n",
            "Loss:1.0012879431966464\n",
            "Pred:[0 1 0 0 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 1 1]\n",
            "120 + 51 = 72\n",
            "------------\n",
            "iters:4300\n",
            "Loss:1.15385194933976\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 1 1 1 1]\n",
            "87 + 72 = 0\n",
            "------------\n",
            "iters:4400\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "68 + 70 = 0\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.9396852865805225\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[1 0 1 1 0 1 1 1]\n",
            "60 + 123 = 4\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.8536951759654647\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "44 + 81 = 36\n",
            "------------\n",
            "iters:4700\n",
            "Loss:1.2242021456886323\n",
            "Pred:[0 0 0 1 0 1 0 0]\n",
            "True:[1 1 1 0 0 0 0 0]\n",
            "117 + 107 = 20\n",
            "------------\n",
            "iters:4800\n",
            "Loss:1.0066247766596825\n",
            "Pred:[0 0 0 0 0 1 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "55 + 50 = 5\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.9284735512690644\n",
            "Pred:[0 1 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 0 1 0]\n",
            "67 + 7 = 64\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.9535726961000232\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[1 1 0 0 1 0 1 0]\n",
            "105 + 97 = 8\n",
            "------------\n",
            "iters:5100\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 0 1 1 0 0]\n",
            "2 + 42 = 0\n",
            "------------\n",
            "iters:5200\n",
            "Loss:0.9110978397749356\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[0 0 1 1 0 1 1 0]\n",
            "4 + 50 = 4\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.9611163449130478\n",
            "Pred:[0 1 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "95 + 48 = 69\n",
            "------------\n",
            "iters:5400\n",
            "Loss:1.0343760252532213\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "112 + 33 = 80\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.9345159989145734\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[0 0 1 0 1 1 0 0]\n",
            "26 + 18 = 8\n",
            "------------\n",
            "iters:5600\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 1 1 1 0]\n",
            "67 + 75 = 0\n",
            "------------\n",
            "iters:5700\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "15 + 95 = 0\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.9664846313431645\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[1 0 1 0 1 0 0 1]\n",
            "88 + 81 = 8\n",
            "------------\n",
            "iters:5900\n",
            "Loss:1.1055312491313103\n",
            "Pred:[0 0 1 0 0 1 0 0]\n",
            "True:[1 1 0 1 1 0 0 0]\n",
            "126 + 90 = 36\n",
            "------------\n",
            "iters:6000\n",
            "Loss:1.0981448057462229\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[1 0 1 1 0 0 0 0]\n",
            "119 + 57 = 66\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.9245266682605877\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "27 + 122 = 1\n",
            "------------\n",
            "iters:6200\n",
            "Loss:1.1417737015403275\n",
            "Pred:[0 1 0 0 1 0 0 1]\n",
            "True:[1 0 1 1 0 0 0 1]\n",
            "123 + 54 = 73\n",
            "------------\n",
            "iters:6300\n",
            "Loss:1.0147581135047403\n",
            "Pred:[0 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 1]\n",
            "78 + 69 = 10\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.9306872827313435\n",
            "Pred:[0 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "79 + 64 = 5\n",
            "------------\n",
            "iters:6500\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "64 + 67 = 0\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.9611930070643943\n",
            "Pred:[0 0 1 0 1 0 0 1]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "121 + 86 = 41\n",
            "------------\n",
            "iters:6700\n",
            "Loss:1.036865233181203\n",
            "Pred:[0 0 0 1 0 1 0 0]\n",
            "True:[1 0 1 0 0 0 0 0]\n",
            "93 + 67 = 20\n",
            "------------\n",
            "iters:6800\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "81 + 93 = 0\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.8925385476337483\n",
            "Pred:[0 0 0 0 0 0 0 1]\n",
            "True:[1 0 1 0 1 1 0 1]\n",
            "71 + 102 = 1\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.7500000031250869\n",
            "Pred:[0 0 0 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 1 1]\n",
            "55 + 48 = 5\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.75\n",
            "Pred:[0 1 0 0 0 0 0 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "85 + 30 = 65\n",
            "------------\n",
            "iters:7200\n",
            "Loss:1.25\n",
            "Pred:[0 0 0 0 1 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "14 + 100 = 10\n",
            "------------\n",
            "iters:7300\n",
            "Loss:1.7499987316212242\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 0 1 1 1 1]\n",
            "46 + 33 = 0\n",
            "------------\n",
            "iters:7400\n",
            "Loss:1.25\n",
            "Pred:[0 0 1 0 0 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "50 + 80 = 34\n",
            "------------\n",
            "iters:7500\n",
            "Loss:1.496620175370102\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 1 1 0]\n",
            "44 + 18 = 0\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.8973403517405814\n",
            "Pred:[0 0 1 0 0 0 0 0]\n",
            "True:[0 0 1 1 1 0 1 0]\n",
            "36 + 22 = 32\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.7500000000914697\n",
            "Pred:[0 0 1 0 0 0 1 0]\n",
            "True:[0 0 1 1 1 0 1 1]\n",
            "46 + 13 = 34\n",
            "------------\n",
            "iters:7800\n",
            "Loss:1.2499998500180707\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "118 + 67 = 0\n",
            "------------\n",
            "iters:7900\n",
            "Loss:1.125\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 1 0 1 0 0 0 1]\n",
            "127 + 82 = 0\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.625\n",
            "Pred:[0 1 0 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "84 + 35 = 84\n",
            "------------\n",
            "iters:8100\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "6 + 127 = 0\n",
            "------------\n",
            "iters:8200\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 0 1]\n",
            "92 + 93 = 0\n",
            "------------\n",
            "iters:8300\n",
            "Loss:1.3749998642546926\n",
            "Pred:[0 0 0 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 0 0]\n",
            "39 + 57 = 2\n",
            "------------\n",
            "iters:8400\n",
            "Loss:1.37499999999958\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "35 + 11 = 0\n",
            "------------\n",
            "iters:8500\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "3 + 127 = 0\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.625\n",
            "Pred:[0 0 0 1 0 1 0 1]\n",
            "True:[0 0 1 1 1 1 0 1]\n",
            "61 + 0 = 21\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.7500000034752063\n",
            "Pred:[0 1 0 0 0 0 0 1]\n",
            "True:[0 1 0 1 0 1 1 1]\n",
            "73 + 14 = 65\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.75\n",
            "Pred:[0 0 0 1 0 0 0 1]\n",
            "True:[0 1 1 1 1 0 1 1]\n",
            "19 + 104 = 17\n",
            "------------\n",
            "iters:8900\n",
            "Loss:2.123319920857745\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 1 0 1 1 1 1 1]\n",
            "61 + 34 = 0\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.875\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "72 + 85 = 8\n",
            "------------\n",
            "iters:9100\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "59 + 127 = 0\n",
            "------------\n",
            "iters:9200\n",
            "Loss:1.249998676820237\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 1 1 0 0 0 0]\n",
            "42 + 6 = 0\n",
            "------------\n",
            "iters:9300\n",
            "Loss:1.0\n",
            "Pred:[0 0 0 0 0 0 0 0]\n",
            "True:[0 0 0 1 0 0 1 0]\n",
            "1 + 17 = 0\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.8750000000008518\n",
            "Pred:[0 0 0 0 1 0 0 0]\n",
            "True:[1 0 1 1 1 0 1 0]\n",
            "72 + 114 = 8\n",
            "------------\n",
            "iters:9500\n",
            "Loss:1.7499999841878209\n",
            "Pred:[0 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "43 + 101 = 10\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.875\n",
            "Pred:[0 0 0 0 0 1 0 0]\n",
            "True:[0 0 1 0 1 1 1 0]\n",
            "12 + 34 = 4\n",
            "------------\n",
            "iters:9700\n",
            "Loss:1.0000184540712127\n",
            "Pred:[0 0 1 0 0 0 0 1]\n",
            "True:[0 1 0 0 1 0 0 1]\n",
            "51 + 22 = 33\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.6250000000011587\n",
            "Pred:[0 1 0 1 0 0 0 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "113 + 14 = 81\n",
            "------------\n",
            "iters:9900\n",
            "Loss:1.749999999999992\n",
            "Pred:[0 0 0 1 0 1 0 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "63 + 43 = 20\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE8LBnWEYpgnh4M4wDNOEcHBnGIZpQv5/M3UVNdwCojkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHgY1OhgrFz2",
        "colab_type": "text"
      },
      "source": [
        "## [try] 中間層の活性化関数を変更してみよう(Sigmoid ➡　Tanh)\n",
        "tanh(numpyにtanhが用意されている。導関数をd_tanhとして作成しよう)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNegCERrrGno",
        "colab_type": "code",
        "outputId": "19384f8a-6f94-4151-ae0a-8d8e8cc32ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from common import functions\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# def d_tanh(x):\n",
        "def d_tanh(x):\n",
        "  return 1/(np.cosh(x) ** 2)\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
        "\n",
        "input_layer_size = 2\n",
        "hidden_layer_size = 16\n",
        "output_layer_size = 1\n",
        "\n",
        "weight_init_std = 1\n",
        "learning_rate = 0.1\n",
        "\n",
        "iters_num = 10000\n",
        "plot_interval = 100\n",
        "\n",
        "# ウェイト初期化 (バイアスは簡単のため省略)\n",
        "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
        "\n",
        "# Xavier\n",
        "# W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size))\n",
        "# W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "# W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size))\n",
        "\n",
        "# He\n",
        "#W_in = np.random.randn(input_layer_size, hidden_layer_size) / (np.sqrt(input_layer_size)) * np.sqrt(2)\n",
        "#W_out = np.random.randn(hidden_layer_size, output_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)\n",
        "#W = np.random.randn(hidden_layer_size, hidden_layer_size) / (np.sqrt(hidden_layer_size)) * np.sqrt(2)# Xavier\n",
        "\n",
        "\n",
        "\n",
        "# 勾配\n",
        "W_in_grad = np.zeros_like(W_in)\n",
        "W_out_grad = np.zeros_like(W_out)\n",
        "W_grad = np.zeros_like(W)\n",
        "\n",
        "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "y = np.zeros((output_layer_size, binary_dim))\n",
        "\n",
        "delta_out = np.zeros((output_layer_size, binary_dim))\n",
        "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
        "\n",
        "all_losses = []\n",
        "\n",
        "for i in range(iters_num):\n",
        "    \n",
        "    # A, B初期化 (a + b = d)\n",
        "    a_int = np.random.randint(largest_number/2)\n",
        "    a_bin = binary[a_int] # binary encoding\n",
        "    b_int = np.random.randint(largest_number/2)\n",
        "    b_bin = binary[b_int] # binary encoding\n",
        "    \n",
        "    # 正解データ\n",
        "    d_int = a_int + b_int\n",
        "    d_bin = binary[d_int]\n",
        "    \n",
        "    # 出力バイナリ\n",
        "    out_bin = np.zeros_like(d_bin)\n",
        "    \n",
        "    # 時系列全体の誤差\n",
        "    all_loss = 0    \n",
        "    \n",
        "    # 時系列ループ\n",
        "    for t in range(binary_dim):\n",
        "        # 入力値\n",
        "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
        "        # 時刻tにおける正解データ\n",
        "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
        "        \n",
        "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
        "#        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
        "#        z[:,t+1] = functions.relu(u[:,t+1])\n",
        "        z[:,t+1] = np.tanh(u[:,t+1]) \n",
        "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
        "\n",
        "\n",
        "        #誤差\n",
        "        loss = functions.mean_squared_error(dd, y[:,t])\n",
        "        \n",
        "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
        "        \n",
        "        all_loss += loss\n",
        "\n",
        "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
        "    \n",
        "    \n",
        "    for t in range(binary_dim)[::-1]:\n",
        "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
        "\n",
        "#        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
        "#        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_relu(u[:,t+1])\n",
        "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * d_tanh(u[:,t+1]) \n",
        "\n",
        "        # 勾配更新\n",
        "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
        "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
        "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
        "    \n",
        "    # 勾配適用\n",
        "    W_in -= learning_rate * W_in_grad\n",
        "    W_out -= learning_rate * W_out_grad\n",
        "    W -= learning_rate * W_grad\n",
        "    \n",
        "    W_in_grad *= 0\n",
        "    W_out_grad *= 0\n",
        "    W_grad *= 0\n",
        "    \n",
        "\n",
        "    if(i % plot_interval == 0):\n",
        "        all_losses.append(all_loss)        \n",
        "        print(\"iters:\" + str(i))\n",
        "        print(\"Loss:\" + str(all_loss))\n",
        "        print(\"Pred:\" + str(out_bin))\n",
        "        print(\"True:\" + str(d_bin))\n",
        "        out_int = 0\n",
        "        for index,x in enumerate(reversed(out_bin)):\n",
        "            out_int += x * pow(2, index)\n",
        "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
        "        print(\"------------\")\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, all_losses, label=\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iters:0\n",
            "Loss:1.3681241041559222\n",
            "Pred:[0 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 1 1 1 0]\n",
            "113 + 45 = 18\n",
            "------------\n",
            "iters:100\n",
            "Loss:1.5160197040658963\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "44 + 73 = 170\n",
            "------------\n",
            "iters:200\n",
            "Loss:1.0868501572631697\n",
            "Pred:[1 0 1 0 1 0 1 1]\n",
            "True:[1 0 0 1 0 0 0 1]\n",
            "116 + 29 = 171\n",
            "------------\n",
            "iters:300\n",
            "Loss:0.8319867304105574\n",
            "Pred:[0 1 1 1 1 0 1 1]\n",
            "True:[1 0 1 1 1 0 1 1]\n",
            "113 + 74 = 123\n",
            "------------\n",
            "iters:400\n",
            "Loss:1.1231596417663074\n",
            "Pred:[0 0 0 1 0 0 0 0]\n",
            "True:[1 1 1 1 1 0 0 0]\n",
            "122 + 126 = 16\n",
            "------------\n",
            "iters:500\n",
            "Loss:1.0352396617654975\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "50 + 106 = 52\n",
            "------------\n",
            "iters:600\n",
            "Loss:1.0859957399604956\n",
            "Pred:[1 1 1 0 1 1 1 1]\n",
            "True:[1 0 0 1 1 1 0 1]\n",
            "122 + 35 = 239\n",
            "------------\n",
            "iters:700\n",
            "Loss:0.8737286763969138\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[1 1 0 0 0 1 0 1]\n",
            "105 + 92 = 125\n",
            "------------\n",
            "iters:800\n",
            "Loss:0.9609904161738397\n",
            "Pred:[0 0 1 0 1 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "63 + 88 = 47\n",
            "------------\n",
            "iters:900\n",
            "Loss:1.1017851948356505\n",
            "Pred:[0 1 0 1 0 0 0 1]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "83 + 73 = 81\n",
            "------------\n",
            "iters:1000\n",
            "Loss:0.8225292283188059\n",
            "Pred:[0 0 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 0 0 1]\n",
            "36 + 61 = 37\n",
            "------------\n",
            "iters:1100\n",
            "Loss:0.7329814593580677\n",
            "Pred:[1 1 1 0 0 0 1 1]\n",
            "True:[1 1 1 0 0 1 0 1]\n",
            "111 + 118 = 227\n",
            "------------\n",
            "iters:1200\n",
            "Loss:0.8512369425820774\n",
            "Pred:[0 0 0 1 0 1 0 1]\n",
            "True:[0 1 0 0 1 1 0 1]\n",
            "48 + 29 = 21\n",
            "------------\n",
            "iters:1300\n",
            "Loss:0.6788682975221172\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "86 + 12 = 66\n",
            "------------\n",
            "iters:1400\n",
            "Loss:0.7710711316327067\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "42 + 60 = 114\n",
            "------------\n",
            "iters:1500\n",
            "Loss:0.9621512716603127\n",
            "Pred:[1 0 1 0 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "103 + 9 = 162\n",
            "------------\n",
            "iters:1600\n",
            "Loss:1.036026410299417\n",
            "Pred:[0 1 0 0 0 0 0 1]\n",
            "True:[1 0 1 0 1 0 0 1]\n",
            "103 + 66 = 65\n",
            "------------\n",
            "iters:1700\n",
            "Loss:1.0114656222039524\n",
            "Pred:[1 1 1 1 0 1 0 1]\n",
            "True:[0 0 1 1 1 0 0 1]\n",
            "22 + 35 = 245\n",
            "------------\n",
            "iters:1800\n",
            "Loss:0.7542865211600944\n",
            "Pred:[1 1 1 0 1 1 0 1]\n",
            "True:[1 0 0 0 1 1 0 1]\n",
            "100 + 41 = 237\n",
            "------------\n",
            "iters:1900\n",
            "Loss:0.9123518811032886\n",
            "Pred:[0 1 0 1 0 0 1 0]\n",
            "True:[0 1 1 0 1 0 1 0]\n",
            "84 + 22 = 82\n",
            "------------\n",
            "iters:2000\n",
            "Loss:0.6823443107133732\n",
            "Pred:[1 0 1 0 1 1 1 0]\n",
            "True:[1 0 1 0 1 0 1 0]\n",
            "61 + 109 = 174\n",
            "------------\n",
            "iters:2100\n",
            "Loss:1.0195987916931772\n",
            "Pred:[0 0 1 0 1 1 0 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "104 + 15 = 45\n",
            "------------\n",
            "iters:2200\n",
            "Loss:0.7504059880956291\n",
            "Pred:[1 0 1 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "124 + 14 = 170\n",
            "------------\n",
            "iters:2300\n",
            "Loss:0.41502238517827317\n",
            "Pred:[0 1 1 0 0 1 1 0]\n",
            "True:[0 1 1 0 0 1 1 0]\n",
            "36 + 66 = 102\n",
            "------------\n",
            "iters:2400\n",
            "Loss:0.8367399074030921\n",
            "Pred:[1 1 0 0 0 0 0 0]\n",
            "True:[1 0 0 1 0 0 0 0]\n",
            "76 + 68 = 192\n",
            "------------\n",
            "iters:2500\n",
            "Loss:0.6679807957934913\n",
            "Pred:[0 0 0 1 1 0 1 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "39 + 27 = 26\n",
            "------------\n",
            "iters:2600\n",
            "Loss:0.6534765363315381\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[1 0 0 1 0 1 0 0]\n",
            "98 + 50 = 52\n",
            "------------\n",
            "iters:2700\n",
            "Loss:0.521639786932895\n",
            "Pred:[0 0 1 0 0 0 0 0]\n",
            "True:[0 0 1 0 0 0 0 0]\n",
            "8 + 24 = 32\n",
            "------------\n",
            "iters:2800\n",
            "Loss:0.7678437059946919\n",
            "Pred:[0 0 0 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "104 + 8 = 16\n",
            "------------\n",
            "iters:2900\n",
            "Loss:1.2433787476873737\n",
            "Pred:[0 1 0 0 0 1 0 1]\n",
            "True:[0 1 1 1 1 1 0 1]\n",
            "81 + 44 = 69\n",
            "------------\n",
            "iters:3000\n",
            "Loss:0.6497954954621608\n",
            "Pred:[1 1 1 0 1 0 0 1]\n",
            "True:[1 1 0 0 1 1 0 1]\n",
            "107 + 98 = 233\n",
            "------------\n",
            "iters:3100\n",
            "Loss:1.0994311319180596\n",
            "Pred:[1 0 0 1 0 0 1 1]\n",
            "True:[0 1 1 1 1 1 1 1]\n",
            "15 + 112 = 147\n",
            "------------\n",
            "iters:3200\n",
            "Loss:0.5922972029210612\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 0 1 1]\n",
            "52 + 63 = 87\n",
            "------------\n",
            "iters:3300\n",
            "Loss:0.7680102482406921\n",
            "Pred:[0 1 1 1 1 0 0 0]\n",
            "True:[0 0 1 0 1 1 0 0]\n",
            "35 + 9 = 120\n",
            "------------\n",
            "iters:3400\n",
            "Loss:0.5040557693759874\n",
            "Pred:[0 1 1 1 1 1 0 1]\n",
            "True:[0 0 1 1 0 1 0 1]\n",
            "40 + 13 = 125\n",
            "------------\n",
            "iters:3500\n",
            "Loss:0.5266786060078464\n",
            "Pred:[1 1 0 1 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "64 + 79 = 223\n",
            "------------\n",
            "iters:3600\n",
            "Loss:0.8409303142939284\n",
            "Pred:[0 1 0 0 1 1 0 0]\n",
            "True:[1 0 0 1 1 1 0 0]\n",
            "101 + 55 = 76\n",
            "------------\n",
            "iters:3700\n",
            "Loss:0.5813347228255271\n",
            "Pred:[0 1 0 1 1 1 1 0]\n",
            "True:[0 1 0 0 0 1 1 0]\n",
            "4 + 66 = 94\n",
            "------------\n",
            "iters:3800\n",
            "Loss:0.7736162138940231\n",
            "Pred:[0 1 0 1 0 1 1 1]\n",
            "True:[1 0 1 1 1 1 1 1]\n",
            "113 + 78 = 87\n",
            "------------\n",
            "iters:3900\n",
            "Loss:0.4393199633451963\n",
            "Pred:[1 0 1 0 1 0 1 1]\n",
            "True:[1 0 0 0 1 0 1 1]\n",
            "35 + 104 = 171\n",
            "------------\n",
            "iters:4000\n",
            "Loss:0.4634708577154618\n",
            "Pred:[1 1 0 0 0 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "103 + 31 = 198\n",
            "------------\n",
            "iters:4100\n",
            "Loss:0.6482282777861148\n",
            "Pred:[1 1 1 0 1 0 1 0]\n",
            "True:[1 0 0 0 0 0 1 0]\n",
            "88 + 42 = 234\n",
            "------------\n",
            "iters:4200\n",
            "Loss:0.6308657868666767\n",
            "Pred:[0 0 0 1 1 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "58 + 93 = 31\n",
            "------------\n",
            "iters:4300\n",
            "Loss:0.5582889209419815\n",
            "Pred:[1 1 0 1 1 1 1 0]\n",
            "True:[1 1 0 0 1 1 1 0]\n",
            "116 + 90 = 222\n",
            "------------\n",
            "iters:4400\n",
            "Loss:0.37745762719255616\n",
            "Pred:[0 1 1 1 0 1 1 0]\n",
            "True:[0 1 1 1 0 1 1 0]\n",
            "61 + 57 = 118\n",
            "------------\n",
            "iters:4500\n",
            "Loss:0.33877147118925766\n",
            "Pred:[1 0 0 0 1 1 0 0]\n",
            "True:[1 0 0 0 1 1 0 0]\n",
            "109 + 31 = 140\n",
            "------------\n",
            "iters:4600\n",
            "Loss:0.5899272970461176\n",
            "Pred:[0 1 0 1 0 0 0 0]\n",
            "True:[0 1 0 1 1 0 0 0]\n",
            "42 + 46 = 80\n",
            "------------\n",
            "iters:4700\n",
            "Loss:0.16108123533487878\n",
            "Pred:[0 1 1 0 0 0 1 1]\n",
            "True:[0 1 1 0 0 0 1 1]\n",
            "40 + 59 = 99\n",
            "------------\n",
            "iters:4800\n",
            "Loss:0.10023319596790006\n",
            "Pred:[1 1 0 0 1 1 0 0]\n",
            "True:[1 1 0 0 1 1 0 0]\n",
            "79 + 125 = 204\n",
            "------------\n",
            "iters:4900\n",
            "Loss:0.4137715622572473\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "9 + 108 = 119\n",
            "------------\n",
            "iters:5000\n",
            "Loss:0.6308551076480178\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[0 0 0 1 0 1 0 0]\n",
            "1 + 19 = 180\n",
            "------------\n",
            "iters:5100\n",
            "Loss:0.13955922525711764\n",
            "Pred:[0 1 1 0 1 1 1 0]\n",
            "True:[0 1 1 0 1 1 1 0]\n",
            "4 + 106 = 110\n",
            "------------\n",
            "iters:5200\n",
            "Loss:1.4276371767363005\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[1 1 0 1 0 1 1 0]\n",
            "127 + 87 = 126\n",
            "------------\n",
            "iters:5300\n",
            "Loss:0.6900139445885243\n",
            "Pred:[0 0 1 1 0 1 0 0]\n",
            "True:[1 0 1 0 0 1 0 0]\n",
            "46 + 118 = 52\n",
            "------------\n",
            "iters:5400\n",
            "Loss:0.5909307769789158\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "57 + 54 = 119\n",
            "------------\n",
            "iters:5500\n",
            "Loss:0.02855929291057855\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "23 + 75 = 98\n",
            "------------\n",
            "iters:5600\n",
            "Loss:0.4573307555712953\n",
            "Pred:[1 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "31 + 67 = 226\n",
            "------------\n",
            "iters:5700\n",
            "Loss:0.01700658807709795\n",
            "Pred:[0 1 1 1 0 1 1 1]\n",
            "True:[0 1 1 1 0 1 1 1]\n",
            "57 + 62 = 119\n",
            "------------\n",
            "iters:5800\n",
            "Loss:0.009455285042607096\n",
            "Pred:[1 0 0 0 0 1 0 0]\n",
            "True:[1 0 0 0 0 1 0 0]\n",
            "113 + 19 = 132\n",
            "------------\n",
            "iters:5900\n",
            "Loss:0.010429378618449706\n",
            "Pred:[0 1 1 0 1 0 0 1]\n",
            "True:[0 1 1 0 1 0 0 1]\n",
            "19 + 86 = 105\n",
            "------------\n",
            "iters:6000\n",
            "Loss:0.007587516181869666\n",
            "Pred:[0 1 1 0 0 0 1 0]\n",
            "True:[0 1 1 0 0 0 1 0]\n",
            "13 + 85 = 98\n",
            "------------\n",
            "iters:6100\n",
            "Loss:0.00397327484993762\n",
            "Pred:[1 1 1 0 0 0 0 0]\n",
            "True:[1 1 1 0 0 0 0 0]\n",
            "125 + 99 = 224\n",
            "------------\n",
            "iters:6200\n",
            "Loss:0.005716684268786877\n",
            "Pred:[1 1 0 0 1 1 1 1]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "116 + 91 = 207\n",
            "------------\n",
            "iters:6300\n",
            "Loss:0.005668417485478533\n",
            "Pred:[1 0 1 1 0 1 0 0]\n",
            "True:[1 0 1 1 0 1 0 0]\n",
            "85 + 95 = 180\n",
            "------------\n",
            "iters:6400\n",
            "Loss:0.1265282719950756\n",
            "Pred:[1 0 1 0 0 1 1 0]\n",
            "True:[1 0 1 0 0 1 1 0]\n",
            "58 + 108 = 166\n",
            "------------\n",
            "iters:6500\n",
            "Loss:0.0584789487904248\n",
            "Pred:[0 0 1 1 1 0 0 1]\n",
            "True:[0 0 1 1 1 0 0 1]\n",
            "1 + 56 = 57\n",
            "------------\n",
            "iters:6600\n",
            "Loss:0.011166362978829298\n",
            "Pred:[0 1 1 0 1 0 1 1]\n",
            "True:[0 1 1 0 1 0 1 1]\n",
            "43 + 64 = 107\n",
            "------------\n",
            "iters:6700\n",
            "Loss:0.0020163510644592483\n",
            "Pred:[1 1 0 0 1 1 1 1]\n",
            "True:[1 1 0 0 1 1 1 1]\n",
            "102 + 105 = 207\n",
            "------------\n",
            "iters:6800\n",
            "Loss:0.0010412289862192486\n",
            "Pred:[0 0 1 1 0 1 1 1]\n",
            "True:[0 0 1 1 0 1 1 1]\n",
            "34 + 21 = 55\n",
            "------------\n",
            "iters:6900\n",
            "Loss:0.009913226784058397\n",
            "Pred:[1 1 1 0 0 1 1 1]\n",
            "True:[1 1 1 0 0 1 1 1]\n",
            "107 + 124 = 231\n",
            "------------\n",
            "iters:7000\n",
            "Loss:0.0013937726334490854\n",
            "Pred:[1 0 0 0 0 0 1 1]\n",
            "True:[1 0 0 0 0 0 1 1]\n",
            "32 + 99 = 131\n",
            "------------\n",
            "iters:7100\n",
            "Loss:0.1268563644030699\n",
            "Pred:[1 1 0 0 0 0 0 0]\n",
            "True:[1 1 0 0 0 0 0 0]\n",
            "126 + 66 = 192\n",
            "------------\n",
            "iters:7200\n",
            "Loss:0.1264721745371764\n",
            "Pred:[0 1 1 1 0 0 1 0]\n",
            "True:[0 1 1 1 0 0 1 0]\n",
            "96 + 18 = 114\n",
            "------------\n",
            "iters:7300\n",
            "Loss:0.00029263312445057234\n",
            "Pred:[1 0 0 0 1 1 1 1]\n",
            "True:[1 0 0 0 1 1 1 1]\n",
            "94 + 49 = 143\n",
            "------------\n",
            "iters:7400\n",
            "Loss:0.0024056237384633876\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "25 + 86 = 111\n",
            "------------\n",
            "iters:7500\n",
            "Loss:0.00020023178306124905\n",
            "Pred:[0 1 1 1 1 0 0 1]\n",
            "True:[0 1 1 1 1 0 0 1]\n",
            "115 + 6 = 121\n",
            "------------\n",
            "iters:7600\n",
            "Loss:0.025060324000165342\n",
            "Pred:[1 0 0 0 0 1 0 1]\n",
            "True:[1 0 0 0 0 1 0 1]\n",
            "41 + 92 = 133\n",
            "------------\n",
            "iters:7700\n",
            "Loss:0.0017102292170625558\n",
            "Pred:[1 0 0 1 0 1 0 1]\n",
            "True:[1 0 0 1 0 1 0 1]\n",
            "99 + 50 = 149\n",
            "------------\n",
            "iters:7800\n",
            "Loss:0.003246044358726266\n",
            "Pred:[1 0 0 1 0 0 1 0]\n",
            "True:[1 0 0 1 0 0 1 0]\n",
            "49 + 97 = 146\n",
            "------------\n",
            "iters:7900\n",
            "Loss:0.0004320932370133635\n",
            "Pred:[0 0 1 1 1 1 1 1]\n",
            "True:[0 0 1 1 1 1 1 1]\n",
            "4 + 59 = 63\n",
            "------------\n",
            "iters:8000\n",
            "Loss:0.1477558966380322\n",
            "Pred:[1 0 0 0 1 0 1 0]\n",
            "True:[1 0 0 0 1 0 1 0]\n",
            "18 + 120 = 138\n",
            "------------\n",
            "iters:8100\n",
            "Loss:0.00020846423399176103\n",
            "Pred:[0 1 1 0 1 1 1 1]\n",
            "True:[0 1 1 0 1 1 1 1]\n",
            "104 + 7 = 111\n",
            "------------\n",
            "iters:8200\n",
            "Loss:0.12521343263539242\n",
            "Pred:[0 1 1 1 1 1 1 0]\n",
            "True:[0 1 1 1 1 1 1 0]\n",
            "28 + 98 = 126\n",
            "------------\n",
            "iters:8300\n",
            "Loss:0.1292150805308524\n",
            "Pred:[0 1 0 0 1 1 1 0]\n",
            "True:[0 1 0 0 1 1 1 0]\n",
            "70 + 8 = 78\n",
            "------------\n",
            "iters:8400\n",
            "Loss:0.1253282907865931\n",
            "Pred:[0 1 0 0 0 0 1 0]\n",
            "True:[0 1 0 0 0 0 1 0]\n",
            "8 + 58 = 66\n",
            "------------\n",
            "iters:8500\n",
            "Loss:0.001241850870399588\n",
            "Pred:[1 1 1 0 1 1 1 0]\n",
            "True:[1 1 1 0 1 1 1 0]\n",
            "127 + 111 = 238\n",
            "------------\n",
            "iters:8600\n",
            "Loss:0.000206815602264597\n",
            "Pred:[1 0 0 1 0 1 1 1]\n",
            "True:[1 0 0 1 0 1 1 1]\n",
            "24 + 127 = 151\n",
            "------------\n",
            "iters:8700\n",
            "Loss:0.010694870170044214\n",
            "Pred:[0 0 1 1 0 0 0 1]\n",
            "True:[0 0 1 1 0 0 0 1]\n",
            "37 + 12 = 49\n",
            "------------\n",
            "iters:8800\n",
            "Loss:0.0004355739415547533\n",
            "Pred:[1 1 0 0 0 1 1 1]\n",
            "True:[1 1 0 0 0 1 1 1]\n",
            "73 + 126 = 199\n",
            "------------\n",
            "iters:8900\n",
            "Loss:0.00022945910321129845\n",
            "Pred:[0 0 1 1 0 1 1 1]\n",
            "True:[0 0 1 1 0 1 1 1]\n",
            "0 + 55 = 55\n",
            "------------\n",
            "iters:9000\n",
            "Loss:0.00016597749104699472\n",
            "Pred:[0 1 1 1 0 0 0 0]\n",
            "True:[0 1 1 1 0 0 0 0]\n",
            "103 + 9 = 112\n",
            "------------\n",
            "iters:9100\n",
            "Loss:0.00017957722093173102\n",
            "Pred:[1 0 0 0 0 1 1 0]\n",
            "True:[1 0 0 0 0 1 1 0]\n",
            "111 + 23 = 134\n",
            "------------\n",
            "iters:9200\n",
            "Loss:0.006795911550136898\n",
            "Pred:[0 1 1 0 0 1 0 1]\n",
            "True:[0 1 1 0 0 1 0 1]\n",
            "85 + 16 = 101\n",
            "------------\n",
            "iters:9300\n",
            "Loss:0.00018587025858498343\n",
            "Pred:[0 1 1 1 0 1 0 0]\n",
            "True:[0 1 1 1 0 1 0 0]\n",
            "15 + 101 = 116\n",
            "------------\n",
            "iters:9400\n",
            "Loss:0.2512910220669763\n",
            "Pred:[0 0 1 1 1 0 0 0]\n",
            "True:[0 0 1 1 1 0 0 0]\n",
            "20 + 36 = 56\n",
            "------------\n",
            "iters:9500\n",
            "Loss:0.12525634539740743\n",
            "Pred:[0 0 1 0 1 0 1 0]\n",
            "True:[0 0 1 0 1 0 1 0]\n",
            "16 + 26 = 42\n",
            "------------\n",
            "iters:9600\n",
            "Loss:0.006314032198123197\n",
            "Pred:[0 1 1 1 0 1 0 1]\n",
            "True:[0 1 1 1 0 1 0 1]\n",
            "33 + 84 = 117\n",
            "------------\n",
            "iters:9700\n",
            "Loss:0.00011424471644507566\n",
            "Pred:[0 0 1 1 0 1 1 1]\n",
            "True:[0 0 1 1 0 1 1 1]\n",
            "6 + 49 = 55\n",
            "------------\n",
            "iters:9800\n",
            "Loss:0.12513982640227175\n",
            "Pred:[1 0 1 0 1 1 1 0]\n",
            "True:[1 0 1 0 1 1 1 0]\n",
            "60 + 114 = 174\n",
            "------------\n",
            "iters:9900\n",
            "Loss:0.0018191763564242439\n",
            "Pred:[1 0 0 0 0 1 1 1]\n",
            "True:[1 0 0 0 0 1 1 1]\n",
            "67 + 68 = 135\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}