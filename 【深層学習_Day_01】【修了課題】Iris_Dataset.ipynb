{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "【深層学習 Day_01】【修了課題】Iris_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HienDT27/Rabbit-Challenge/blob/master/%E3%80%90%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92_Day_01%E3%80%91%E3%80%90%E4%BF%AE%E4%BA%86%E8%AA%B2%E9%A1%8C%E3%80%91Iris_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cNl2QA_Rnv5",
        "colab_type": "text"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkwjN1jNVAYy",
        "colab_type": "text"
      },
      "source": [
        "## Googleドライブのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvFXpiH3EVC1",
        "colab_type": "code",
        "outputId": "6a60394b-01ae-459d-9989-39536ecd0b96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ub7RYdeY6pK",
        "colab_type": "text"
      },
      "source": [
        "## sys.pathの設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oql7L19rEsWi",
        "colab_type": "text"
      },
      "source": [
        "以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ic2JzkvFX59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/【E資格】深層学習/DNN_code')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToUJok-EiuLx",
        "colab_type": "text"
      },
      "source": [
        "# IRIS Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y61xM1nb-ZMK",
        "colab_type": "text"
      },
      "source": [
        "Irisデータとは、機械学習でよく使われるアヤメの品種のデータです。\n",
        "アヤメの品種のSetosa Versicolor Virginicaの3品種に関する150件のデータが入っています。\n",
        "\n",
        "データセットの中身はSepal Length（がく片の長さ）、 Sepal Width（がく片の幅）、\n",
        " Petal Length（花びらの長さ）、 Petal Width（花びらの幅）の4つの特徴量を持っています。データセットはこれら4つの特徴量と、品種名で成り立っています。\n",
        "\n",
        " 以下のソースコードにてデータセットの中身を確認していきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NhG918H0p6S",
        "colab_type": "code",
        "outputId": "506d691c-4ec1-45e9-ae21-bdf0b5ea915a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "#df['target'] = iris.target_names[iris.target]\n",
        "print(df.head())\n",
        "print(iris.data.shape)\n",
        "\n",
        "# iris_dataset['target_names']に対応する品種のラベル値も同様に分割されている\n",
        "# 0:Setosa, 1:Versicolour , 2:Virginica\n",
        "print(iris['target_names'])\n",
        "T = iris.target\n",
        "print(T)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
            "0                5.1               3.5                1.4               0.2\n",
            "1                4.9               3.0                1.4               0.2\n",
            "2                4.7               3.2                1.3               0.2\n",
            "3                4.6               3.1                1.5               0.2\n",
            "4                5.0               3.6                1.4               0.2\n",
            "(150, 4)\n",
            "['setosa' 'versicolor' 'virginica']\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OWif6Kt25BH",
        "colab_type": "code",
        "outputId": "0ecb0754-49a1-41d9-fa96-98ff003fc291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# one hot label\n",
        "from keras.utils import np_utils\n",
        "data_X = iris.data\n",
        "data_d = np_utils.to_categorical(iris.target)\n",
        "\n",
        "# データ分割\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, d_train, d_test = train_test_split(\n",
        "    data_X, data_d, test_size=0.3, random_state=0)\n",
        "\n",
        "#print(x_train, x_test, d_train, d_test)\n",
        "print( '学習データのOne hot label後：',d_train)\n",
        "\n",
        "train_size = len(x_train)\n",
        "\n",
        "print(\"x_train_shape: {}\".format(x_train.shape))\n",
        "print(\"d_train_shape: {}\".format(d_train.shape))\n",
        "\n",
        "print(\"x_test_shape: {}\".format(x_test.shape))\n",
        "print(\"d_test_shape: {}\".format(d_test.shape))\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "学習データのOne hot label後： [[0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]]\n",
            "x_train_shape: (105, 4)\n",
            "d_train_shape: (105, 3)\n",
            "x_test_shape: (45, 4)\n",
            "d_test_shape: (45, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMVvN0tn6oj4",
        "colab_type": "code",
        "outputId": "02a82af8-15ae-4558-b6d2-56a0a8151ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "from common import functions #講義の演習にて定義された関数を利用する\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 重み初期値補正係数\n",
        "wieght_init = 0.01 # 変更してみよう\n",
        "#入力層サイズ\n",
        "input_layer_size = 4 # 変更してみよう\n",
        "#中間層サイズ\n",
        "hidden_layer_size = 10 # 変更してみよう\n",
        "#出力層サイズ\n",
        "output_layer_size = 3 # 変更してみよう\n",
        "# 繰り返し数\n",
        "iters_num = 1000 # 変更してみよう\n",
        "# ミニバッチサイズ\n",
        "batch_size = 100 # 変更してみよ\n",
        "# 学習率\n",
        "learning_rate = 0.07 # 変更してみよう\n",
        "# 描写頻度\n",
        "plot_interval=10\n",
        "\n",
        "def print_vec(text, vec):\n",
        "    print(\"*** \" + text + \" ***\")\n",
        "    print(vec)\n",
        "    #print(\"shape: \" + str(x.shape))\n",
        "    print(\"\")\n",
        "\n",
        "# 初期設定\n",
        "def init_network():\n",
        "    network = {} \n",
        "    network['W1'] = wieght_init * np.random.randn(input_layer_size, hidden_layer_size)\n",
        "    network['W2'] = wieght_init * np.random.randn(hidden_layer_size, output_layer_size)\n",
        "    # 試してみよう_Xavierの初期値\n",
        "    # network['W1'] = np.random.randn(input_layer_size, hidden_layer_size) / np.sqrt(input_layer_size)\n",
        "    # network['W2'] = np.random.randn(hidden_layer_size, output_layer_size) / np.sqrt(hidden_layer_size)\n",
        "    # 試してみよう Heの初期値\n",
        "    # network['W1'] = np.random.randn(input_layer_size, hidden_layer_size) / np.sqrt(input_layer_size) * np.sqrt(2)\n",
        "    # network['W2'] = np.random.randn(hidden_layer_size, output_layer_size) / np.sqrt(hidden_layer_size) * np.sqrt(2)\n",
        "\n",
        "    network['b1'] = np.zeros(hidden_layer_size)\n",
        "    network['b2'] = np.zeros(output_layer_size)\n",
        "    \n",
        "    return network\n",
        "\n",
        "\n",
        "# 順伝播\n",
        "def forward(network, x):\n",
        "    W1, W2 = network['W1'], network['W2']\n",
        "    b1, b2  = network['b1'], network['b2']\n",
        "        \n",
        "    u1 =  np.dot(x, W1) + b1\n",
        "    z1 = functions.relu(u1)\n",
        "    u2 =  np.dot(z1, W2) + b2\n",
        "    y = functions.softmax(u2)\n",
        " \n",
        "    return z1, y\n",
        "\n",
        "# 誤差逆伝播\n",
        "def backward(x, d, z1, y):\n",
        "    grad = {}\n",
        "    \n",
        "    W1, W2 = network['W1'], network['W2']\n",
        "    b1, b2 = network['b1'], network['b2']    \n",
        "    # 出力層でのデルタ\n",
        "    delta2 = functions.d_softmax_with_loss(d, y)\n",
        "    # b2の勾配\n",
        "    grad['b2'] = np.sum(delta2, axis=0)\n",
        "    # W2の勾配\n",
        "    grad['W2'] = np.dot(z1.T, delta2)\n",
        "    # 1層でのデルタ\n",
        "    delta1 = np.dot(delta2, W2.T) * functions.d_relu(z1)\n",
        "    # b1の勾配\n",
        "    grad['b1'] = np.sum(delta1, axis=0)\n",
        "    # W1の勾配\n",
        "    grad['W1'] = np.dot(x.T, delta1)\n",
        "\n",
        "    return grad\n",
        "\n",
        "# パラメータの初期化\n",
        "network = init_network()\n",
        "\n",
        "\n",
        "accuracies_train = []\n",
        "loss_train = []\n",
        "#accuracies_test = []\n",
        "\n",
        "# 正答率\n",
        "def accuracy(x, d):\n",
        "    z1, y = forward(network, x)\n",
        "    y = np.argmax(y, axis=1)\n",
        "    if d.ndim != 1 : d = np.argmax(d, axis=1)\n",
        "    accuracy = np.sum(y == d) / float(x.shape[0])\n",
        "    return accuracy\n",
        "\n",
        "for i in range(iters_num):\n",
        "\n",
        "    z1, y = forward(network, x_train)\n",
        "    #print(y)\n",
        "    #print(d_train)\n",
        "\n",
        "    if (i+1)%plot_interval==0:\n",
        "\n",
        "        # 誤差\n",
        "        loss = functions.cross_entropy_error(d_train, y)\n",
        "        loss_train.append(loss)\n",
        "        #正答率\n",
        "        accr_train = accuracy(x_train, d_train)\n",
        "        accuracies_train.append(accr_train)\n",
        "\n",
        "        print('交差エントロピー誤差：' ,loss)\n",
        "        print('Generation: ' + str(i+1) + '. 正答率(トレーニング) = ' + str(accr_train))\n",
        "        #print('                : ' + str(i+1) + '. 正答率(テスト) = ' + str(accr_test))\n",
        "           \n",
        "    grad = backward(x_train, d_train, z1, y)\n",
        "\n",
        "    # パラメータに勾配適用\n",
        "    for key in ('W1', 'W2', 'b1', 'b2'):\n",
        "        network[key]  -= learning_rate * grad[key]\n",
        "\n",
        "\n",
        "lists = range(0, iters_num, plot_interval)\n",
        "plt.plot(lists, loss_train, label=\"loss \")\n",
        "plt.plot(lists, accuracies_train, label=\"training set\")\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.title(\"正答率\")\n",
        "# グラフの表示\n",
        "plt.show()\n",
        "print('-----------------------------------')\n",
        "print('---学習後の重みとバイアス表示---')\n",
        "print_vec(\"偏微分_重み1\", grad[\"W1\"])\n",
        "print_vec(\"偏微分_重み2\", grad[\"W2\"])\n",
        "print_vec(\"偏微分_バイアス1\", grad[\"b1\"])\n",
        "print_vec(\"偏微分_バイアス2\", grad[\"b2\"])\n",
        "\n",
        "print('-----------------------------------')\n",
        "print('---テストデータに対する結果---')\n",
        "z_test, y_test = forward(network, x_test)\n",
        "grad = backward(x_test, d_test, z_test, y_test)\n",
        "loss_2 = functions.cross_entropy_error(d_test, y_test)\n",
        "accr_test = accuracy(x_test, d_test)\n",
        "\n",
        "print('テストでの誤差：',loss_2)\n",
        "print('テストでの正答率：',accr_test)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "交差エントロピー誤差： 1.0942816240522226\n",
            "Generation: 10. 正答率(トレーニング) = 0.37142857142857144\n",
            "交差エントロピー誤差： 1.081134116358785\n",
            "Generation: 20. 正答率(トレーニング) = 0.37142857142857144\n",
            "交差エントロピー誤差： 1.0438466182730335\n",
            "Generation: 30. 正答率(トレーニング) = 0.37142857142857144\n",
            "交差エントロピー誤差： 0.976746941042269\n",
            "Generation: 40. 正答率(トレーニング) = 0.37142857142857144\n",
            "交差エントロピー誤差： 0.8745247748782636\n",
            "Generation: 50. 正答率(トレーニング) = 0.6952380952380952\n",
            "交差エントロピー誤差： 0.7788599986649065\n",
            "Generation: 60. 正答率(トレーニング) = 0.6952380952380952\n",
            "交差エントロピー誤差： 0.6731293106678076\n",
            "Generation: 70. 正答率(トレーニング) = 0.6952380952380952\n",
            "交差エントロピー誤差： 0.5746152811237498\n",
            "Generation: 80. 正答率(トレーニング) = 0.6952380952380952\n",
            "交差エントロピー誤差： 0.5046845406357973\n",
            "Generation: 90. 正答率(トレーニング) = 0.7238095238095238\n",
            "交差エントロピー誤差： 0.4550488060495147\n",
            "Generation: 100. 正答率(トレーニング) = 0.7619047619047619\n",
            "交差エントロピー誤差： 0.41630787953294457\n",
            "Generation: 110. 正答率(トレーニング) = 0.8476190476190476\n",
            "交差エントロピー誤差： 0.38329008480872556\n",
            "Generation: 120. 正答率(トレーニング) = 0.8952380952380953\n",
            "交差エントロピー誤差： 0.35355765501361136\n",
            "Generation: 130. 正答率(トレーニング) = 0.9333333333333333\n",
            "交差エントロピー誤差： 0.3261138664086139\n",
            "Generation: 140. 正答率(トレーニング) = 0.9428571428571428\n",
            "交差エントロピー誤差： 0.300639024352311\n",
            "Generation: 150. 正答率(トレーニング) = 0.9523809523809523\n",
            "交差エントロピー誤差： 0.27711382964197956\n",
            "Generation: 160. 正答率(トレーニング) = 0.9619047619047619\n",
            "交差エントロピー誤差： 0.2555933844398742\n",
            "Generation: 170. 正答率(トレーニング) = 0.9619047619047619\n",
            "交差エントロピー誤差： 0.23611125992058116\n",
            "Generation: 180. 正答率(トレーニング) = 0.9714285714285714\n",
            "交差エントロピー誤差： 0.21981653815527746\n",
            "Generation: 190. 正答率(トレーニング) = 0.9714285714285714\n",
            "交差エントロピー誤差： 0.41678466976594136\n",
            "Generation: 200. 正答率(トレーニング) = 0.7047619047619048\n",
            "交差エントロピー誤差： 0.31112857275953804\n",
            "Generation: 210. 正答率(トレーニング) = 0.8571428571428571\n",
            "交差エントロピー誤差： 0.2710359965371308\n",
            "Generation: 220. 正答率(トレーニング) = 0.9047619047619048\n",
            "交差エントロピー誤差： 0.25413934038450914\n",
            "Generation: 230. 正答率(トレーニング) = 0.9142857142857143\n",
            "交差エントロピー誤差： 0.243451636260978\n",
            "Generation: 240. 正答率(トレーニング) = 0.9238095238095239\n",
            "交差エントロピー誤差： 0.23277228503075895\n",
            "Generation: 250. 正答率(トレーニング) = 0.9238095238095239\n",
            "交差エントロピー誤差： 0.2212510984585786\n",
            "Generation: 260. 正答率(トレーニング) = 0.9238095238095239\n",
            "交差エントロピー誤差： 0.20947675321169393\n",
            "Generation: 270. 正答率(トレーニング) = 0.9238095238095239\n",
            "交差エントロピー誤差： 0.19817084709245705\n",
            "Generation: 280. 正答率(トレーニング) = 0.9333333333333333\n",
            "交差エントロピー誤差： 0.1871241787853722\n",
            "Generation: 290. 正答率(トレーニング) = 0.9333333333333333\n",
            "交差エントロピー誤差： 0.17628711821480542\n",
            "Generation: 300. 正答率(トレーニング) = 0.9428571428571428\n",
            "交差エントロピー誤差： 0.16578579678118588\n",
            "Generation: 310. 正答率(トレーニング) = 0.9428571428571428\n",
            "交差エントロピー誤差： 0.15582591897224266\n",
            "Generation: 320. 正答率(トレーニング) = 0.9428571428571428\n",
            "交差エントロピー誤差： 0.1465992004855791\n",
            "Generation: 330. 正答率(トレーニング) = 0.9428571428571428\n",
            "交差エントロピー誤差： 0.13822297267457462\n",
            "Generation: 340. 正答率(トレーニング) = 0.9523809523809523\n",
            "交差エントロピー誤差： 0.1307352791917128\n",
            "Generation: 350. 正答率(トレーニング) = 0.9619047619047619\n",
            "交差エントロピー誤差： 0.12410715847891342\n",
            "Generation: 360. 正答率(トレーニング) = 0.9619047619047619\n",
            "交差エントロピー誤差： 0.11832289345612243\n",
            "Generation: 370. 正答率(トレーニング) = 0.9619047619047619\n",
            "交差エントロピー誤差： 0.11314235752431974\n",
            "Generation: 380. 正答率(トレーニング) = 0.9714285714285714\n",
            "交差エントロピー誤差： 0.10848725374728589\n",
            "Generation: 390. 正答率(トレーニング) = 0.9714285714285714\n",
            "交差エントロピー誤差： 0.10430632854772959\n",
            "Generation: 400. 正答率(トレーニング) = 0.9714285714285714\n",
            "交差エントロピー誤差： 0.10053866401349726\n",
            "Generation: 410. 正答率(トレーニング) = 0.9714285714285714\n",
            "交差エントロピー誤差： 0.09711731401782722\n",
            "Generation: 420. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.09400834016774304\n",
            "Generation: 430. 正答率(トレーニング) = 1.0\n",
            "交差エントロピー誤差： 0.09114332382994077\n",
            "Generation: 440. 正答率(トレーニング) = 1.0\n",
            "交差エントロピー誤差： 0.08852661585181448\n",
            "Generation: 450. 正答率(トレーニング) = 1.0\n",
            "交差エントロピー誤差： 0.0861609404519694\n",
            "Generation: 460. 正答率(トレーニング) = 1.0\n",
            "交差エントロピー誤差： 0.08404269576734053\n",
            "Generation: 470. 正答率(トレーニング) = 0.9904761904761905\n",
            "交差エントロピー誤差： 0.08206074097087587\n",
            "Generation: 480. 正答率(トレーニング) = 0.9904761904761905\n",
            "交差エントロピー誤差： 0.0802126400024929\n",
            "Generation: 490. 正答率(トレーニング) = 0.9904761904761905\n",
            "交差エントロピー誤差： 0.07849189926644841\n",
            "Generation: 500. 正答率(トレーニング) = 0.9904761904761905\n",
            "交差エントロピー誤差： 0.07690014395517772\n",
            "Generation: 510. 正答率(トレーニング) = 0.9904761904761905\n",
            "交差エントロピー誤差： 0.07544289148151849\n",
            "Generation: 520. 正答率(トレーニング) = 0.9904761904761905\n",
            "交差エントロピー誤差： 0.07407428598223281\n",
            "Generation: 530. 正答率(トレーニング) = 0.9904761904761905\n",
            "交差エントロピー誤差： 0.07274887472706047\n",
            "Generation: 540. 正答率(トレーニング) = 0.9904761904761905\n",
            "交差エントロピー誤差： 0.07150257596517932\n",
            "Generation: 550. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.07031849341225482\n",
            "Generation: 560. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.0691986026815533\n",
            "Generation: 570. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.06814280802012244\n",
            "Generation: 580. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.06715080762312946\n",
            "Generation: 590. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.06622758646744485\n",
            "Generation: 600. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.0653311974972668\n",
            "Generation: 610. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.0644776594383723\n",
            "Generation: 620. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.0636725855320436\n",
            "Generation: 630. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.06291393154342992\n",
            "Generation: 640. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.06219399621524142\n",
            "Generation: 650. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.06151922229827192\n",
            "Generation: 660. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.060874766496971884\n",
            "Generation: 670. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.060259654344166434\n",
            "Generation: 680. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.059675850170996234\n",
            "Generation: 690. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05912201685871937\n",
            "Generation: 700. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.0585920192583528\n",
            "Generation: 710. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05809280928094201\n",
            "Generation: 720. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.057613397046251645\n",
            "Generation: 730. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.057137942053774336\n",
            "Generation: 740. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.056677166805759085\n",
            "Generation: 750. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05624422850775196\n",
            "Generation: 760. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.055816715906514436\n",
            "Generation: 770. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.055393765843906255\n",
            "Generation: 780. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.054981253168085026\n",
            "Generation: 790. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05457997885059766\n",
            "Generation: 800. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05419266444699855\n",
            "Generation: 810. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05381957070488046\n",
            "Generation: 820. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05345729016576876\n",
            "Generation: 830. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05310037190260413\n",
            "Generation: 840. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.052752638725141604\n",
            "Generation: 850. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05241516028749449\n",
            "Generation: 860. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05208904841344325\n",
            "Generation: 870. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05177341443297566\n",
            "Generation: 880. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.0514681978150028\n",
            "Generation: 890. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05116827861833734\n",
            "Generation: 900. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05087846585183411\n",
            "Generation: 910. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05059857355589414\n",
            "Generation: 920. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.050326366565561276\n",
            "Generation: 930. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.05006315923747813\n",
            "Generation: 940. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.04980913588420999\n",
            "Generation: 950. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.04956449226828579\n",
            "Generation: 960. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.049330028539814205\n",
            "Generation: 970. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.04910330797254623\n",
            "Generation: 980. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.04888231859007308\n",
            "Generation: 990. 正答率(トレーニング) = 0.9809523809523809\n",
            "交差エントロピー誤差： 0.04866856570405408\n",
            "Generation: 1000. 正答率(トレーニング) = 0.9809523809523809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 27491 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 31572 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:211: RuntimeWarning: Glyph 29575 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 27491 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 31572 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:180: RuntimeWarning: Glyph 29575 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------\n",
            "---学習後の重みとバイアス表示---\n",
            "*** 偏微分_重み1 ***\n",
            "[[-0.05879262 -0.05429285 -0.038644    0.02436847  0.          0.12949581\n",
            "  -0.04122072 -0.00494241 -0.03949079  0.        ]\n",
            " [-0.02711749 -0.02500164 -0.01782089  0.01123874  0.          0.05953408\n",
            "  -0.01907959 -0.00228535 -0.01827884  0.        ]\n",
            " [-0.04974608 -0.04599935 -0.03269159  0.02077744  0.          0.11077195\n",
            "  -0.03466004 -0.00418771 -0.03320201  0.        ]\n",
            " [-0.01757339 -0.01625711 -0.01154829  0.00735403  0.          0.03924728\n",
            "  -0.0122185  -0.00147735 -0.01170417  0.        ]]\n",
            "\n",
            "*** 偏微分_重み2 ***\n",
            "[[ 1.97965789e-03  4.30787517e-02 -4.50584096e-02]\n",
            " [ 1.92407736e-03  4.17553944e-02 -4.36794717e-02]\n",
            " [ 1.33287308e-03  2.89551559e-02 -3.02880290e-02]\n",
            " [-6.39228670e-04  9.00074540e-03 -8.36151672e-03]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [-3.68026709e-03  4.72790409e-02 -4.35987738e-02]\n",
            " [ 1.24142040e-03  2.75515790e-02 -2.87929994e-02]\n",
            " [ 4.82859348e-07  6.80158473e-04 -6.80641333e-04]\n",
            " [ 1.20166678e-03  2.66412424e-02 -2.78429092e-02]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "*** 偏微分_バイアス1 ***\n",
            "[-0.00742333 -0.00685762 -0.00488319  0.00302148  0.          0.01602957\n",
            " -0.00523249 -0.0006178  -0.00501398  0.        ]\n",
            "\n",
            "*** 偏微分_バイアス2 ***\n",
            "[-0.00015529  0.0062164  -0.00606111]\n",
            "\n",
            "-----------------------------------\n",
            "---テストデータに対する結果---\n",
            "テストでの誤差： 0.14086320096037502\n",
            "テストでの正答率： 0.9555555555555556\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}