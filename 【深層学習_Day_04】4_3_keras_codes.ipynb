{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "【深層学習  Day 04】4_3_keras_codes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HienDT27/Rabbit-Challenge/blob/master/%E3%80%90%E6%B7%B1%E5%B1%A4%E5%AD%A6%E7%BF%92_Day_04%E3%80%914_3_keras_codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cNl2QA_Rnv5",
        "colab_type": "text"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkwjN1jNVAYy",
        "colab_type": "text"
      },
      "source": [
        "## Googleドライブのマウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvFXpiH3EVC1",
        "colab_type": "code",
        "outputId": "edf92b56-1c44-4063-9c59-b3c6861346d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ub7RYdeY6pK",
        "colab_type": "text"
      },
      "source": [
        "## sys.pathの設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oql7L19rEsWi",
        "colab_type": "text"
      },
      "source": [
        "以下では，Googleドライブのマイドライブ直下にDNN_codeフォルダを置くことを仮定しています．必要に応じて，パスを変更してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ic2JzkvFX59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/【E資格】深層学習/DNN_code')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLlq0vfB2xeJ",
        "colab_type": "text"
      },
      "source": [
        "# keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQNC_-NI2xeL",
        "colab_type": "text"
      },
      "source": [
        "## 線形回帰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdix662X2xeM",
        "colab_type": "code",
        "outputId": "c06cffbb-22db-4935-bdcf-5d0112d2951a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "iters_num = 1000\n",
        "plot_interval = 10\n",
        "\n",
        "x = np.linspace(-1, 1, 200)\n",
        "np.random.shuffle(x)\n",
        "d = 0.5 * x + 2 + np.random.normal(0, 0.05, (200,))\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# モデルを作成\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim=1, units=1))\n",
        "# model.add(Dense(input_dim=1, output_dim=1))\n",
        "\n",
        "# モデルを表示\n",
        "model.summary()\n",
        "\n",
        "# モデルのコンパイル\n",
        "model.compile(loss='mse', optimizer='sgd')\n",
        "\n",
        "# train\n",
        "for i in range(iters_num):\n",
        "    loss = model.train_on_batch(x, d)\n",
        "    if (i+1) % plot_interval == 0:\n",
        "        print('Generation: ' + str(i+1) + '. 誤差 = ' + str(loss))\n",
        "\n",
        "W, b = model.layers[0].get_weights()\n",
        "print('W:', W)\n",
        "print('b:', b)\n",
        "\n",
        "y = model.predict(x)\n",
        "plt.scatter(x, d)\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 1)                 2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Generation: 10. 誤差 = 3.6942694\n",
            "Generation: 20. 誤差 = 2.6541474\n",
            "Generation: 30. 誤差 = 1.936122\n",
            "Generation: 40. 誤差 = 1.4361179\n",
            "Generation: 50. 誤差 = 1.0842767\n",
            "Generation: 60. 誤差 = 0.8336293\n",
            "Generation: 70. 誤差 = 0.65253085\n",
            "Generation: 80. 誤差 = 0.5196039\n",
            "Generation: 90. 誤差 = 0.4203563\n",
            "Generation: 100. 誤差 = 0.3449212\n",
            "Generation: 110. 誤差 = 0.28654325\n",
            "Generation: 120. 誤差 = 0.24056612\n",
            "Generation: 130. 誤差 = 0.20375313\n",
            "Generation: 140. 誤差 = 0.17383154\n",
            "Generation: 150. 誤差 = 0.14918631\n",
            "Generation: 160. 誤差 = 0.12865375\n",
            "Generation: 170. 誤差 = 0.11138248\n",
            "Generation: 180. 誤差 = 0.09673886\n",
            "Generation: 190. 誤差 = 0.08424299\n",
            "Generation: 200. 誤差 = 0.07352474\n",
            "Generation: 210. 誤差 = 0.06429354\n",
            "Generation: 220. 誤差 = 0.056317464\n",
            "Generation: 230. 誤差 = 0.049408488\n",
            "Generation: 240. 誤差 = 0.04341217\n",
            "Generation: 250. 誤差 = 0.03820005\n",
            "Generation: 260. 誤差 = 0.033664264\n",
            "Generation: 270. 誤差 = 0.029713504\n",
            "Generation: 280. 誤差 = 0.02626993\n",
            "Generation: 290. 誤差 = 0.023266833\n",
            "Generation: 300. 誤差 = 0.020646794\n",
            "Generation: 310. 誤差 = 0.018360259\n",
            "Generation: 320. 誤差 = 0.016364275\n",
            "Generation: 330. 誤差 = 0.014621619\n",
            "Generation: 340. 誤差 = 0.01309992\n",
            "Generation: 350. 誤差 = 0.011771026\n",
            "Generation: 360. 誤差 = 0.010610403\n",
            "Generation: 370. 誤差 = 0.009596691\n",
            "Generation: 380. 誤差 = 0.008711244\n",
            "Generation: 390. 誤差 = 0.007937803\n",
            "Generation: 400. 誤差 = 0.0072621848\n",
            "Generation: 410. 誤差 = 0.006672006\n",
            "Generation: 420. 誤差 = 0.0061564506\n",
            "Generation: 430. 誤差 = 0.0057060784\n",
            "Generation: 440. 誤差 = 0.0053126407\n",
            "Generation: 450. 誤差 = 0.004968946\n",
            "Generation: 460. 誤差 = 0.004668696\n",
            "Generation: 470. 誤差 = 0.0044063986\n",
            "Generation: 480. 誤差 = 0.004177257\n",
            "Generation: 490. 誤差 = 0.0039770813\n",
            "Generation: 500. 誤差 = 0.003802207\n",
            "Generation: 510. 誤差 = 0.0036494357\n",
            "Generation: 520. 誤差 = 0.0035159755\n",
            "Generation: 530. 誤差 = 0.0033993851\n",
            "Generation: 540. 誤差 = 0.0032975313\n",
            "Generation: 550. 誤差 = 0.0032085523\n",
            "Generation: 560. 誤差 = 0.0031308192\n",
            "Generation: 570. 誤差 = 0.0030629113\n",
            "Generation: 580. 誤差 = 0.003003587\n",
            "Generation: 590. 誤差 = 0.0029517603\n",
            "Generation: 600. 誤差 = 0.0029064852\n",
            "Generation: 610. 誤差 = 0.0028669334\n",
            "Generation: 620. 誤差 = 0.00283238\n",
            "Generation: 630. 誤差 = 0.002802194\n",
            "Generation: 640. 誤差 = 0.0027758232\n",
            "Generation: 650. 誤差 = 0.002752787\n",
            "Generation: 660. 誤差 = 0.002732662\n",
            "Generation: 670. 誤差 = 0.00271508\n",
            "Generation: 680. 誤差 = 0.0026997214\n",
            "Generation: 690. 誤差 = 0.0026863038\n",
            "Generation: 700. 誤差 = 0.0026745808\n",
            "Generation: 710. 誤差 = 0.0026643414\n",
            "Generation: 720. 誤差 = 0.0026553944\n",
            "Generation: 730. 誤差 = 0.0026475799\n",
            "Generation: 740. 誤差 = 0.0026407521\n",
            "Generation: 750. 誤差 = 0.002634788\n",
            "Generation: 760. 誤差 = 0.0026295774\n",
            "Generation: 770. 誤差 = 0.0026250256\n",
            "Generation: 780. 誤差 = 0.00262105\n",
            "Generation: 790. 誤差 = 0.0026175755\n",
            "Generation: 800. 誤差 = 0.0026145414\n",
            "Generation: 810. 誤差 = 0.0026118895\n",
            "Generation: 820. 誤差 = 0.0026095733\n",
            "Generation: 830. 誤差 = 0.0026075495\n",
            "Generation: 840. 誤差 = 0.0026057824\n",
            "Generation: 850. 誤差 = 0.002604239\n",
            "Generation: 860. 誤差 = 0.00260289\n",
            "Generation: 870. 誤差 = 0.0026017118\n",
            "Generation: 880. 誤差 = 0.0026006813\n",
            "Generation: 890. 誤差 = 0.0025997818\n",
            "Generation: 900. 誤差 = 0.0025989963\n",
            "Generation: 910. 誤差 = 0.0025983087\n",
            "Generation: 920. 誤差 = 0.0025977097\n",
            "Generation: 930. 誤差 = 0.0025971853\n",
            "Generation: 940. 誤差 = 0.0025967285\n",
            "Generation: 950. 誤差 = 0.0025963283\n",
            "Generation: 960. 誤差 = 0.0025959795\n",
            "Generation: 970. 誤差 = 0.0025956745\n",
            "Generation: 980. 誤差 = 0.002595407\n",
            "Generation: 990. 誤差 = 0.0025951746\n",
            "Generation: 1000. 誤差 = 0.002594971\n",
            "W: [[0.5030295]]\n",
            "b: [2.0012653]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTd6I_kw2xeP",
        "colab_type": "text"
      },
      "source": [
        "## 単純パーセプトロン \n",
        "OR回路\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "### [try]\n",
        "-  np.random.seed(0)をnp.random.seed(1)に変更\n",
        "-  エポック数を100に変更\n",
        "-  AND回路, XOR回路に変更\n",
        "-  OR回路にしてバッチサイズを10に変更\n",
        "-  エポック数を300に変更しよう\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1L1WE642xeP",
        "colab_type": "code",
        "outputId": "59862194-14b6-4fc4-da7a-5e53f8dd9bee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# モジュール読み込み\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        " \n",
        "# 乱数を固定値で初期化\n",
        "np.random.seed(0)\n",
        "\n",
        "# シグモイドの単純パーセプトロン作成\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim=2, units=1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1))\n",
        " \n",
        "# トレーニング用入力 X と正解データ T\n",
        "X = np.array( [[0,0], [0,1], [1,0], [1,1]] )\n",
        "T = np.array( [[0], [1], [1], [1]] )\n",
        " \n",
        "# トレーニング\n",
        "model.fit(X, T, epochs=30, batch_size=1)\n",
        " \n",
        "# トレーニングの入力を流用して実際に分類\n",
        "Y = model.predict_classes(X, batch_size=1)\n",
        "\n",
        "print(\"TEST\")\n",
        "print(Y == T)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4352\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4204\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4079\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3971\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3876\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3790\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3717\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3650\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3586\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3528\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3476\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3425\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3378\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3333\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3291\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3250\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3210\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3172\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3136\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3100\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3067\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3032\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3000\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2968\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2938\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2908\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2878\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2850\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2821\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2794\n",
            "TEST\n",
            "[[ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxJoimbOFEQp",
        "colab_type": "text"
      },
      "source": [
        "### 【Try 01】OR回路のSeed変更\n",
        "-  np.random.seed(0)をnp.random.seed(1)に変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sPuTO4cFILV",
        "colab_type": "code",
        "outputId": "1bed5e77-33f8-43db-f5c9-27584ec97a85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# モジュール読み込み\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        " \n",
        "# 乱数を固定値で初期化\n",
        "np.random.seed(1)\n",
        "\n",
        "# シグモイドの単純パーセプトロン作成\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim=2, units=1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1))\n",
        " \n",
        "# トレーニング用入力 X と正解データ T\n",
        "X = np.array( [[0,0], [0,1], [1,0], [1,1]] )\n",
        "T = np.array( [[0], [1], [1], [1]] )\n",
        " \n",
        "# トレーニング\n",
        "model.fit(X, T, epochs=30, batch_size=1)\n",
        " \n",
        "# トレーニングの入力を流用して実際に分類\n",
        "Y = model.predict_classes(X, batch_size=1)\n",
        "\n",
        "print(\"TEST\")\n",
        "print(Y == T)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.4976\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4734\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4528\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4364\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4231\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4115\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4016\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3928\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3852\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3781\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3719\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3661\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3605\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3555\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3506\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3460\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3417\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3375\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3334\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3294\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3257\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3220\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3186\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3151\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3117\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3085\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3053\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3022\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2991\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2961\n",
            "TEST\n",
            "[[False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI9ysoLIKHzR",
        "colab_type": "text"
      },
      "source": [
        "###【Try 02】Epochを100に変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xicqpH5WKQNX",
        "colab_type": "code",
        "outputId": "33343559-fe2f-40c7-df7c-a3204b95e241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# モジュール読み込み\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        " \n",
        "# 乱数を固定値で初期化\n",
        "np.random.seed(1)\n",
        "\n",
        "# シグモイドの単純パーセプトロン作成\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim=2, units=1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1))\n",
        " \n",
        "# トレーニング用入力 X と正解データ T\n",
        "X = np.array( [[0,0], [0,1], [1,0], [1,1]] )\n",
        "T = np.array( [[0], [1], [1], [1]] )\n",
        " \n",
        "# トレーニング\n",
        "model.fit(X, T, epochs=100, batch_size=1)\n",
        " \n",
        "# トレーニングの入力を流用して実際に分類\n",
        "Y = model.predict_classes(X, batch_size=1)\n",
        "\n",
        "print(\"TEST\")\n",
        "print(Y == T)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.4976\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4734\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4528\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4364\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4231\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4115\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4016\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3928\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3852\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3781\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3719\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3661\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3605\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3555\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3506\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3460\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3417\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3375\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3334\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3294\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3257\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3220\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3186\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3151\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3117\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3085\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3053\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3022\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2991\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2961\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2931\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2903\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2875\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2847\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2820\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2794\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2767\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2741\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2716\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2691\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2667\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2643\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2619\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2596\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2573\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2551\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2528\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2507\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2485\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2464\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2443\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2423\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2403\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2383\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2363\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2344\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2325\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2307\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2288\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2270\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2252\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2235\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2217\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2200\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2183\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2167\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2151\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2134\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2118\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2103\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2087\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2072\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2057\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2042\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2027\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2013\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1998\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1984\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1970\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1957\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1943\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1930\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1917\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1904\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1891\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1878\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1865\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1853\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1841\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1829\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1817\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1805\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1793\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1782\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1770\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1759\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1748\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1737\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1726\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1715\n",
            "TEST\n",
            "[[ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTLB5RIcF6Cs",
        "colab_type": "text"
      },
      "source": [
        "###【Try 03】AND回路に変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCRurZ2wGCMx",
        "colab_type": "code",
        "outputId": "604ec1c7-a3cc-4336-ef8c-be9085953e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# モジュール読み込み\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        " \n",
        "# 乱数を固定値で初期化\n",
        "np.random.seed(0)\n",
        "\n",
        "# シグモイドの単純パーセプトロン作成\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim=2, units=1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1))\n",
        " \n",
        "# トレーニング用入力 X と正解データ T\n",
        "X = np.array( [[0,0], [0,1], [1,0], [1,1]] )\n",
        "#T = np.array( [[0], [1], [1], [1]] )\n",
        "T = np.array( [[0], [0], [0], [1]] )\n",
        " \n",
        "# トレーニング\n",
        "model.fit(X, T, epochs=30, batch_size=1)\n",
        " \n",
        "# トレーニングの入力を流用して実際に分類\n",
        "Y = model.predict_classes(X, batch_size=1)\n",
        "\n",
        "print(\"TEST\")\n",
        "print(Y == T)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_6 (Dense)              (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.8084\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7406\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6849\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6409\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6056\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5781\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5573\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5409\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5270\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5151\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5051\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4965\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4889\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4818\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4751\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4682\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4623\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4565\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4512\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4459\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4403\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4354\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4309\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4264\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4219\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4176\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4132\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4090\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4046\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4011\n",
            "TEST\n",
            "[[ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z5eF8dIKkoc",
        "colab_type": "text"
      },
      "source": [
        "###【Try 03】XOR回路に変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssXtfjy_Kmq4",
        "colab_type": "code",
        "outputId": "c5411809-dd9a-40b6-8719-3f021e5080b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# モジュール読み込み\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        " \n",
        "# 乱数を固定値で初期化\n",
        "np.random.seed(0)\n",
        "\n",
        "# シグモイドの単純パーセプトロン作成\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim=2, units=1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1))\n",
        " \n",
        "# トレーニング用入力 X と正解データ T\n",
        "X = np.array( [[0,0], [0,1], [1,0], [1,1]] )\n",
        "#T = np.array( [[0], [1], [1], [1]] )\n",
        "#T = np.array( [[0], [0], [0], [1]] )\n",
        "T = np.array( [[0], [1], [1], [0]] )\n",
        "\n",
        "# トレーニング\n",
        "model.fit(X, T, epochs=30, batch_size=1)\n",
        " \n",
        "# トレーニングの入力を流用して実際に分類\n",
        "Y = model.predict_classes(X, batch_size=1)\n",
        "\n",
        "print(\"TEST\")\n",
        "print(Y == T)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 50ms/step - loss: 0.8427\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8205\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8049\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7924\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7822\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7754\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7688\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7622\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7578\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7555\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7520\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7497\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7468\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7454\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.7439\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.7425\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7422\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7404\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7394\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7393\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7380\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.7368\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7371\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7363\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7356\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7348\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7344\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7338\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7328\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7326\n",
            "TEST\n",
            "[[ True]\n",
            " [ True]\n",
            " [False]\n",
            " [False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7K3CDdtK20o",
        "colab_type": "text"
      },
      "source": [
        "###【Try 04】OR回路にしてバッチサイズを10に変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUxPnPLoK7TJ",
        "colab_type": "code",
        "outputId": "c3bbd6ad-6978-4085-e306-816895881553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# モジュール読み込み\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        " \n",
        "# 乱数を固定値で初期化\n",
        "np.random.seed(0)\n",
        "\n",
        "# シグモイドの単純パーセプトロン作成\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim=2, units=1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1))\n",
        " \n",
        "# トレーニング用入力 X と正解データ T\n",
        "X = np.array( [[0,0], [0,1], [1,0], [1,1]] )\n",
        "T = np.array( [[0], [1], [1], [1]] )\n",
        " \n",
        "# トレーニング\n",
        "model.fit(X, T, epochs=30, batch_size=10)\n",
        " \n",
        "# トレーニングの入力を流用して実際に分類\n",
        "Y = model.predict_classes(X, batch_size=1)\n",
        "\n",
        "print(\"TEST\")\n",
        "print(Y == T)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.4326\n",
            "Epoch 2/30\n",
            "4/4 [==============================] - 0s 939us/step - loss: 0.4285\n",
            "Epoch 3/30\n",
            "4/4 [==============================] - 0s 946us/step - loss: 0.4246\n",
            "Epoch 4/30\n",
            "4/4 [==============================] - 0s 767us/step - loss: 0.4208\n",
            "Epoch 5/30\n",
            "4/4 [==============================] - 0s 717us/step - loss: 0.4172\n",
            "Epoch 6/30\n",
            "4/4 [==============================] - 0s 664us/step - loss: 0.4138\n",
            "Epoch 7/30\n",
            "4/4 [==============================] - 0s 592us/step - loss: 0.4105\n",
            "Epoch 8/30\n",
            "4/4 [==============================] - 0s 780us/step - loss: 0.4074\n",
            "Epoch 9/30\n",
            "4/4 [==============================] - 0s 578us/step - loss: 0.4044\n",
            "Epoch 10/30\n",
            "4/4 [==============================] - 0s 830us/step - loss: 0.4014\n",
            "Epoch 11/30\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3986\n",
            "Epoch 12/30\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3959\n",
            "Epoch 13/30\n",
            "4/4 [==============================] - 0s 520us/step - loss: 0.3933\n",
            "Epoch 14/30\n",
            "4/4 [==============================] - 0s 731us/step - loss: 0.3908\n",
            "Epoch 15/30\n",
            "4/4 [==============================] - 0s 857us/step - loss: 0.3884\n",
            "Epoch 16/30\n",
            "4/4 [==============================] - 0s 721us/step - loss: 0.3860\n",
            "Epoch 17/30\n",
            "4/4 [==============================] - 0s 643us/step - loss: 0.3837\n",
            "Epoch 18/30\n",
            "4/4 [==============================] - 0s 684us/step - loss: 0.3815\n",
            "Epoch 19/30\n",
            "4/4 [==============================] - 0s 629us/step - loss: 0.3794\n",
            "Epoch 20/30\n",
            "4/4 [==============================] - 0s 696us/step - loss: 0.3773\n",
            "Epoch 21/30\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3753\n",
            "Epoch 22/30\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3733\n",
            "Epoch 23/30\n",
            "4/4 [==============================] - 0s 609us/step - loss: 0.3714\n",
            "Epoch 24/30\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3696\n",
            "Epoch 25/30\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3678\n",
            "Epoch 26/30\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3660\n",
            "Epoch 27/30\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3643\n",
            "Epoch 28/30\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3626\n",
            "Epoch 29/30\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3610\n",
            "Epoch 30/30\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3594\n",
            "TEST\n",
            "[[False]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muoebTaQLV5R",
        "colab_type": "text"
      },
      "source": [
        "###【Try 05】エポック数を300に変更しよう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq4yqsYKLmbJ",
        "colab_type": "code",
        "outputId": "76850afa-4f7e-4a75-a7db-b17213c1b917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# モジュール読み込み\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        " \n",
        "# 乱数を固定値で初期化\n",
        "np.random.seed(0)\n",
        "\n",
        "# シグモイドの単純パーセプトロン作成\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim=2, units=1))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1))\n",
        " \n",
        "# トレーニング用入力 X と正解データ T\n",
        "X = np.array( [[0,0], [0,1], [1,0], [1,1]] )\n",
        "T = np.array( [[0], [1], [1], [1]] )\n",
        " \n",
        "# トレーニング\n",
        "model.fit(X, T, epochs=300, batch_size=10)\n",
        " \n",
        "# トレーニングの入力を流用して実際に分類\n",
        "Y = model.predict_classes(X, batch_size=1)\n",
        "\n",
        "print(\"TEST\")\n",
        "print(Y == T)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 1)                 3         \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3\n",
            "Trainable params: 3\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "4/4 [==============================] - 0s 58ms/step - loss: 0.4326\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 954us/step - loss: 0.4285\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 929us/step - loss: 0.4246\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 971us/step - loss: 0.4208\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.4172\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.4138\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.4105\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.4074\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.4044\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.4014\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3986\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3959\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3933\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3908\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3884\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3860\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3837\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3815\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3794\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3773\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3753\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 955us/step - loss: 0.3733\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 898us/step - loss: 0.3714\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3696\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 686us/step - loss: 0.3678\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 671us/step - loss: 0.3660\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 617us/step - loss: 0.3643\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 888us/step - loss: 0.3626\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 775us/step - loss: 0.3610\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 743us/step - loss: 0.3594\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 649us/step - loss: 0.3578\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 976us/step - loss: 0.3563\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 766us/step - loss: 0.3548\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 806us/step - loss: 0.3533\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 637us/step - loss: 0.3519\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 649us/step - loss: 0.3504\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 626us/step - loss: 0.3491\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 821us/step - loss: 0.3477\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 684us/step - loss: 0.3464\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 603us/step - loss: 0.3451\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 887us/step - loss: 0.3438\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 707us/step - loss: 0.3425\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 649us/step - loss: 0.3413\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 619us/step - loss: 0.3400\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 748us/step - loss: 0.3388\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3376\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 635us/step - loss: 0.3365\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 926us/step - loss: 0.3353\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 584us/step - loss: 0.3342\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 658us/step - loss: 0.3330\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 869us/step - loss: 0.3319\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 647us/step - loss: 0.3308\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 860us/step - loss: 0.3297\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3287\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 868us/step - loss: 0.3276\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 703us/step - loss: 0.3266\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 785us/step - loss: 0.3255\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 829us/step - loss: 0.3245\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 804us/step - loss: 0.3235\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 813us/step - loss: 0.3225\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 882us/step - loss: 0.3215\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 860us/step - loss: 0.3205\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 799us/step - loss: 0.3196\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 740us/step - loss: 0.3186\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 895us/step - loss: 0.3177\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 772us/step - loss: 0.3167\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 895us/step - loss: 0.3158\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 922us/step - loss: 0.3149\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 844us/step - loss: 0.3140\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 727us/step - loss: 0.3131\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 982us/step - loss: 0.3122\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 740us/step - loss: 0.3113\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 891us/step - loss: 0.3104\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3095\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3086\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.3078\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 999us/step - loss: 0.3069\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 894us/step - loss: 0.3061\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 813us/step - loss: 0.3052\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 735us/step - loss: 0.3044\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 698us/step - loss: 0.3036\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 779us/step - loss: 0.3027\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 789us/step - loss: 0.3019\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 734us/step - loss: 0.3011\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 759us/step - loss: 0.3003\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 706us/step - loss: 0.2995\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 637us/step - loss: 0.2987\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 687us/step - loss: 0.2979\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 952us/step - loss: 0.2971\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2963\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 662us/step - loss: 0.2956\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 893us/step - loss: 0.2948\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2940\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2933\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2925\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2917\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2910\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2903\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2895\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2888\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 864us/step - loss: 0.2880\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2873\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2866\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2859\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 904us/step - loss: 0.2852\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2844\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2837\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2830\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2823\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 852us/step - loss: 0.2816\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 568us/step - loss: 0.2810\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 746us/step - loss: 0.2803\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 627us/step - loss: 0.2796\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 604us/step - loss: 0.2789\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 533us/step - loss: 0.2782\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 788us/step - loss: 0.2775\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 852us/step - loss: 0.2769\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 828us/step - loss: 0.2762\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2755\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 947us/step - loss: 0.2749\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 829us/step - loss: 0.2742\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 573us/step - loss: 0.2736\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 682us/step - loss: 0.2729\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 659us/step - loss: 0.2723\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 696us/step - loss: 0.2716\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 595us/step - loss: 0.2710\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 667us/step - loss: 0.2703\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 498us/step - loss: 0.2697\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 694us/step - loss: 0.2691\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 543us/step - loss: 0.2684\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 713us/step - loss: 0.2678\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 754us/step - loss: 0.2672\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 697us/step - loss: 0.2666\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 734us/step - loss: 0.2659\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 575us/step - loss: 0.2653\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 546us/step - loss: 0.2647\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 672us/step - loss: 0.2641\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 664us/step - loss: 0.2635\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 595us/step - loss: 0.2629\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 598us/step - loss: 0.2623\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 584us/step - loss: 0.2617\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 701us/step - loss: 0.2611\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 670us/step - loss: 0.2605\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 589us/step - loss: 0.2599\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 699us/step - loss: 0.2593\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 639us/step - loss: 0.2587\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 710us/step - loss: 0.2581\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 568us/step - loss: 0.2576\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 632us/step - loss: 0.2570\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 535us/step - loss: 0.2564\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 720us/step - loss: 0.2558\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 666us/step - loss: 0.2553\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 661us/step - loss: 0.2547\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 651us/step - loss: 0.2541\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 568us/step - loss: 0.2536\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 582us/step - loss: 0.2530\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 752us/step - loss: 0.2524\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 760us/step - loss: 0.2519\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 574us/step - loss: 0.2513\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 506us/step - loss: 0.2508\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 978us/step - loss: 0.2502\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 668us/step - loss: 0.2497\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 712us/step - loss: 0.2491\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 692us/step - loss: 0.2486\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 750us/step - loss: 0.2481\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 710us/step - loss: 0.2475\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 648us/step - loss: 0.2470\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 605us/step - loss: 0.2464\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 710us/step - loss: 0.2459\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 770us/step - loss: 0.2454\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2449\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 774us/step - loss: 0.2443\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 668us/step - loss: 0.2438\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 718us/step - loss: 0.2433\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 695us/step - loss: 0.2428\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 679us/step - loss: 0.2423\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 698us/step - loss: 0.2417\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 587us/step - loss: 0.2412\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 736us/step - loss: 0.2407\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 799us/step - loss: 0.2402\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 732us/step - loss: 0.2397\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 844us/step - loss: 0.2392\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 878us/step - loss: 0.2387\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 842us/step - loss: 0.2382\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 731us/step - loss: 0.2377\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 598us/step - loss: 0.2372\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 699us/step - loss: 0.2367\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 633us/step - loss: 0.2362\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 764us/step - loss: 0.2357\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 713us/step - loss: 0.2352\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 752us/step - loss: 0.2347\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2343\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 822us/step - loss: 0.2338\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 690us/step - loss: 0.2333\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 683us/step - loss: 0.2328\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 989us/step - loss: 0.2323\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2319\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2314\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2309\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2304\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2300\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2295\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2291\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2286\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2281\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2277\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2272\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2268\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2263\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2258\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2254\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2249\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 779us/step - loss: 0.2245\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2241\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2236\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2232\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2227\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2223\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2219\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2214\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2210\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2205\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2201\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2197\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2193\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2188\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2184\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2180\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2176\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 791us/step - loss: 0.2171\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 777us/step - loss: 0.2167\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 888us/step - loss: 0.2163\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 778us/step - loss: 0.2159\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2155\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 661us/step - loss: 0.2151\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 737us/step - loss: 0.2147\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 860us/step - loss: 0.2142\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 651us/step - loss: 0.2138\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 887us/step - loss: 0.2134\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 926us/step - loss: 0.2130\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2126\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 904us/step - loss: 0.2122\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 688us/step - loss: 0.2118\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 750us/step - loss: 0.2114\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 770us/step - loss: 0.2110\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 916us/step - loss: 0.2106\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 858us/step - loss: 0.2102\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 719us/step - loss: 0.2098\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 755us/step - loss: 0.2094\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 780us/step - loss: 0.2091\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 764us/step - loss: 0.2087\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 718us/step - loss: 0.2083\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2079\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 812us/step - loss: 0.2075\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 930us/step - loss: 0.2071\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 872us/step - loss: 0.2067\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 858us/step - loss: 0.2064\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 893us/step - loss: 0.2060\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 845us/step - loss: 0.2056\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 781us/step - loss: 0.2052\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 867us/step - loss: 0.2048\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 886us/step - loss: 0.2045\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 893us/step - loss: 0.2041\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 943us/step - loss: 0.2037\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2034\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2030\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2026\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.2022\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.2019\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 916us/step - loss: 0.2015\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 855us/step - loss: 0.2012\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 844us/step - loss: 0.2008\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 731us/step - loss: 0.2004\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 644us/step - loss: 0.2001\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 902us/step - loss: 0.1997\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 866us/step - loss: 0.1994\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1990\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 836us/step - loss: 0.1986\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 730us/step - loss: 0.1983\n",
            "Epoch 280/300\n",
            "4/4 [==============================] - 0s 704us/step - loss: 0.1979\n",
            "Epoch 281/300\n",
            "4/4 [==============================] - 0s 790us/step - loss: 0.1976\n",
            "Epoch 282/300\n",
            "4/4 [==============================] - 0s 668us/step - loss: 0.1972\n",
            "Epoch 283/300\n",
            "4/4 [==============================] - 0s 773us/step - loss: 0.1969\n",
            "Epoch 284/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1965\n",
            "Epoch 285/300\n",
            "4/4 [==============================] - 0s 731us/step - loss: 0.1962\n",
            "Epoch 286/300\n",
            "4/4 [==============================] - 0s 908us/step - loss: 0.1958\n",
            "Epoch 287/300\n",
            "4/4 [==============================] - 0s 788us/step - loss: 0.1955\n",
            "Epoch 288/300\n",
            "4/4 [==============================] - 0s 863us/step - loss: 0.1952\n",
            "Epoch 289/300\n",
            "4/4 [==============================] - 0s 980us/step - loss: 0.1948\n",
            "Epoch 290/300\n",
            "4/4 [==============================] - 0s 597us/step - loss: 0.1945\n",
            "Epoch 291/300\n",
            "4/4 [==============================] - 0s 732us/step - loss: 0.1941\n",
            "Epoch 292/300\n",
            "4/4 [==============================] - 0s 745us/step - loss: 0.1938\n",
            "Epoch 293/300\n",
            "4/4 [==============================] - 0s 666us/step - loss: 0.1935\n",
            "Epoch 294/300\n",
            "4/4 [==============================] - 0s 559us/step - loss: 0.1931\n",
            "Epoch 295/300\n",
            "4/4 [==============================] - 0s 867us/step - loss: 0.1928\n",
            "Epoch 296/300\n",
            "4/4 [==============================] - 0s 846us/step - loss: 0.1925\n",
            "Epoch 297/300\n",
            "4/4 [==============================] - 0s 716us/step - loss: 0.1921\n",
            "Epoch 298/300\n",
            "4/4 [==============================] - 0s 707us/step - loss: 0.1918\n",
            "Epoch 299/300\n",
            "4/4 [==============================] - 0s 1ms/step - loss: 0.1915\n",
            "Epoch 300/300\n",
            "4/4 [==============================] - 0s 675us/step - loss: 0.1911\n",
            "TEST\n",
            "[[ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bT4_iOk2xeS",
        "colab_type": "text"
      },
      "source": [
        "## 分類 (iris)\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "### [try]\n",
        "-  中間層の活性関数をsigmoidに変更しよう\n",
        "-  SGDをimportしoptimizerをSGD(lr=0.1)に変更しよう\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ6_puLL2xeS",
        "colab_type": "code",
        "outputId": "21afb39d-82b6-475d-902e-8a399ccf4789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "x = iris.data\n",
        "d = iris.target\n",
        "\n",
        "# from sklearn.cross_validation import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, d_train, d_test = train_test_split(x, d, test_size=0.2)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "# from keras.optimizers import SGD\n",
        "\n",
        "#モデルの設定\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=4))\n",
        "model.add(Activation('relu'))\n",
        "# model.add(Activation('sigmoid'))\n",
        "model.add(Dense(3, input_dim=12))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, d_train, batch_size=5, epochs=20, verbose=1, validation_data=(x_test, d_test))\n",
        "loss = model.evaluate(x_test, d_test, verbose=0)\n",
        "\n",
        "#Accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.ylim(0, 1.0)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 12)                60        \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 3)                 39        \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 99\n",
            "Trainable params: 99\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 120 samples, validate on 30 samples\n",
            "Epoch 1/20\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 1.1144 - acc: 0.2000 - val_loss: 0.9317 - val_acc: 0.4667\n",
            "Epoch 2/20\n",
            "120/120 [==============================] - 0s 658us/step - loss: 0.8804 - acc: 0.6500 - val_loss: 0.8638 - val_acc: 0.6000\n",
            "Epoch 3/20\n",
            "120/120 [==============================] - 0s 648us/step - loss: 0.7967 - acc: 0.6000 - val_loss: 0.7788 - val_acc: 0.6000\n",
            "Epoch 4/20\n",
            "120/120 [==============================] - 0s 573us/step - loss: 0.7236 - acc: 0.6333 - val_loss: 0.6421 - val_acc: 0.7000\n",
            "Epoch 5/20\n",
            "120/120 [==============================] - 0s 526us/step - loss: 0.6447 - acc: 0.7000 - val_loss: 0.5870 - val_acc: 0.7333\n",
            "Epoch 6/20\n",
            "120/120 [==============================] - 0s 525us/step - loss: 0.6161 - acc: 0.6667 - val_loss: 0.6616 - val_acc: 0.6000\n",
            "Epoch 7/20\n",
            "120/120 [==============================] - 0s 577us/step - loss: 0.6085 - acc: 0.6083 - val_loss: 0.5326 - val_acc: 0.7333\n",
            "Epoch 8/20\n",
            "120/120 [==============================] - 0s 531us/step - loss: 0.5537 - acc: 0.7083 - val_loss: 0.4968 - val_acc: 0.7333\n",
            "Epoch 9/20\n",
            "120/120 [==============================] - 0s 512us/step - loss: 0.5383 - acc: 0.6833 - val_loss: 0.4960 - val_acc: 0.8333\n",
            "Epoch 10/20\n",
            "120/120 [==============================] - 0s 509us/step - loss: 0.5111 - acc: 0.7583 - val_loss: 0.4739 - val_acc: 0.9333\n",
            "Epoch 11/20\n",
            "120/120 [==============================] - 0s 514us/step - loss: 0.4855 - acc: 0.7917 - val_loss: 0.5278 - val_acc: 0.6667\n",
            "Epoch 12/20\n",
            "120/120 [==============================] - 0s 504us/step - loss: 0.4812 - acc: 0.7500 - val_loss: 0.4601 - val_acc: 0.8667\n",
            "Epoch 13/20\n",
            "120/120 [==============================] - 0s 600us/step - loss: 0.4547 - acc: 0.8417 - val_loss: 0.4234 - val_acc: 0.9667\n",
            "Epoch 14/20\n",
            "120/120 [==============================] - 0s 516us/step - loss: 0.4464 - acc: 0.8833 - val_loss: 0.4348 - val_acc: 0.9000\n",
            "Epoch 15/20\n",
            "120/120 [==============================] - 0s 552us/step - loss: 0.4240 - acc: 0.8750 - val_loss: 0.4701 - val_acc: 0.6667\n",
            "Epoch 16/20\n",
            "120/120 [==============================] - 0s 568us/step - loss: 0.3998 - acc: 0.8750 - val_loss: 0.3688 - val_acc: 0.7667\n",
            "Epoch 17/20\n",
            "120/120 [==============================] - 0s 550us/step - loss: 0.3957 - acc: 0.8333 - val_loss: 0.3686 - val_acc: 0.9667\n",
            "Epoch 18/20\n",
            "120/120 [==============================] - 0s 538us/step - loss: 0.3918 - acc: 0.8833 - val_loss: 0.3570 - val_acc: 0.9667\n",
            "Epoch 19/20\n",
            "120/120 [==============================] - 0s 528us/step - loss: 0.3635 - acc: 0.9167 - val_loss: 0.3364 - val_acc: 0.9667\n",
            "Epoch 20/20\n",
            "120/120 [==============================] - 0s 605us/step - loss: 0.3497 - acc: 0.9083 - val_loss: 0.3205 - val_acc: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSvm4/wfQ4TGAF6bopQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DTnEVUNMf0J",
        "colab_type": "text"
      },
      "source": [
        "###【Try 01】中間層の活性関数をsigmoidに変更しよう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yua2ccRYOPrJ",
        "colab_type": "code",
        "outputId": "8a05d3ce-a2fa-4095-a8bf-8016574f516f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "x = iris.data\n",
        "d = iris.target\n",
        "\n",
        "# from sklearn.cross_validation import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, d_train, d_test = train_test_split(x, d, test_size=0.2)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "# from keras.optimizers import SGD\n",
        "\n",
        "#モデルの設定\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=4))\n",
        "#model.add(Activation('relu'))\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dense(3, input_dim=12))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, d_train, batch_size=5, epochs=20, verbose=1, validation_data=(x_test, d_test))\n",
        "loss = model.evaluate(x_test, d_test, verbose=0)\n",
        "\n",
        "#Accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.ylim(0, 1.0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 12)                60        \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 3)                 39        \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 99\n",
            "Trainable params: 99\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 120 samples, validate on 30 samples\n",
            "Epoch 1/20\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 1.1935 - acc: 0.3500 - val_loss: 1.1575 - val_acc: 0.2667\n",
            "Epoch 2/20\n",
            "120/120 [==============================] - 0s 492us/step - loss: 1.0451 - acc: 0.3500 - val_loss: 1.0388 - val_acc: 0.2667\n",
            "Epoch 3/20\n",
            "120/120 [==============================] - 0s 564us/step - loss: 0.9893 - acc: 0.4333 - val_loss: 0.9892 - val_acc: 0.4333\n",
            "Epoch 4/20\n",
            "120/120 [==============================] - 0s 600us/step - loss: 0.9641 - acc: 0.6500 - val_loss: 0.9564 - val_acc: 0.6000\n",
            "Epoch 5/20\n",
            "120/120 [==============================] - 0s 502us/step - loss: 0.9439 - acc: 0.5917 - val_loss: 0.9349 - val_acc: 0.6000\n",
            "Epoch 6/20\n",
            "120/120 [==============================] - 0s 501us/step - loss: 0.9252 - acc: 0.5833 - val_loss: 0.9155 - val_acc: 0.6333\n",
            "Epoch 7/20\n",
            "120/120 [==============================] - 0s 611us/step - loss: 0.9095 - acc: 0.5833 - val_loss: 0.8988 - val_acc: 0.6333\n",
            "Epoch 8/20\n",
            "120/120 [==============================] - 0s 492us/step - loss: 0.8940 - acc: 0.6833 - val_loss: 0.8791 - val_acc: 0.6333\n",
            "Epoch 9/20\n",
            "120/120 [==============================] - 0s 494us/step - loss: 0.8791 - acc: 0.7000 - val_loss: 0.8607 - val_acc: 0.5333\n",
            "Epoch 10/20\n",
            "120/120 [==============================] - 0s 592us/step - loss: 0.8663 - acc: 0.5833 - val_loss: 0.8473 - val_acc: 0.6333\n",
            "Epoch 11/20\n",
            "120/120 [==============================] - 0s 469us/step - loss: 0.8509 - acc: 0.5917 - val_loss: 0.8329 - val_acc: 0.6333\n",
            "Epoch 12/20\n",
            "120/120 [==============================] - 0s 505us/step - loss: 0.8388 - acc: 0.6250 - val_loss: 0.8189 - val_acc: 0.6333\n",
            "Epoch 13/20\n",
            "120/120 [==============================] - 0s 487us/step - loss: 0.8252 - acc: 0.7250 - val_loss: 0.8048 - val_acc: 0.6667\n",
            "Epoch 14/20\n",
            "120/120 [==============================] - 0s 637us/step - loss: 0.8119 - acc: 0.6917 - val_loss: 0.7898 - val_acc: 0.6667\n",
            "Epoch 15/20\n",
            "120/120 [==============================] - 0s 483us/step - loss: 0.7993 - acc: 0.7000 - val_loss: 0.7762 - val_acc: 0.6000\n",
            "Epoch 16/20\n",
            "120/120 [==============================] - 0s 581us/step - loss: 0.7861 - acc: 0.6750 - val_loss: 0.7644 - val_acc: 0.6667\n",
            "Epoch 17/20\n",
            "120/120 [==============================] - 0s 495us/step - loss: 0.7749 - acc: 0.6833 - val_loss: 0.7522 - val_acc: 0.6667\n",
            "Epoch 18/20\n",
            "120/120 [==============================] - 0s 504us/step - loss: 0.7626 - acc: 0.6917 - val_loss: 0.7395 - val_acc: 0.6667\n",
            "Epoch 19/20\n",
            "120/120 [==============================] - 0s 564us/step - loss: 0.7520 - acc: 0.7000 - val_loss: 0.7274 - val_acc: 0.6667\n",
            "Epoch 20/20\n",
            "120/120 [==============================] - 0s 528us/step - loss: 0.7398 - acc: 0.6917 - val_loss: 0.7176 - val_acc: 0.6667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY8KcJQJjjAlz/w9jrrTyWNyjNgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpHX3TICMn0B",
        "colab_type": "text"
      },
      "source": [
        "###【Try 02】SGDをimportしoptimizerをSGD(lr=0.1)に変更しよう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXW1N5cxPL4m",
        "colab_type": "code",
        "outputId": "f6475004-7aca-468e-d034-9883403a0829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "x = iris.data\n",
        "d = iris.target\n",
        "\n",
        "# from sklearn.cross_validation import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, d_train, d_test = train_test_split(x, d, test_size=0.2)\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "#モデルの設定\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=4))\n",
        "model.add(Activation('relu'))\n",
        "#model.add(Activation('sigmoid'))\n",
        "model.add(Dense(3, input_dim=12))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "#model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.compile(optimizer=SGD(lr=0.1), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, d_train, batch_size=5, epochs=20, verbose=1, validation_data=(x_test, d_test))\n",
        "loss = model.evaluate(x_test, d_test, verbose=0)\n",
        "\n",
        "#Accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.ylim(0, 1.0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_22 (Dense)             (None, 12)                60        \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 3)                 39        \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 99\n",
            "Trainable params: 99\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 120 samples, validate on 30 samples\n",
            "Epoch 1/20\n",
            "120/120 [==============================] - 0s 4ms/step - loss: 0.8838 - acc: 0.6167 - val_loss: 0.6776 - val_acc: 0.6333\n",
            "Epoch 2/20\n",
            "120/120 [==============================] - 0s 560us/step - loss: 0.5357 - acc: 0.7000 - val_loss: 0.4337 - val_acc: 0.8333\n",
            "Epoch 3/20\n",
            "120/120 [==============================] - 0s 507us/step - loss: 0.4170 - acc: 0.8750 - val_loss: 0.5942 - val_acc: 0.6333\n",
            "Epoch 4/20\n",
            "120/120 [==============================] - 0s 502us/step - loss: 0.4410 - acc: 0.7417 - val_loss: 0.5034 - val_acc: 0.6667\n",
            "Epoch 5/20\n",
            "120/120 [==============================] - 0s 557us/step - loss: 0.4619 - acc: 0.7500 - val_loss: 0.4970 - val_acc: 0.6333\n",
            "Epoch 6/20\n",
            "120/120 [==============================] - 0s 563us/step - loss: 0.3886 - acc: 0.7750 - val_loss: 0.4902 - val_acc: 0.7000\n",
            "Epoch 7/20\n",
            "120/120 [==============================] - 0s 539us/step - loss: 0.3554 - acc: 0.8167 - val_loss: 0.2894 - val_acc: 0.8667\n",
            "Epoch 8/20\n",
            "120/120 [==============================] - 0s 518us/step - loss: 0.3690 - acc: 0.8250 - val_loss: 0.2458 - val_acc: 0.9667\n",
            "Epoch 9/20\n",
            "120/120 [==============================] - 0s 539us/step - loss: 0.3882 - acc: 0.7833 - val_loss: 0.4336 - val_acc: 0.7000\n",
            "Epoch 10/20\n",
            "120/120 [==============================] - 0s 617us/step - loss: 0.2982 - acc: 0.8333 - val_loss: 0.5577 - val_acc: 0.7000\n",
            "Epoch 11/20\n",
            "120/120 [==============================] - 0s 514us/step - loss: 0.3948 - acc: 0.8250 - val_loss: 0.2946 - val_acc: 0.8667\n",
            "Epoch 12/20\n",
            "120/120 [==============================] - 0s 524us/step - loss: 0.2910 - acc: 0.8667 - val_loss: 0.3578 - val_acc: 0.7667\n",
            "Epoch 13/20\n",
            "120/120 [==============================] - 0s 516us/step - loss: 0.4272 - acc: 0.7833 - val_loss: 0.5074 - val_acc: 0.6333\n",
            "Epoch 14/20\n",
            "120/120 [==============================] - 0s 582us/step - loss: 0.4140 - acc: 0.7833 - val_loss: 0.4505 - val_acc: 0.7000\n",
            "Epoch 15/20\n",
            "120/120 [==============================] - 0s 496us/step - loss: 0.2948 - acc: 0.8667 - val_loss: 0.2840 - val_acc: 0.8667\n",
            "Epoch 16/20\n",
            "120/120 [==============================] - 0s 633us/step - loss: 0.3059 - acc: 0.8417 - val_loss: 0.2037 - val_acc: 0.9667\n",
            "Epoch 17/20\n",
            "120/120 [==============================] - 0s 515us/step - loss: 0.2717 - acc: 0.8583 - val_loss: 0.2078 - val_acc: 0.9667\n",
            "Epoch 18/20\n",
            "120/120 [==============================] - 0s 512us/step - loss: 0.2494 - acc: 0.9167 - val_loss: 1.6454 - val_acc: 0.6667\n",
            "Epoch 19/20\n",
            "120/120 [==============================] - 0s 516us/step - loss: 0.3735 - acc: 0.9000 - val_loss: 0.1465 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "120/120 [==============================] - 0s 584us/step - loss: 0.3128 - acc: 0.8833 - val_loss: 0.3216 - val_acc: 0.9333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3dd3iUVfbA8e9JAgklJBBaqKH33ptS\npCgIdkVxEQs2LLvqrq5d111/urqWVawoqICKDREEQXBF6b1LQCCht4SWnvv7405wCJNkksw7k2TO\n53nyJDPzlpPJZM68t5wrxhiUUkoFr5BAB6CUUiqwNBEopVSQ00SglFJBThOBUkoFOU0ESikV5DQR\nKKVUkNNEoIKKiHwoIv/wcttdInKR0zEpFWiaCJRSKshpIlCqFBKRsEDHoMoOTQSqxHE1yTwkIutF\n5LSIvC8itURkjoicFJH5IlLVbfuRIrJJRJJEZJGItHJ7rJOIrHbt9ykQketcI0RkrWvfX0WkvZcx\nDheRNSJyQkQSROSpXI/3dR0vyfX4Ta77K4jISyKyW0SSRWSx677+IpLo4Xm4yPXzUyIyQ0Q+FpET\nwE0i0l1ElrjOsV9E/isi5d32byMiP4jIMRE5KCJ/F5HaInJGRGLctussIodFpJw3v7sqezQRqJLq\nSmAw0By4FJgD/B2ogX3d3gsgIs2BacD9rsdmA9+KSHnXm+LXwEdANeBz13Fx7dsJmATcDsQAbwMz\nRSTci/hOA38CooHhwJ0icpnruA1d8b7uiqkjsNa137+BLkBvV0x/BbK9fE5GATNc5/wEyAL+DFQH\negGDgLtcMUQC84HvgTpAU2CBMeYAsAi4xu24NwLTjTEZXsahyhhNBKqket0Yc9AYsxf4GVhmjFlj\njEkFvgI6uba7FvjOGPOD643s30AF7BttT6Ac8IoxJsMYMwNY4XaO8cDbxphlxpgsY8xkIM21X76M\nMYuMMRuMMdnGmPXYZHSh6+HrgfnGmGmu8x41xqwVkRDgZuA+Y8xe1zl/NcakefmcLDHGfO06Z4ox\nZpUxZqkxJtMYswubyHJiGAEcMMa8ZIxJNcacNMYscz02GRgDICKhwGhsslRBShOBKqkOuv2c4uF2\nZdfPdYDdOQ8YY7KBBKCu67G95tzKirvdfm4IPOBqWkkSkSSgvmu/fIlIDxFZ6GpSSQbuwH4yx3WM\nHR52q45tmvL0mDcScsXQXERmicgBV3PRP72IAeAboLWINMJedSUbY5YXMSZVBmgiUKXdPuwbOgAi\nItg3wb3AfqCu674cDdx+TgCeM8ZEu31VNMZM8+K8U4GZQH1jTBTwFpBzngSgiYd9jgCpeTx2Gqjo\n9nuEYpuV3OUuFTwR2Ao0M8ZUwTaducfQ2FPgrquqz7BXBTeiVwNBTxOBKu0+A4aLyCBXZ+cD2Oad\nX4ElQCZwr4iUE5ErgO5u+74L3OH6dC8iUsnVCRzpxXkjgWPGmFQR6Y5tDsrxCXCRiFwjImEiEiMi\nHV1XK5OAl0WkjoiEikgvV5/Eb0CE6/zlgMeAgvoqIoETwCkRaQnc6fbYLCBWRO4XkXARiRSRHm6P\nTwFuAkaiiSDoaSJQpZoxZhv2k+3r2E/clwKXGmPSjTHpwBXYN7xj2P6EL932XQncBvwXOA7Eu7b1\nxl3AMyJyEngCm5ByjrsHuASblI5hO4o7uB5+ENiA7as4BvwfEGKMSXYd8z3s1cxp4JxRRB48iE1A\nJ7FJ7VO3GE5im30uBQ4A24EBbo//gu2kXm2McW8uU0FIdGEapYKTiPwITDXGvBfoWFRgaSJQKgiJ\nSDfgB2wfx8lAx6MCy7GmIRGZJCKHRGRjHo+LiLwmIvFiJw51dioWpdQfRGQydo7B/ZoEFDh4RSAi\nFwCngCnGmLYeHr8EuAfbltoDeNUY0yP3dkoppZzl2BWBMeZ/2M6wvIzCJgljjFkKRItIrFPxKKWU\n8iyQhavqcu4EmUTXfftzbygi47GzQKlUqVKXli1b+iVApZTyicw0OLQZylWAmCYQ4v+yTqtWrTpi\njMk9NwUIbCLwmjHmHeAdgK5du5qVK1cGOCKllCqE1R/BzAkQGg6R2TBmOlRv6tcQRCTPYcKBnEew\nFzsDNEc9131KKVW2JC6HiGi4eQ6kn4ZJQ2DvqkBHdVYgE8FM4E+u0UM9sfVOzmsWUkqpUi9hBdTr\nBnW7wM3zoHwl+PBSiJ8f6MgAZ4ePTsNO8W8hIokicouI3CEid7g2mQ3sxM7mfBdX+VyllCpTUpPh\n8Fao76puUr0p3PIDVGsMU6+F9Z/lv78fONZHYIwZXcDjBrjbF+fKyMggMTGR1NRUXxyuxIqIiKBe\nvXqUK6frhyhVauxdBRh7RZAjsjaM+w6m3wBf3ganD0Mvn7wdFkmp6CwuSGJiIpGRkcTFxXFuocmy\nwxjD0aNHSUxMpFGjRoEOJzBSkyEiKtBRqEA5fcS+BooqLByq1AV/v0ckrgTENgu5i4iCG2bAV+Nh\n7t/h1EG46Gn/x0cZSQSpqallOgkAiAgxMTEcPnw40KEExvJ3Yc7f4O5lUL1ZoKNR/rZ9Pky7FrIz\ni3ec66ZCy+G+iclbCcuhZiuIqHL+Y+Ui4KoPYM5f4ZdX4dQhGPk6hPr3qr9MJAKgTCeBHMHwO3q0\nb639xGSy4LfvNREEmxP74avboXpz6HN/0Y/z3QO2c9aficAYSFwBrUfmvU1IKFzyb6hcCxY+Z698\nrplsO5T9pMwkAlVGpZ2EGTdDxeoQVh7iF0DvewIdlfKX7CzbdJJ+2n5yrlmMyaQbPoddv/guNm8c\njYfUJKjXPf/tRODCv0LlmjDrzzB5JFz/GVSK8UuYuh6BDyQlJfHmm28Wer9LLrmEpKQkByIqI4yx\nn+KO/w5XvgcthsPuXyEjJdCRKX/5+WX4/X9wyYvFSwIAcX3gyDY45cfm1QTXCqDuHcX56XITXPMR\nHNwIk4ZC0h7HQnOnicAH8koEmZn5t2fOnj2b6Ohop8Iq/dZOhfWfwoUP23/ipgMhKw12+/lTnQqM\n3b/Con9Cu6uh05jiH69hX9dx/fj6SVxhO4WrN/d+n1Yj4Mav4PQheH8IHNzsXHwumgh84OGHH2bH\njh107NiRbt260a9fP0aOHEnr1q0BuOyyy+jSpQtt2rThnXfeObtfXFwcR44cYdeuXbRq1YrbbruN\nNm3aMGTIEFJSgvxT7+HfYPaDENcPLnjQ3tewj52iH/9jYGNTzjtzDL64FaIbwvCXfTOSpk5HKFfR\n/4mgblcIKeRbbcPeMO57+/MHw2xSdFCZ6yN4+ttNbN53wqfHbF2nCk9e2ibPx59//nk2btzI2rVr\nWbRoEcOHD2fjxo1nh3lOmjSJatWqkZKSQrdu3bjyyiuJiTm37W/79u1MmzaNd999l2uuuYYvvviC\nMWN88CmoNMpIgRnjbIGuK961nWlgbzfsDTsWBDY+5Sxj4Ju77QiaW3/wPNqmKELL2Uld/uonSDtp\nC821HFG0/Wu1hlvmwUdXwEeXw1WTHOvo1isCB3Tv3v2csf6vvfYaHTp0oGfPniQkJLB9+/bz9mnU\nqBEdO3YEoEuXLuzatctf4ZY8cx+1baSXvQVVclUmbzrIztJM1rJUZdayt2DbbBj8DNTp5NtjN+wL\nhzbZKw6n7V0NJhvqe9k/4El0A7h5LtRqC5+OcWwWcpm7Isjvk7u/VKr0x7CvRYsWMX/+fJYsWULF\nihXp37+/xxnQ4eHhZ38ODQ0N3qahzd/Ayveh1wRoPuT8x5sMAh6DHT9C5xv9Hp5y2L41MO9xaH4x\n9LzT98eP62O/71ni/DDSxBX2e+6JZIVVKQbGzoRv74fYDsWPywO9IvCByMhITp70vOJfcnIyVatW\npWLFimzdupWlS5f6ObpS5Phu+OYeqNMZBj3peZuarSAyVpuHyqKcocKVasBlbzozw7ZuFwiL8E/z\nUOIKqN4CKlQt/rHKV4Ir34UaLYp/LA/K3BVBIMTExNCnTx/atm1LhQoVqFWr1tnHhg0bxltvvUWr\nVq1o0aIFPXv2DGCkJVhWBnxxC2BsW2hYec/biUCTgbbpIDvrj/4DVboZY8fPH98FN30HFas5c56w\ncDuUc/fiQu+67cBJqlYqR83IiII3zplI1vziIgTpf5oIfGTq1Kke7w8PD2fOnDkeH8vpB6hevTob\nN248e/+DDz7o8/hKvB//Yf9xrvoAqhVQS6nJQFj7iZ1xXK+Yl92qZFj7iZ3wNeBROyDASQ37wP9e\n8Lp2VVpmFk/N3My05XZMf4NqFenSsCqdG1alc4NoWtauQmhIrquXYzvhzNHi9Q/4kSYCFXjx8+GX\nV+xkmrZXFLx94wGA2OYhTQSl3+FtMPshO1S43wPOn69hb9uJu2cpNB+a76b7k1O48+PVrE1I4ta+\njagdFcGq3cdZHH+Er9bYAQuVyofSsUE0XRrY5NCpQVWicvoHCppRXEJoIlCBdfIAfHk71GgFQ//l\n3T6VYuyY8PgFdlq+Kr0yUuDzcXZ8v/tQYSfV62bXDN61ON9EsGznUe6eupqU9Cwm3tCZi9vZEWy3\n9rPVgBOPp7B6z3FW7bZf/10YT7ax+75W5RuGhFTk2z0V6RxyisbVK5XoWmGaCFTgZGfBl646MjfN\ngvIVvd+3ySBY/B8tTV3azf27Hc55w4zzhwo7pXxF22mcx8QyYwwf/rqL577bQoNqFZl2W0+a1Yo8\nZxsRoX61itSvVpFRHesCcDotk3UJSazafZz2y35jTXYTHvpiEwBVK5ajs+uKoUvDqnSoF02F8iWn\nf0sTgQqcxf+B33+CS1+zo4EKo+kg+Pnftg5Nq0udiU85a9PXsHKSLSLYbLB/zx3XBxa/AmmnILzy\n2btT0rP4+1cb+GrNXi5qVYuXr+1AlQjvSkJXCg+jd9Pq9G5QARb/TsN+f2Z+uwvOXjGs3H2cBVsP\nARAWIrSuU+Wc5FAnKiJgVw2aCFRg7FkKC/8Jba+Ezn8q/P71ukH5SNs8pImg9Dm+C2beaz+ZD3zC\n/+dv2Ad+fgkSltkPFUDCsTPc/tEqthw4wV8GN2fCgKaE5O4E9sa+NWCykPo9aFozkqY1I7m2WwMA\njp9OZ03CH81Jn65I4MNfdwFQu0rE2U7oLg2r0jq2CuXD/DPCXxOB8r8zx2DGLRBdH0a8UrTx4qHl\noNEFtsPYmICs6qSKKCvD/v0LGirspPo9QEJt81DTQfzvt8PcM20N2cYwaWw3BrSsWfRjn6042vW8\nh6pWKs/AlrUY2NIOMc/Iymbr/pOs2n2M1Xtss9J3G/YDEB4WQod60WcTQ+cG0cRUDj/vmL6gicAH\nkpKSmDp1KnfddVeh933llVcYP348FSsWon28NDMGvplgl+W7ZV7x6sg0HQjbvrND9WKa+C5G5awf\nn4W9K+HqD6FqXGBiCK8MdTphdv3Cmwvj+fe8bTSvGcnbN3YhrnoxF4RJXAkxTb2aC1EuNIR29aJo\nVy+Km1yTng8kp57TCf3+4p289ZPthX56ZBvG9o4rXnweaCLwgZwy1PklAmMMGVnmvEu9V155hTFj\nxgRPIlj+jn3zHvpPqNu5eMdqYi/piV+giaC02D7fLsnYZRy0uTygoaTX70XI0om8vn09w9vH8cJV\n7alYvphvicZA4nJoWvQ+j9pREVzSLpZLXKOUUjOy2LA3mVW7j9O9kTMT7TQR+IB7GerBgwdTs2ZN\nPvvsM9LS0rj88st5+umn2X3wOH+6YTRJhw+QnZ3F448/zsGDB9m3bx8DBgygevXqLFy4MNC/irP2\nrYV5j0HzYdCz8FdP56nWCKo2ss1DPcYX/3jKWTlLTtZsDcO8HCrskB2HT/H+umj+SSYv9UznklGd\nfNNRm7QbTh/22CxUVBHlQukWV41ucQ7NtqYsJoI5D8OBDb49Zu12cPHzeT7sXoZ63rx5zJgxg+XL\nl2OMYeTIkfz000+s276HGrVqM/nTL2lUvRLJyclERUXx8ssvs3DhQqpXr+7bmEsa9yUnR/mwjkzT\nQbB2GmSmB6at2VvZ2bDrf7b6ZWjh/+1Op2WyOP4IA1rU9FsHoi9lZWaS9NFNVE0/RchV39mS4gEy\nd9MBHvhsHdVCm2IkhOFRO333ekxwTSSrXzomkuUofa+oEm7evHnMmzePTp060blzZ7Zu3cr6zduI\na96KZYsX8cwTf2fu/IVERQXZ2Pdlb8GxHbZwli/XYW0yCDJO29EfJdmqD2DKKFj4j0LtlpVt+GxF\nAv3/vYjbP1rFw1+sxxjjUJDOMMYw4+OJxBxeyt9TxjDq86O89/NO9iX5t8JuVrbh33O3cftHq2hc\noxLT7h2K1G7n2wJ0icuhXCU7QbIUKXtXBPl8cvcHYwyPPPIIt99++9n7dh4+RVpmNmtWr+aD6V/y\n+OOPs/SXwTz5ZB4VNsuazDRY/q6tERTX17fHjusLIWG2eahRP98e21eys2HpRJAQO3cirt/ZIYv5\nWbLjKM/O2szm/Sfo1CCaYW1q89HS3cRGR/DQ0GKu3+tH7/xvJ112TuFYRB0a9b+djRsO8o/vtvCP\n77bQpWFVRrSPZXi7WGpW8aKYWyEZY0g4lsKqPcf4YtVeFscf4eou9Xj2srZElAu1V2gr3rOv0TAf\njMhJXGH7vopw1RdIpSvaEsq9DPXQoUN5/PHHueGGG6hcuTI7du1hT1IaMRVCiWxYh/E3j6VC5Ujm\nfDH1nH3LdNPQxi/tKKFR56/rXGwRVexQwPgFcNFTvj++L8TPh6Pb7cS5pW/advI7foHIWh4333Xk\nNP+cvYV5mw9SN7oCr17XkZEd6gCQmZ3NGwt3EBtVgTE9G/rztyiSb9buZc73s7g9/DeyB/yL23s1\n5/b+zfn9yGm+W7+PWev38/S3m3lm1ma6x1VjRIc6XNy2NtWLOEwyNSOLTfuSz464WbU7iSOn0gCI\njAjj2cvaMqZHgz/6A+L6wNI3YO+q4he7y0ixzdK97y3ecQJAE4EPuJehvvjii7n++uvp1asXAOUr\nVOTZ/7xNwr79jLn6MkJCQsiWUB7/10tkZxvGjx/PsGHDqFOnTtnsLDbG/qPVaOnVp+AiaTLQDkk8\ndRgq13DmHMWx5L92DYUOo+1EuHcHwFfjYcxX56xlm3wmg9d+3M6UJbsoHxrCQ0NbcEvfRvaTq8uz\no9py8EQaT3yzkdpVIriotedkUhL8uuMID36+jslRCzAmkhC3hYQaVa/EhIHNmDCwGfGHTvLtuv3M\nWr+Px7/eyJPfbKR3k+qMaB/LsLa1ia6Yd9/PoRPnDrXcuPcE6VnZADSMqcgFzaqfHYffvFbk+VVC\nG/QCxDYPFTcR7FsL2Zmlrn8AQEpbe2PXrl3NypUrz7lvy5YttGpV8trksrINW/efoEqFctSv9sfw\n0NNpmew4fIraVSIKfTlcUn/XPP3+M0weAZe+aquLOmHfGninvy1a1v4aZ85RVAc2wlt9YNATf1TW\nXPUhfHvf2fsysrKZumwPr8z/jaSUDK7pUp8HhjbPs+79mfRMrntnKb8dPMm023rSqYEPFj7xsa0H\nTnD1xCW0izzJJ6fHIz3vhKHP5buPMYatB04yy3WlsPvoGcJChL7NqjOifR0GtazJ3qRzC70lHrf9\nDOXDQuhQL8q+6bvKNnh9VTGxD1SqDn/6pni/9C+vwg9PwEM77PFKGBFZZYzxOJxJrwgclHQmnSxj\niKl07ieaSuFhVIkox6GTaVStVJ5yoWW4z37pm1AxBtpf69w5anew54hfUPISwdKJEFbBjpvP0Xks\n7PwJ8+NzrKE1Dy2vwI7Dp+nVOIbHRrSiTZ38BxJULB/G+2O7ceXEX7ll8kq+vLN38SdB+dD+5BTG\nfbCCiuGhvN1iFbLaQI/bC9xPRGgVW4VWsVV4cEgLNu49wawN+5i1bj8Pfr7unG1rRobTNa4qN/WO\no0vDqrSpE1X00VQNe8Oaj+2M51Dv6gp5lLjCDmcugUmgIJoIvGUMmCzbMenV5oYjp9KpUD7UY5XB\n2lERbD94ikMnUqlbtYxOJju6A7bNgQsedHa4YEiIXaNgx4+2YzbEmcR66EQqkRHlvK8aeeoQbPgM\nOo05d5apCNu7/4MqW5dQc/4EKlV+hXf/1J2LWtX0eix7jchwPhxnk8HYD5bz5Z29HSs/UBgnUjMY\n98EKTqZm8vnN7YmcejO0GmkXYS8EETk74/bhYS1Zm5DE4u1HaBBjF4WpG13BdwXaGvaxEx33rSl6\ns44xduho4wt9E5OflZlEYIxxtnLfmSNwYp+dDOPFp4bTaZmkZWZRr2pFj3FFlAulWuXyHDuVTkzl\nrHPagfNS2prxWPaWTZzdbnX+XE0HwcYZtqRx7XY+PfTx0+k8/s1GZq23NWCiKpQjNiqCOtEVzvke\nG1WBOtER1I6KIDwsFFa8D1np50yeO3IqjZd/+I3py/fQI/wePgl5gq/rTSOk1YhCj2VvXKMy79/U\njdHvLOXmySuZflvPgJY2Ts/M5vYpq4g/dIoPx3Wn1YEvIS0Zet1drOOKCJ0aVHWuCayhq7bDrsVF\nTwTJCXDqgO0DKoXKRCKIiIjg6NGjxMTEOJMMjIHTR+yqRinHoXLBBamOnk4nLESIrpB30qgVGU7S\n6XQOJKcWeGlvjOHo0aNERPh+iJ0jUo7by+12V0Fk7SIfJj0zm4MnUtmXlEJqZjZ9msQQ5qkprfEA\n+z1+gU8TwfzNB3nkqw0knUnnzv5NiIwIY39SKvuTU9iXlMqaPcc5fibjvP3qVILZ2RPZU7EHX/6a\nTmzUDlIysnj/5985k5HFn3rFcd+gwYSsy7azrVe8B91vK3R8nRtU5fXRnbjj41XcM201b43p4vn5\ncVh2tuGvM9axZOdRXr6mA32bVIM5E6Fu15LfeVq5hl1kfvcv0O8vRTvG2RXJNBEETL169UhMTOTw\n4cPOnCAr3a6khUBoEkQezXfzzGzDweRUKkeEsS05/6uH06kZ7EvJJGl/efspMh8RERHUq1evsNEH\nxqrJkHEm31ISWdmGQydT2ed6Y92flMo+1/f9ySnsS07lyKk03C+EmtWszKPDW9G/Ra5kXCUWarax\n8wn63l/s8E+kZvDMt5uZsSqRlrUjmTyuO63reC6Ql5KeZeNPtglrf3IqdX6fQXRiMv+UEcxZlcjJ\ntEwABrasyd8vaUXTmq4a+D3vtmsqzP27HQYb277QsQ5pU5unR7bh8W828cTMTTx3WVu/17V/Ye42\nvl67j4eGtuCKzvVg62xbDPCqx/0aR5HF9YH1n0NWZtHmACSssH1Btdr4PjY/KBOJoFy5cjRqVMCC\n58Xx/SP2E1u/B2HRP+0Y8Npt89z8xblbmbhoPz89NOCc0UKepGZkMeDfi6gRGc7Xd/UpWv3zkiYr\nw7a5xvU7+8a28/ApPluZSOLxM+xPTmV/UgoHT6aRlX1uc1el8qHEuppaWtauQmx0BHWiKhAbHUHS\nmQz+PW8bN32wggub1+Cx4a3OXTmq6UBY9rZd8ax80TtPF28/wl9nrOPAiVQmDGjKvYOa5dsRWaF8\nKI1rVKZxDdebuzHw5jdQqy0v3HEPL4hwMjWDU2mZxEbl6isJCYHLJsJbfWHGOBj/0zkLpXjrxl5x\n7EtOZeKiHdSNrsDdA5oW+hhFNWXJLt76aQc39GjAXf1dxf+WvAFR9W3/QGnQsI9dJOfA+qIVQzw7\nkawYnc0BVCYSgaOyMmDD57ZQWrdb4X8vwrppUNvzULjUjCymLU9gUKtaBSYBsH0FDw5pwQOfr+Pb\n9fvOLntXqm3+Bk7sheEvkXQmnVcXbOejJbsRgbrRFYiNqkDPJjFn3+BzvsdGVaBKRFi+n2aHtqnN\nlCW7eHXBdoa9+jPXd2/A/Rc1sx2lTQbBr6/bMeHNhxQ67NNpmTw/ZysfLd1N4xqV+OLO3kVrl965\nEA5vgVFvnG33j4woR2ReK11Vqm6Hvk4ZCbMfhMvfKvw5gYeGtGB/Ugovzt1GbFSE/WTusLmbDvDk\nzE1c1KomT49sY/92+9fB7sUw+NnSM8M2Z8b77l8KnwgyUu3vXMy+kEBy9K8kIsOAV4FQ4D1jzPO5\nHm8ATAaiXds8bIyZ7WRMhbbjR1tNsMNoWyOn+VCbGC562uOLfPaG/Rw7nc7YXnFen+LyTnV5f/Hv\nvPD9Noa2qe1Vx3GJZQwsfRNTrQkfHm7OK9MXcTI1g2u7NeAvg5tTI7J4I1vKh4Vwa7/GXNG5Hq/M\n/41Plu3h67V7uWdgU8Z27054WAXbPFTIRLBi1zEe/Hwde46d4da+jXhwaIui/x2WvAmVakDbq7zf\np1E/uOCv8NPz0OhC6Di60KcNCRFeuKoDh06m8dcZ66kRGU6/Zs5NsFu1+zj3TltD+3rRvDa60x99\nE0vetPV2irLyXKBE1oZqTeyHiN73FG7fA+shO6PU9g+Ag0XnRCQUeAO4GGgNjBaR1rk2ewz4zBjT\nCbgOcKAGQTGtnWrHqDe9yN7ucJ0tl7DT8yzgKUvsp8k+Tb0vrBYSIjw6vBV7k1KYsmRX8WMOIJOw\nDPau4rVTg3h61lba1Y3iu3v78a8r2hU7CbirVqk8z4xqy/f39aNrw6r8c/ZWhry+nMMxXTHxC7w+\nTmpGFs99t5lr3l6CMfDp+F48NqJ10ZPA4W0Q/wN0uw3KFbJj/8K/2to33z0AR7YX6fTlw0J468Yu\nNK1ZmTs/Xs3mfSeKdJyC7Dx8ilsnryA2KoJJY7v+Ucf/5AHY+IUdMlsh2pFzO6Zhb9jzK2RnFW6/\nsyuSaSLwpDsQb4zZaYxJB6YDo3JtY4CcHrgoYJ+D8RReynE7Dr7tVX+UOG42BCpUtc1DuaxLSGJt\nQhJ/6tmw0J11fZpWp3+LGrz+YzzHT6f7Inq/27L/BCumPUuSqcTc8oN4f2xXPrqlO61ii7EKWQGa\n1Yrkg3HdmXJzd8LDQpiYGIcc3c7WLZsK3HddQhIjXl/Muz//zg09GjDnvn7FX/hj6UQIDYeuNxd+\n35BQW501LBw+H2ebHIqgSkQ5PhjXjciIMMZ9uJy9Pq7yefhkGmM/WI6I8OG47ufOX1j+ri2z0PMO\nn57TL+L6QmoyHCz4tXOOxOV2nkQetaNKAycTQV0gwe12ous+d08BY0QkEZgNeLwmE5HxIrJSRFY6\nNjLIk01fQ1bauZfpYeE2Mc1r36kAACAASURBVGz9zr5o3ExZsptK5UO5skvR2mYfubgVp9Myef3H\n+OJE7XeHTqby8Bfruf21L+iS8gsJja7hmz8PYVCrWn4bvXJB8xrMvrcfnQZcAcDkjyfxwGfrOHji\n/DfT9MxsXpq3jSsm/srptEym3Nydf1zWjkrhxWwpPXMM1k23s5uLWvOoSh3bR3Bwgx1WWkSxURX4\ncFx3zqRncdOk5SR7GOJaFKfTMrll8goOn0zj/bFdzx32nJFiO1xbDodqjX1yPr/KmU+wu5BlqRNX\nQr0SPkS2AIGubTAa+NAYUw+4BPhIRM6LyRjzjjGmqzGma40afiwqtm66LZYW2/Hc+zuMhsxU2ynq\ncux0Ot+u38cVnevl3SlYgBa1I7mma30+WrqL3UdPFydyv0jNyOKNhfEMeHERM1Yl8kL9pYSEhNLu\n8ocCUjYjLDSESwcNIDuyDmNr7uDbdfvo/+IiXp2/nZR0e7m/Zf8JRr3xC6//GM9lHevy/f0XcEFz\nH72mVk6CzJTir77WfKgdVrriXdjybZEP06J2JO/c2JXdR89w20crScssZJNHLplZ2UyYupqNe5P5\n7+jO53ekr5sOKcd8s/pcIETXt5/sdy32fp/kvXZgRCluFgJnO4v3AvXdbtdz3efuFmAYgDFmiYhE\nANWBQw7G5Z2jOyBhqS1tnPtTbd3OENPMrozl6hD7dEUC6ZnZ/KlX8UoD/2Vwc75Zu48Xvt/GGzcU\nc01fhxhjmLV+P8/P2crepBQGt67F3wfVpdHk8dD6MogK4MgnEUKaDqLllpnMv78Pz8/bzn/m/8a0\n5XsY0qYW05bvIapCOd65sQtD2hR9ott5MtNts0jjAVArd1dYEVz0lG2v/uZuiO1Q6BINOXo1ieHF\nq9tz3/S1/PnTtVzbrWjHAZi5dh8Ltx3mucvbnl/1NDvb1pWK7VD8Kp6B1LAv/Pa9HfTgzdVszkSy\n+poI8rICaCYijbAJ4Drg+lzb7AEGAR+KSCsgAvBj208+1n8KiOdiaSK2uWjBM3Dsd7Ki4/h46W56\nNY45d1x7EdSsEsH4Cxrz6oLt3Lz7OF0alqzKkmv2HOfZWZtZvSeJVrFVePGq9vRuWt2OFEk/Cb1K\nwKfBpoNgzUc0SN3Kmzd0Z/nvx/jHd5uZsmQ3w9vF8uxlbalWycfLWm760pYYGPVf3xwvrDxcNQne\nugBm3ALjZhd5jPqojnU5kJzKv+ZsZfaGA8UK6+4BTbihh4cPOzsWwJHf4PJ3fLfsYyDE9YF1U+Hw\nVqjpRZXfxBUQFgG1fFvWxN8cSwTGmEwRmQDMxQ4NnWSM2SQizwArjTEzgQeAd0Xkz9iO45tMSSio\nk51tO4Mb97dttp60uwYWPAvrP2NBjbHsTUrh8RG+KQ89/oLGTF2+h3/O3sKMO3r5fZZobsYY1icm\nM+mX3/lm7T6qVw7n/65sx1Vd6tv67tlZsGwi1O8JdbsENFbADr+UEFtuon53ujeqxtd39WHX0dN/\nTPryJWPsBKrqLexcBl+p1hgufQW+uAUW/hMuKvqKdrdf2ISBLWtyIjWzyMeoFB5Ki7w+6Cx5AyrX\nhjaXF/n4JYJ73SFvE0Fsx5K9XrYXHJ1H4JoTMDvXfU+4/bwZ6ONkDEWyZwkk7YEB+XTWRde3Y7/X\nTWNKxQuJjYrgola+GTVQKTyMvwxuziNfbmDupgMMaxvrk+MWhjGGTftOMGv9fr7bsI+EYymEh4Uw\nYUBT7ujfhMruHatbZ9nna0j+9eb9pmI1qNPZfkod8Ahgh+g6kgTAdi4eWA8jXvF95dN2V8HvP9kl\nLhv1s4vwFFFxr1bzdHCzHU496IlS/4ZI1TiIrGP/pgXVfspMt4vR9Bjvl9CcVEqm/fnZumlQvjK0\nGpH/dh2uh6/vIOXAr4wZMtKnxb6u7lKPD375nefnbGVgy1pFr7VeSNvcFgb5/chpQkOEPk2rc8/A\nZgxtXZuoih6aJ5a8CdEN7WiRkqLpIDsLPOW4He7rpCVvQoVqdo6JE4b9nx2r/uXtcNeSklfvfumb\n56+5UFqJ2OahnT8V3E9wYL0dVVjKO4oh8KOGSp6MFDtstPWoguvVtLqU9JAIrg5bzLXd6ue/bSGF\nhYbwyMWt2HX0DFOX7fbpsXOLP3SKV+b/xuCXf2LoK//jjYXx1ImO4F9XtGPFoxcx5ebuXNO1vuck\nsHeV7VTvcYcdB19SNBloq8Xu/MnZ8xzdAdtm23kDTq25UL6i7S84cxQW/cuZcxTVqcOw/jPbZ1ax\nmHMwSoqGfeD0IThawDDusxVHS/fQUdArgvNt/c52enrx6e4UEfyY1Z1R5ZZRITzb56H0b1GDPk1j\neHXBdi7vXI+ofEpaF9buo6eZtX4/367bx9YDJxGB7nHVeHZUG4a1jfV+FvCSN6F8pJ1JWpLU7Qrh\nUbZ5qM1lzp1n2dt2zYUilJAulFptbLJZOQm63w41mjt7Pm+tnGQ/FZfWIaOe5NQd2rUYqjfLe7uE\n5VClnq18W8rpFUFu66bZqokN+xa46VerE/k0ow8Vsk/ZGcg+JiI8cnErklIymLhoR7GPl3j8DG//\ntINLX1/MhS8u4sW526gUHsaTl7Zm6SOD+PT2XtzYK877JJC8FzZ/bYfQRjg3e7hIQsOg8QUQ/yM4\nNf4gJcmuudD2ymKtueC1/g9DuYow/ynnz+WNjFQ716HZkPzfMEubmKZQqWbBE8sSV5b6YaM59IrA\n3ckDtshc378U2OlnjGHykt1Uju2FyaiLrJsOba/weUht60Zxece6TPrld8b0bEC9PJa1TM3IOlsL\nP+d7zuIpObX+c2rid6gXxaOXtOKS9rHUjS5Gc8byd2zzixfr0QZEk0F2QtaR7c58gl49GTJO+2/I\nbKXq0O/Pdtjyrl9sW3YgbZxhCzKWpasB+KOfYNcvefcTnDwAyXug553+j88BmgjcbfjcvrF50Sy0\nZOdR4g+d4sWr2iNJ18Avr9k1ar1YvaywHhjagu827OfpbzczvF3suYu3uL57WiWreuXy1I6KoGFM\nJXo1jqFBTCUGt6pFgxgfrJGcdgpWfQCtLoWqxZtE55icETY7Fvg+EWRlwrKcNRc6+PbY+el5l10C\nc95jcOsCx9ZnLpAxtlmwZhs7zLqsadgHNn0Fx3dBNQ9rnZSBQnPuNBHkMMbOFK7b1avL3Cm/7qZq\nxXJc2qEOJI22w/s2fO5ITfK60RW4pW8j3ly0gx82HwTOXTe3U4Po89bNrVUlwtly1uum2VpLPUtw\nDfaqDe1lfvwC339y2/INnEiES1707XELUq4CDHwcvr7DTmJrV4hS1770+092fWi3NRfKFPf1CTwl\ngsQVEFq+SCvKlUSaCHIc2GBf2MNfKnDTvUkpzNt8gPEXNLFvtjVa2HHr66Y5tjjFnwc358LmNYip\nHE5sVETxC6QVR3a2rbJZt0vJX4+2ySBYPQUy02zBQF9Z8qad8NV8mO+O6a3218LSN2DB0/aKzJe/\nl7eKsuZCaVK9hR0SvOsXzwMhElfYK8FAPPcO0M7iHOumQ0g5aFNwO3/OcM4berjVbekw2iaTAxsd\nCa9caAg9GsfQtGblwCYBgO1z4dgO20xR0j8NNhloC8HtWeK7YyYsh70rocedgWmaCQmxq38l7bH9\nNP52ZLt9DXS7tfBrLpQWISG2ZtJuDwXosjJg35oyMWw0hyYCcC1H+Rm0GFbgWOi0zCyme1qKsu2V\nNpF4WKegzFnyBlSpa+dalHRxfe3fpRCL1RRoyRsQEQUdc5fO8qMmA6DpYDtp7swx/5777JoLt/j3\nvP4W19cm26SEc+8/sMFWH67XNTBxOUATAZy7HGUBZm/Yz9HT6edXGXVfxjKr6PVcSrz962HXz3ak\nUGlYqDu8MjToaf/GvnB8N2yZCV1uKtIi8z41+BlIOwn/+7f/znnmmF21rzhrLpQWea1PkLjSfi/p\nzaKFoIkA7Kf4ijH2E1YBJv/qWoqyiYdp/meXsVzk+xhLiqUTXevRjg10JN5rOggObrRD/opr+TuA\nQPcSUF+mVmvbfr38HTi20z/nXPWBb9ZcKA1qtbFXfuclguW2HlFU0RagKok0EaQkwdbZ5y5HmQf3\npShDQjy0jZ9dxnKqQ8EG2MkD9oqn0w2laz3as8NIPa8z7bW0k7bjuc1lJedNYMCj9spswTPOn8vX\nay6UdCGh0KC37TB2l7C8TDULgSYCO1Y4K82ruQMFLkWZzzKWZcKK9+x6tD1K2Xq0tdrZES47itlP\nsOZjSDtRsobMRtaG3vfa13HCCmfPtflrOLnfsZFxJVJcHzswIudq8tQhSNpdppqFQIeP/rEcZZ1O\n+W6WsxTlNV0LWIqyw2g77X7zN2dXLysTctajbXExxDQJdDSFExJirwri58PhbUBRRjoZWPYW1O8B\n9UrAmgvuet9jm2zmPQY3f+/MSK6zay409+2aCyVdzmpruxbbORtnC82VjYlkOYI7ERzbmfdylG6M\nMfxr9hbXUpRx+R/TwzKWpV5WJsz6i61+WVrbhpsOtqvOvVHMT3KD/dAEU1jhlWHA3+Hb++zaEK0u\n9e3xjbEd0vvXwoj/BG42cyDU7mCLKu7+5Y9EEFLOv7PJ/SC4E8G66YDY1cby8eqC7Xy+KpF7Bjal\neUGLe4jYZqYfn4Vjv3uelViapJ+BGePsOq4XPmwXRymN2lxuZ+Vmphb9GOGRth+oJOo4xnbk//Ck\nneTmqxFd2dnw/d9sh3T7a6FTGflw463QMGjQ449+goQVULudcyXHAyR4E4H7cpT5LLb+2YoEXpm/\nnSs71+Mvg72sV9P+WvjxH7ZOe/+/+STcgDhzDKZeaz8FDX8ZupXiceOhYQUvNFSahYbZSWZTr4aV\nH/hm1azMNPjqdtv/0GuCPX4wXQ3kaNgH4p+GE/th3+qyc6XvJgj/qi4JS+1kkXzmDizadohHvtpA\nv2bVef7Kdt6vHey2jKVjJZCdlpwIk4bZ5oBrJpfuJBAsmg2GRhfYxWuKO1gh9QR8cpVNAoOfhaHP\nBWcSgD/qDq14DzLOlLn+AQjmRLBumh0Pn8enxA2Jydz1yWpa1Ipk4pgulCvsMpQdRsPx3yFhmQ+C\n9bNDW+D9IXaEyI1flY4ZxMo2Sw5+FlKO2SKIRXXyIHw4HHb/Cpe/DX3u9V2MpVGdTnYdiBXv2tua\nCMqIApajTDh2hnEfrqBqxfJ8OK7buQu1e6vVSPviKW0lJ/Yss1cC2ZkwbvYfn4ZU6VCnI7S/zhaF\ny10awRtHd8CkIXaZxtGfOrcOc2kSWs4OF01Nhsq1ILpBwfuUMsGZCLZ+Z8eDdzy/Wej46XTGfrCc\n9MwsJt/cjZpVilhUK7yyTQYbv7IrOZUG2+bAlJF2lvUt82ynmCp9Bj5mv//4j8Ltt28tTBpqm4XG\nfgvNLvJ9bKVVzoqF9bqV/EKLRRCciWDddLvWaK7lKFMzsrh1ykoSj6fw3thuNK1ZwAihgnS4DtKS\n7eLmxXH4N5h5L7zZ217ypyQV73ierP4Ipt8ANVvbJFA1zvfnUP4RXd+umrZ+un1z98aOhbY5KKyC\n/fuXsZmzxZYzn6AMNgtBMCaCkwfsDNMO157T+ZWVbbhv+hpW7znOK9d2pHuj/KuQeqXRBbZK57rp\nhd/XGDtkbep18EY3OwY+LNyuV/ufNvD9I7YAWnHljBGfOcGOoBr7rV0SUZVuff9sr+zmPVbwgIUN\nM+CTqyG6oU0CZWn9YV9p0BMuetrz2gRlQPAlgrPLUf7RLGSM4dlZm5m76SCPDW/NJe1ifXOukFBb\npTF+vp2a7o2sTNj4Bbw7ED68xBa4uvBhuH8jjF8It/8MLUfYcd2vdYLPx8He1UWLLzsb5vzNznlo\nfy2Mnh74iprKNyKi7Otm18+wfV7e2y19C764xbaBj5sNVXz02i9rQkKh7/1l9kNS8CWCddPPW47y\nvZ9/58Nfd3FL30bc0tfHE8DaXwcmyyag/KSdtBOCXusEM262HVMj/gN/3gQDHvmj5G9se7jibbhv\nva35Ej8f3h0AHwyHbd/bN3dvZKbZN4Dlb9sx4pe9VWDRPVXKdB0H1ZrAD0+cXxrdGHt1+f3f7AeL\nMV+WrkKCyqeCKxHsX2/LEbuNhJi5bh/Pzd7C8PaxPHpJK9+fs6arjlFeo4dO7Hdr7nnYTm67bipM\nWAldb857BmNUXRjyrE0UQ56zi2xPuxbe7AGrJuffQZ16wjYFbPpSx4iXZaHlYPDTcHgrrP34j/uz\nMuGbCba/qctNcM2UsrvSmPJKcP335yxH2fZKAJbsOMqDn62je1w1Xrq6g+fS0r7Q4frzl7E8uBm+\nvgteaQe/vGpL+966wBYNaznc+zfmiCrQewLctxaufN8mjm/vhVfawk8vwOmj525/6pDtFNy12F4F\nBPsY8bKu5Qio3xN+fA7STtmSIZ/eYBPDhQ/DiFdss4cKamJK2czXrl27mpUrVxZ+x6xMeLml7fS5\n9mN+O3iSKyf+Sq0qEcy4oxfRFR1sFjl9FF5qbss3N70Ifn3ddliXqwidboSed/quJpExtl3419dt\n23BYBbt+QM76wh9dYRfPuWaKnYmqyr7ElfDeILvG8t5VrpIhL+ls8SAjIquMMR6HgwVPrSG35SgP\nJKcydtJyKpQL5cNx3ZxNAmCXsWw2FJb8135VrgWDnoAu4wpcI7nQROxopUYXwKGt9nyrp8CK96F8\nZdtcMPZbHR4YTOp1tUX3lk2E0PK2ZIjOFldugicRnDoA1Rpzon5/bnp3OSdSMvjsjl7Uq1qx4H19\noc99dhJbh+ug3dV2KKjTaraEUf+FgY/bUUYJy2zxuBpeFs9TZcdFT9u+ob5/Lr0VZJVjgqdpCEjP\nyGTc5JUs23mMD8Z1o1+zMr74tlJKuWjTEHauwN++3Mgv8Ud56eoOmgSUUsolaEYNvbloB1+t2cuD\nQ5rnveawUkoFIUevCERkGPAqEAq8Z4x53sM21wBPAQZYZ4y53olYLutUF2MMdw9o6sThlVKq1HIs\nEYhIKPAGMBhIBFaIyExjzGa3bZoBjwB9jDHHRaSmU/HUja7AhIFaQ0UppXJzsmmoOxBvjNlpjEkH\npgO5x6zdBrxhjDkOYIzxsiCPUkopX3EyEdQF3FfGSHTd56450FxEfhGRpa6mpPOIyHgRWSkiKw8f\nPuxQuEopFZwC3VkcBjQD+gOjgXdF5LzKV8aYd4wxXY0xXWvU0NE+SinlS14lAhH5UkSGi0hhEsde\noL7b7Xqu+9wlAjONMRnGmN+B37CJQSmllJ94+8b+JnA9sF1EnheRFl7sswJoJiKNRKQ8cB0wM9c2\nX2OvBhCR6timop1exqSUUsoHvEoExpj5xpgbgM7ALmC+iPwqIuNEpFwe+2QCE4C5wBbgM2PMJhF5\nRkRGujabCxwVkc3AQuAhY8xRT8dTSinlDK9LTIhIDDAGuBHYB3wC9AXaGWP6OxVgbsUpMaGUUsGq\n2CUmROQroAXwEXCpMWa/66FPRUTflZVSqhTzdkLZa8aYhZ4eyCvDKKWUKh287Sxu7T6sU0Sqishd\nDsWklFLKj7xNBLcZY5JybrhmAt/mTEhKKaX8ydtEECoiZxf0ddURcnhZL6WUUv7gbR/B99iO4bdd\nt2933aeUUqqU8zYR/A375n+n6/YPwHuORKSUUsqvvEoExphsYKLrSymlVBni7TyCZsC/gNZARM79\nxpjGDsWllFLKT7ztLP4AezWQCQwApgAfOxWUUkop//E2EVQwxizAlqTYbYx5ChjuXFhKKaX8xdvO\n4jRXCertIjIBW066snNhKaWU8hdvrwjuAyoC9wJdsMXnxjoVlFJKKf8p8IrANXnsWmPMg8ApYJzj\nUSmllPKbAq8IjDFZ2HLTSimlyiBv+wjWiMhM4HPgdM6dxpgvHYlKKaWU33ibCCKAo8BAt/sMoIlA\nKaVKOW9nFmu/gFJKlVHeziz+AHsFcA5jzM0+j0gppZRfeds0NMvt5wjgcuy6xUoppUo5b5uGvnC/\nLSLTgMWORKSUUsqvvJ1QllszoKYvA1FKKRUY3vYRnOTcPoID2DUKlFJKlXLeNg1FOh2IUkqpwPCq\naUhELheRKLfb0SJymXNhKaWU8hdv+wieNMYk59wwxiQBTzoTklJKKX/yNhF42s7boadKKaVKMG8T\nwUoReVlEmri+XgZWORmYUkop//A2EdwDpAOfAtOBVOBup4JSSinlP96OGjoNPOxwLEoppQLA21FD\nP4hItNvtqiIy17mwlFJK+Yu3TUPVXSOFADDGHEdnFiulVJngbSLIFpEGOTdEJA4P1UiVUkqVPt4O\nAX0UWCwiPwEC9APGOxaVUkopv/G2s/h7EemKffNfA3wNpDgZmFJKKf/wtrP4VmAB8ADwIPAR8JQX\n+w0TkW0iEi8ieY46EpErRcS4ko1SSik/8raP4D6gG7DbGDMA6AQk5beDiIQCbwAXA62B0SLS2sN2\nka7jLytE3EoppXzE20SQaoxJBRCRcGPMVqBFAft0B+KNMTuNMenYiWijPGz3LPB/2ElqSiml/Mzb\nRJDomkfwNfCDiHwD7C5gn7pAgvsxXPedJSKdgfrGmO/yO5CIjBeRlSKy8vDhw16GrJRSyhvedhZf\n7vrxKRFZCEQB3xfnxCISArwM3OTF+d8B3gHo2rWrDltVSikfKnQFUWPMT15uuheo73a7nuu+HJFA\nW2CRiADUBmaKyEhjzMrCxqWUUqpoirpmsTdWAM1EpJGIlAeuA2bmPGiMSTbGVDfGxBlj4oClgCYB\npZTyM8cSgTEmE5gAzAW2AJ8ZYzaJyDMiMtKp8yqllCocRxeXMcbMBmbnuu+JPLbt72QsSimlPHOy\naUgppVQpoIlAKaWCnCYCpZQKcpoIlFIqyGkiUEqpIKeJQCmlgpwmAqWUCnKaCJRSKshpIlBKqSCn\niUAppYKcJgKllApymgiUUirIaSJQSqkgp4lAKaWCnCYCpZQKcpoIlFIqyGkiUEqpIKeJQCmlgpwm\nAqWUCnKaCJRSKshpIlBKqSCniUAppYKcJgKllApymgiUUirIaSJQSqkgp4lAKaWCnCYCpZQKcpoI\nlFIqyGkiUEqpIKeJQCmlgpwmAqWUCnKaCJRSKshpIlBKqSCniUAppYKco4lARIaJyDYRiReRhz08\n/hcR2Swi60VkgYg0dDIepZRS53MsEYhIKPAGcDHQGhgtIq1zbbYG6GqMaQ/MAF5wKh6llFKeOXlF\n0B2IN8bsNMakA9OBUe4bGGMWGmPOuG4uBeo5GI9SSikPnEwEdYEEt9uJrvvycgswx9MDIjJeRFaK\nyMrDhw/7MESllFIlorNYRMYAXYEXPT1ujHnHGNPVGNO1Ro0a/g1OKaXKuDAHj70XqO92u57rvnOI\nyEXAo8CFxpg0B+NRSinlgZNXBCuAZiLSSETKA9cBM903EJFOwNvASGPMIQdjUUoplQfHEoExJhOY\nAMwFtgCfGWM2icgzIjLStdmLQGXgcxFZKyIz8zicUkophzjZNIQxZjYwO9d9T7j9fJGT51dKKVWw\nEtFZrJRSKnA0ESilVJDTRKCUUkFOE4FSSgU5TQRKKRXkNBEopVSQ00SglFJBThOBUkoFOU0ESikV\n5DQRKKVUkNNEoJRSQU4TgVJKBTlNBEopFeQ0ESilVJDTRKCUUkFOE4FSSgU5TQRKKRXkNBEopVSQ\n00SglFJBThOBUkoFOU0ESikV5DQRKKVUkNNEoJRSQU4TgVJKBTlNBEopFeQ0ESilVJDTRKCUUkFO\nE4FSSgU5TQRKKRXkNBEopVSQ00SglFJBThOBUkoFOU0ESikV5DQRKKVUkNNEoJRSQc7RRCAiw0Rk\nm4jEi8jDHh4PF5FPXY8vE5E4J+NRSil1PscSgYiEAm8AFwOtgdEi0jrXZrcAx40xTYH/AP/nVDxK\nKaU8c/KKoDsQb4zZaYxJB6YDo3JtMwqY7Pp5BjBIRMTBmJRSSuUS5uCx6wIJbrcTgR55bWOMyRSR\nZCAGOOK+kYiMB8a7bp4SkW1FjKl67mOXMBpf8Wh8xVfSY9T4iq5hXg84mQh8xhjzDvBOcY8jIiuN\nMV19EJIjNL7i0fiKr6THqPE5w8mmob1Afbfb9Vz3edxGRMKAKOCogzEppZTKxclEsAJoJiKNRKQ8\ncB0wM9c2M4Gxrp+vAn40xhgHY1JKKZWLY01Drjb/CcBcIBSYZIzZJCLPACuNMTOB94GPRCQeOIZN\nFk4qdvOSwzS+4tH4iq+kx6jxOUD0A7hSSgU3nVmslFJBThOBUkoFuTKZCEpyaQsRqS8iC0Vks4hs\nEpH7PGzTX0SSRWSt6+sJf8XnOv8uEdngOvdKD4+LiLzmev7Wi0hnP8bWwu15WSsiJ0Tk/lzb+P35\nE5FJInJIRDa63VdNRH4Qke2u71Xz2Hesa5vtIjLW0zYOxPaiiGx1/f2+EpHoPPbN97XgcIxPiche\nt7/jJXnsm+//u4PxfeoW2y4RWZvHvn55DovFGFOmvrAd0zuAxkB5YB3QOtc2dwFvuX6+DvjUj/HF\nAp1dP0cCv3mIrz8wK4DP4S6gej6PXwLMAQToCSwL4N/6ANAw0M8fcAHQGdjodt8LwMOunx8G/s/D\nftWAna7vVV0/V/VDbEOAMNfP/+cpNm9eCw7H+BTwoBevgXz/352KL9fjLwFPBPI5LM5XWbwiKNGl\nLYwx+40xq10/nwS2YGdYlyajgCnGWgpEi0hsAOIYBOwwxuwOwLnPYYz5H3bkmzv319lk4DIPuw4F\nfjDGHDPGHAd+AIY5HZsxZp4xJtN1cyl2nk/A5PH8ecOb//diyy8+13vHNcA0X5/XX8piIvBU2iL3\nG+05pS2AnNIWfuVqkuoELPPwcC8RWScic0SkjV8DAwPME5FVrvIeuXnzHPvDdeT9zxfI5y9HLWPM\nftfPB4BaHrYpCc/lzdgrPE8Kei04bYKr+WpSHk1rJeH56wccNMZsz+PxQD+HBSqLiaBUEJHKwBfA\n/caYE7keXo1t7ugAHIBI2QAAA9tJREFUvA587efw+hpjOmMrx94tIhf4+fwFck1SHAl87uHhQD9/\n5zG2jaDEjdUWkUeBTOCTPDYJ5GthItAE6Ajsxza/lESjyf9qoMT/P5XFRFDiS1uISDlsEvjEGPNl\n7seNMSeMMadcP88GyolIdX/FZ4zZ6/p+CPgKe/ntzpvn2GkXA6uNMQdzPxDo58/NwZwmM9f3Qx62\nCdhzKSI3ASOAG1yJ6jxevBYcY4w5aIzJMsZkA+/mce6AvhZd7x9XAJ/mtU0gn0NvlcVEUKJLW7ja\nE98HthhjXs5jm9o5fRYi0h37d/JLohKRSiISmfMztlNxY67NZgJ/co0e6gkkuzWB+Euen8IC+fzl\n4v46Gwt842GbucAQEanqavoY4rrPUSIyDPgrMNIYcyaPbbx5LTgZo3u/0+V5nNub/3cnXQRsNcYk\nenow0M+h1wLdW+3EF3ZUy2/Y0QSPuu57BvuiB4jANinEA8uBxn6MrS+2iWA9sNb1dQlwB3CHa5sJ\nwCbsCIilQG8/xtfYdd51rhhynj/3+AS76NAOYAPQ1c9/30rYN/Yot/sC+vxhk9J+IAPbTn0Ltt9p\nAbAdmA9Uc23bFXjPbd+bXa/FeGCcn2KLx7at57wGc0bR1QFm5/da8OPz95Hr9bUe++YemztG1+3z\n/t/9EZ/r/g9zXndu2wbkOSzOl5aYUEqpIFcWm4aUUkoVgiYCpZQKcpoIlFIqyGkiUEqpIKeJQCml\ngpwmAqX8yFUZdVag41DKnSYCpZQKcpoIlPJARMaIyHJXDfm3RSRURE6JyH/EriOxQERquLbtKCJL\n3Wr7V3Xd31RE5ruK360WkSauw1cWkRmu9QA+8VflW6XyoolAqVxEpBVwLdDHGNMRyAJuwM5oXmmM\naQP8BDzp2mUK8DdjTHvsTNic+z8B3jC2+F1v7MxUsBVn7wdaY2ee9nH8l1IqH2GBDkCpEmgQ0AVY\n4fqwXgFbMC6bP4qLfQx8KSJRQLQx5ifX/ZOBz131ZeoaY74CMMakAriOt9y4atO4VrWKAxY7/2sp\n5ZkmAqXOJ8BkY8wj59wp8niu7YpanyXN7ecs9P9QBZg2DSl1vgXAVSJSE86uPdwQ+/9ylWub64HF\nxphk4LiI9HPdfyPwk7GrzyWKyGWuY4SLSEW//hZKeUk/iSiVizFms4g8hl1VKgRbcfJu4DTQ3fXY\nIWw/AtgS02+53uh3AuNc998IvC0iz7iOcbUffw2lvKbVR5XykoicMsZUDnQcSvmaNg0ppVSQ0ysC\npZQKcnpFoJRSQU4TgVJKBTlNBEopFeQ0ESilVJDTRKCUUkHu/wEuZG06hyAmtgAAAABJRU5ErkJg\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WO8UoGF2xeU",
        "colab_type": "text"
      },
      "source": [
        "## 分類 (mnist)\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "### [try]\n",
        "-  load_mnistのone_hot_labelをFalseに変更しよう (error)\n",
        "-  誤差関数をsparse_categorical_crossentropyに変更しよう\n",
        "-  Adamの引数の値を変更しよう\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2wYkCR82xeV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7de16bec-edfa-4eb7-a8e9-76e02b7719b9"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from data.mnist import load_mnist\n",
        "\n",
        "(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "# 必要なライブラリのインポート、最適化手法はAdamを使う\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# モデル作成\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "# バッチサイズ、エポック数\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, d_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, d_test))\n",
        "loss = model.evaluate(x_test, d_test, verbose=0)\n",
        "print('Test loss:', loss[0])\n",
        "print('Test accuracy:', loss[1])\n",
        "#Accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.ylim(0, 1.0)\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_18 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.2553 - acc: 0.9225 - val_loss: 0.0959 - val_acc: 0.9715\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1030 - acc: 0.9688 - val_loss: 0.0760 - val_acc: 0.9765\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0722 - acc: 0.9764 - val_loss: 0.0674 - val_acc: 0.9792\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0557 - acc: 0.9817 - val_loss: 0.0688 - val_acc: 0.9795\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0472 - acc: 0.9851 - val_loss: 0.0593 - val_acc: 0.9811\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0377 - acc: 0.9874 - val_loss: 0.0646 - val_acc: 0.9822\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0326 - acc: 0.9896 - val_loss: 0.0686 - val_acc: 0.9815\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0293 - acc: 0.9900 - val_loss: 0.0796 - val_acc: 0.9794\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0291 - acc: 0.9901 - val_loss: 0.0732 - val_acc: 0.9808\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0255 - acc: 0.9910 - val_loss: 0.0700 - val_acc: 0.9815\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0237 - acc: 0.9919 - val_loss: 0.0762 - val_acc: 0.9811\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0210 - acc: 0.9930 - val_loss: 0.0675 - val_acc: 0.9835\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0194 - acc: 0.9934 - val_loss: 0.0675 - val_acc: 0.9836\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0212 - acc: 0.9930 - val_loss: 0.0687 - val_acc: 0.9833\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0166 - acc: 0.9941 - val_loss: 0.0754 - val_acc: 0.9824\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0189 - acc: 0.9936 - val_loss: 0.0735 - val_acc: 0.9840\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0154 - acc: 0.9948 - val_loss: 0.0854 - val_acc: 0.9840\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0166 - acc: 0.9943 - val_loss: 0.0887 - val_acc: 0.9817\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0153 - acc: 0.9947 - val_loss: 0.0715 - val_acc: 0.9826\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0141 - acc: 0.9957 - val_loss: 0.0836 - val_acc: 0.9824\n",
            "Test loss: 0.08355475019063051\n",
            "Test accuracy: 0.9824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXycdbnw/8+VrdmTZumSJt1ogbZQ\nWihlESyLaAvKLrIKqBRFjvgcUeBRUXsefugRPRxFRcQqyE5ZRC07LRwOW1dK95ayzCRd0mbfM8n1\n++N7TzJNJ+20yWSSmev9es0r9z7XTJK55rveoqoYY4wxPSXFOgBjjDGDkyUIY4wxYVmCMMYYE5Yl\nCGOMMWFZgjDGGBOWJQhjjDFhWYIwBhCRv4rI/4vw2I9F5HPRjsmYWLMEYYwxJixLEMbEERFJiXUM\nJn5YgjBDhle1830RWSMijSLyZxEZKSLPi0i9iLwiIsNDjj9XRNaJSI2ILBWRKSH7ZorISu+8x4H0\nHs/1RRFZ7Z37lohMjzDGc0RklYjUiYhPRH7aY/8p3vVqvP3XeNszRORXIvKJiNSKyJvettNExB/m\nffict/xTEVkkIg+JSB1wjYjMFpG3vefYLiL3iEhayPnTRORlEakSkZ0i8n9FZJSINIlIYchxx4pI\npYikRvLaTfyxBGGGmouAs4DDgS8BzwP/FyjG/T1/B0BEDgceBb7r7VsM/ENE0rwPy2eBvwEFwJPe\ndfHOnQksBK4HCoE/As+JyLAI4msEvgrkA+cA3xKR873rjvPi/a0X0wxgtXfeXcBxwMleTD8AOiN8\nT84DFnnP+TDQAfwfoAg4CTgTuMGLIQd4BXgBKAEmAa+q6g5gKXBJyHWvAh5T1fYI4zBxxhKEGWp+\nq6o7VbUc+B/gXVVdpaotwDPATO+4rwD/UtWXvQ+4u4AM3AfwiUAqcLeqtqvqImBZyHPMB/6oqu+q\naoeqPgC0euftl6ouVdUPVLVTVdfgktQcb/flwCuq+qj3vHtUdbWIJAFfA25S1XLvOd9S1dYI35O3\nVfVZ7zmbVXWFqr6jqgFV/RiX4IIxfBHYoaq/UtUWVa1X1Xe9fQ8AVwKISDJwGS6JmgRlCcIMNTtD\nlpvDrGd7yyXAJ8EdqtoJ+IAx3r5y3Xumyk9ClscB3/OqaGpEpAYo887bLxE5QUSWeFUztcA3cd/k\n8a7xYZjTinBVXOH2RcLXI4bDReSfIrLDq3b6/yKIAeDvwFQRmYArpdWq6nuHGJOJA5YgTLyqwH3Q\nAyAigvtwLAe2A2O8bUFjQ5Z9wB2qmh/yyFTVRyN43keA54AyVc0D7gWCz+MDDgtzzm6gpZd9jUBm\nyOtIxlVPheo5JfMfgI3AZFXNxVXBhcYwMVzgXinsCVwp4iqs9JDwLEGYePUEcI6InOk1sn4PV030\nFvA2EAC+IyKpInIhMDvk3D8B3/RKAyIiWV7jc04Ez5sDVKlqi4jMxlUrBT0MfE5ELhGRFBEpFJEZ\nXulmIfBrESkRkWQROclr89gMpHvPnwr8CDhQW0gOUAc0iMiRwLdC9v0TGC0i3xWRYSKSIyInhOx/\nELgGOBdLEAnPEoSJS6q6CfdN+Le4b+hfAr6kqm2q2gZciPsgrMK1Vzwdcu5y4DrgHqAa2OodG4kb\ngAUiUg/cjktUwet+CpyNS1ZVuAbqY7zdNwMf4NpCqoBfAEmqWutd835c6acR2KtXUxg34xJTPS7Z\nPR4SQz2u+uhLwA5gC3B6yP7/xTWOr1TV0Go3k4DEbhhkjAklIq8Bj6jq/bGOxcSWJQhjTBcROR54\nGdeGUh/reExsWRWTMQYAEXkAN0biu5YcDFgJwhhjTC+sBGGMMSasuJnYq6ioSMePHx/rMIwxZkhZ\nsWLFblXtObYGiKMEMX78eJYvXx7rMIwxZkgRkV67M1sVkzHGmLAsQRhjjAnLEoQxxpiw4qYNIpz2\n9nb8fj8tLS2xDiXq0tPTKS0tJTXV7u1ijOkfcZ0g/H4/OTk5jB8/nr0n7owvqsqePXvw+/1MmDAh\n1uEYY+JEXFcxtbS0UFhYGNfJAUBEKCwsTIiSkjFm4MR1ggDiPjkEJcrrNMYMnLiuYjLGmHhV19LO\nxu31bNheR2pyEpefMPbAJx0kSxBRVlNTwyOPPMINN9xwUOedffbZPPLII+Tn50cpMmPMUKCq+Kub\nWb+9jg3b61hfUceGHXX4qpq7jjl2bL4liKGopqaG3//+9/skiEAgQEpK72//4sWLox2aMWaQaWnv\nYPNOVyrYsL2+KxnUtwQAEIEJRVlML83n0uPHMnV0LlNLchmRc6CbDB4aSxBRduutt/Lhhx8yY8YM\nUlNTSU9PZ/jw4WzcuJHNmzdz/vnn4/P5aGlp4aabbmL+/PlA99QhDQ0NzJs3j1NOOYW33nqLMWPG\n8Pe//52MjIwYvzJjhqaOTuWj3Q2sq6hjXYX7Rt7UFmB4Zhp5makMz0xjeGYqed7P4Zlp5GWkMjzL\nrWekJkfc5tfRqTS0BKhvbaehNUB9S8BbD1Df0u6WWwL4qptYX1HHtt2NdHS6GbYz05KZMjqX82aU\nMHV0HlNG53DEqBwy0wbuYzthEsTP/rGO9RV1/XrNqSW5/ORL0/Z7zM9//nPWrl3L6tWrWbp0Keec\ncw5r167t6o66cOFCCgoKaG5u5vjjj+eiiy6isLBwr2ts2bKFRx99lD/96U9ccsklPPXUU1x55ZX9\n+lqMiZXmtg7aOzvJGZbS750tWto72LSj3ksGtazfXsfG7fU0t3cAkJacxBGjcsjNSGFHXQsbd9RT\n3dRGU1tHr9dMS04iP5g4MlMZnplKkggNrQHqWgI0tHQng/1dJyhJYFRuOlNG5zL3qFFMGZ3L1NG5\njC3IJCkptp1PEiZBDBazZ8/ea6zCb37zG5555hkAfD4fW7Zs2SdBTJgwgRkzZgBw3HHH8fHHHw9Y\nvMb0F1VlZ10r67fXdlefbK/joz2NqLoP3oKsNAqz0yjMHkZhVhqFWWkUZKdRlDWMwuw0CrLSKMp2\nyz2/Sdc2tbNuey3rvVLBuoo6tlY2dH0jzxmWwpSSXC6dXca0kjymleQyaUQ2qcn7duZsDXRQ29RO\ndVM7NU1tXT9rmtupbmqjprGdmma3/aPdjXQq5KSnkJeRSml+BtnDUshJTyE7PYWc9FRyhgWXU7r2\n5aSnkj0shcy0yEskAy1hEsSBvukPlKysrK7lpUuX8sorr/D222+TmZnJaaedFnYsw7Bh3fWLycnJ\nNDc373OMMYeis1NpbAuQnCQHVXVyIO0dnWzd1bBXo+r6ijqqm9q7jhlbkMmU0TmcO6OErLQUdje2\nUtXQxp5G99hW2UBVY+/f5tNTkyj0EkdVYxv+6u7/ixE5w5hWkstZU0cyrSSXaSV5lBVkRPz6hqUk\nMyI3mRG56X17I4a4hEkQsZKTk0N9ffi7N9bW1jJ8+HAyMzPZuHEj77zzzgBHZ+JBTVMbO+taqW9p\np74lQF2Pn/VdP/dervOqQoI3lUxOEu+bbQo5w1K7vuXmpqeQm5HavS89da+fuekp7Kpv3atUsGVX\nPe0d7sLDUpI4clQOX5g2iqkluUwZncuRo3LISY9sWpimtgB7GtqoamxjT2Mre7wkUtXYxu6GVqoa\n2ygryOTyE1yj7bSSPIqj1GibaCxBRFlhYSGf+cxnOOqoo8jIyGDkyJFd++bOncu9997LlClTOOKI\nIzjxxBNjGKkZ7FSV8prmkMbVWtZV1LG9tvcR9CldH/rdH/BjCzL3+nDPSU+lQ3WfRFLXEsBf3dS1\n3tAaoPMAdyguzhnG1NG5fPbwYqaW5DJ1dA7jC7NICVONE6nMtBQyC1IoK8g85GuYQxM396SeNWuW\n9rxh0IYNG5gyZUqMIhp4ifZ641mgo5Ntuxtdw6qXENZV1FHb7KpoRGBiUVZXXfqY4Rl7fejnpqeS\nk55KempSv1UbqSqNbR0hicQlkfqWAPkZqUwZnWvf3IcgEVmhqrPC7bMShDEx1tzWwaad9azzSgTr\nKurYuL2O1kAnAGleFc3ZR49iqpcQjhzg7o7gpnPJHuYaWUfnDehTmxixBGHMAGgLdPJpVRMf727k\n4z2NbNvdyMe7G/lod+NeVUQ56SlMK8nlyhPHMa3EDYI6rDh8Txtjos0ShDH9pKNTKa9u5qM93R/+\nwYe/ummv+vv8zFTGF2Zx0sRCxhdlcfjIbKaV5FE6PPKeNsZEmyUIYw5SfUs7H1Y2snVXA1t3NfBh\nZQPbKhvwVTXT1tHZdVxWWjITirOYXprH+TNKGF+UxfiiLCYUZjE8Ky2Gr8CYyEQ1QYjIXOC/gWTg\nflX9eY/944CFQDFQBVypqn5v3y+Ac7xD/0NVH49mrMaEUlV2N7S5JFDZwIdeMti6q4Eddd1VQqnJ\nwvjCLCaPyOGsqaOYUJTJhKJsxhdlUpw9zEoDZkiLWoIQkWTgd8BZgB9YJiLPqer6kMPuAh5U1QdE\n5AzgTuAqETkHOBaYAQwDlorI86rav3NlmLimqnR0KoFO72eHEujspKNTae9UOrz19g6lvKbJlQZ2\nNbK10iWCYI8hcKWBSSOyOXlSIZNGZDOpOJtJI7IZW5DZpy6cxgxm0SxBzAa2quo2ABF5DDgPCE0Q\nU4F/95aXAM+GbH9DVQNAQETWAHOBJ6IYb1Qc6nTfAHfffTfz588nMzMx+n+3BTq7uk7WNbd3D/jy\nluuaA/vsD25rDXR2JYL2js6uxHCwirLTOKw4my9OH+0SgfcYlZtupQGTcKKZIMYAvpB1P3BCj2Pe\nBy7EVUNdAOSISKG3/Sci8isgEzidvRMLACIyH5gPMHZs/8+F3h96m+47EnfffTdXXnll3CYIX1UT\nz6wq57n3K/BXN9HS3rnf45MEN7I3w/Xzz01PZVxhZld//9TkJJKThJQkcT+Tk7qWU5OF5CS3npIc\nPCbJ2y6Myk1n0ohs8jOtbcCYoFg3Ut8M3CMi1wBvAOVAh6q+JCLHA28BlcDbwD4TsqjqfcB94AbK\nDVTQByN0uu+zzjqLESNG8MQTT9Da2soFF1zAz372MxobG7nkkkvw+/10dHTw4x//mJ07d1JRUcHp\np59OUVERS5YsifVL6Rd1Le08/8F2nlpZznsfVQFw4sQCTj+i2H3oZ7gEkDOsezm4PWsQT2pmTDyK\nZoIoB8pC1ku9bV1UtQJXgkBEsoGLVLXG23cHcIe37xFgc5+ief5W2PFBny6xj1FHw7yf7/eQ0Om+\nX3rpJRYtWsR7772HqnLuuefyxhtvUFlZSUlJCf/6178AN0dTXl4ev/71r1myZAlFRUX9G/cAC3R0\n8ubW3Ty9spwX1+2gNdDJxKIsvv+FIzhvRgmlw+OzhGTMUBfNBLEMmCwiE3CJ4VLg8tADRKQIqFLV\nTuA2XI+mYAN3vqruEZHpwHTgpSjGOiBeeuklXnrpJWbOnAlAQ0MDW7Zs4dRTT+V73/set9xyC1/8\n4hc59dRTYxxp/9iwvY6nV/p5dnUFlfWt5GemcsmsMi46rpRjSvOsNGDMIBe1BKGqARG5EXgR1811\noaquE5EFwHJVfQ44DbhTRBRXxfRt7/RU4H+8D5A6XPfXQJ8COsA3/YGgqtx2221cf/31++xbuXIl\nixcv5kc/+hFnnnkmt99+ewwi7Ltd9S08t7qCp1aWezdTF04/YgQXHlvK6UcWMywlOdYhGmMiFNU2\nCFVdDCzuse32kOVFwKIw57XgejINeaHTfX/hC1/gxz/+MVdccQXZ2dmUl5eTmppKIBCgoKCAK6+8\nkvz8fO6///69zh3sVUwt7R28vH4nT6/088aW3XR0KseU5rHgvGl8cXoJBTYozJghKdaN1HEvdLrv\nefPmcfnll3PSSScBkJ2dzUMPPcTWrVv5/ve/T1JSEqmpqfzhD38AYP78+cydO5eSkpJB2Ui9tryW\nx5f5eHZ1OfUtAUbnpXP9Zydy4bFjmDQiJ9bhGWP6yKb7jiMD8Xprm9t57v0KHl/2KWvL6xiWksS8\no0bx5VllnDSxMOb30DXGHByb7tv0iaqy7ONqHlv2KYs/2E5LeydTRuey4LxpnHfMGPIyI7szmDFm\naLEEYXpVWd/KUyv9PLHMx7bdjeQMS+GiY0u59PixHDUm13ohGRPn4j5BqGpCfJD1V1VhR6fyxuZK\nHlv2Ka9u2EWgUzl+/HBuOH0SZx89asBvUmOMiZ24/m9PT09nz549FBYWxnWSUFX27NlDenr6IV/D\nV9XEk8t9PLnCz/baFgqz0vj6KRP48qwyJo3I7sdojTFDRVwniNLSUvx+P5WVlbEOJerS09MpLS09\n6PPWVdTyyxc38fpm9x7NObyYn3xpKmccOZK0FJul1JhEFtcJIjU1lQkTJsQ6jEFpV30Lv3pxM0+s\n8JGfkcpNZ07my7PKGJOfEevQjDGDRFwnCLOvlvYO/vzmR/x+yVbaOjr5+mcm8G9nTLaeSMaYfViC\nSBCqyj/XbOfnz2+kvKaZz08dyW1nT2FCUVasQzPm4KlC5Ub4cAlsWwoNO/t2vaLJMOMKmDAHkqxq\nNcgSRAJY7avhP/65nhWfVDNldC6//PJ0Tj5scE/fYSLU3gKb/gU1Puhsh84O6AxAR7v7GVzvDFnv\n2hfySE6DtGwYlu39zIG0rJBtOSH7QtZT0mGgOoDU73TJYJuXFOq3u+0Fh0HhYcAhxqGdsOVl+OBJ\nyB8LM6+CGZdD3sG36cUbSxBxrKKmmf98YSPPrq6gKHsYv7joaC4+roxkG+089O3eCiv+Aqsfhubq\nHjsFklMhKWXvR3IqJCV768H93npHO7TVQ2sDtDVAoCXs0+5Dkl2iyBkNhZPcN/HCyd3LmQWH/hrb\nmuCTt1xC+HAJ7FrntmcUwMQ5MPF0OOx096HeV+0tsPGfsPJBWHIHLL0TDjsDjv0qHD4PUhJzPrG4\nnmojUTW1Bbj39W3c98aHdCpcd+oEvnXaJLKH2feBIS3Q5j7Eli+Ej//HfbAfeQ4cdy2UzQ750O+H\nKpKOdpcoggmjtWHvBNJzvdYPe7ZC1UeutBKUURCSNA7rXi6YACnD9n7Ozg7Y/n53QvC9Cx1trnQz\n9sTuhDDqmOhWA1V95BLvqoehvgIyi+CYS13JYsSR/f98qu4Ro6qt/U21YQkijnR2Kk+vKueXL25k\nZ10rXzqmhFvmHmE35Bnqqj6ClQ/AqoegsRLyxsJxV7sPrJyRsY5ubx0BqPkEdm9xCWPPFlfa2bNl\n73YCSXLf/IOljfrt8NHr3aWhkUfBxNNcQhh7MqTF4G+4swM+fM2VKjY97xJf6fHufT/qQlcNdzBa\n62HPh+592b3Fe2+2uG3tjS4RpqS7R2p6yHKGS6YpGb1vzx8LM684pJdpCSIBvPdRFf/vX+tZ46/l\nmLJ8bv/iFI4b14fifW86Au4PfOda2LEGdqyFXevdH2xeKeSVuZ/5Zd3ruWNi8w8+lHUEYPMLrrTw\n4Wuunv/weTDrWlf1kTQE76vRUhvmA3KrW0/Pc8ngsDNcQ/FgS3wNlbDmMVj5N9i9CVKz4KgLYOZX\nXekt2A7T2eElyK0hCdJLlsE2EwDEfagHS1QZ+a5ar70FAs0QaIV272eg2dse8gg9LtDiEtc3Xjmk\nl2YJIo41tga49ekP+Mf7FYzOS+eWuUdy7jEl/TOrakst7FznksCONS4p7NrQXT+dnAbFR8LIaa5K\notYPtT73j6Cde18rszAkgQSTR0hCyR4xcI2d/S3Q5r4RJ/dDFV6t331jXfmgex9zSrpLC3lj+n79\nwUh16PzuVcG/zP1+1j7tvvkXHe4ee7ZC1TZXLRaUnu8lgUl7t9EUTHSlgf7Q2ek6GhxiO4kliDhV\nWd/K1/66jPXb6/i3MyZx/WcPIyPtEL5ZqrpvPTvWeiWDD9yj5pPuYzIL3T24Rx4Fo6bDqKPcP0Vy\nmPETHe3uw63W7x41n3YvB5NIW8Pe5xROhqO/DEdf7PVIGSRUXbVHrc/1FArGH/ozWHWSluO+CWbk\nuw+Grp/D97+clu1KCcv/AltedM856XMw62sw+fP9k3hM/2uth3XPwOpHoHF3dyIIJoGiye7/ZpAn\nP0sQcejj3Y1c/Zf32FXXyu+umMkZRx5kkbz6Y68P+RL46I2QnjDi/shHHeUlhKPdz5xR/feHrgot\nNd0Jo+oj2LQYPn4TUBhzHBx9iavnzR7RP8+5P3Xb3be/0ATWlQT80N609/Fd1WkhpSCA5hr3upqr\nQ5a99Y7WA8eRNcL1mjn2qzB8XP+/TmPCiFmCEJG5wH/j7kl9v6r+vMf+ccBCoBiowt172u/t+0/g\nHCAJeBm4SfcTbCIliDX+Gq79yzIUWHjN8cwoyz/wSc01LhEEe4hUf+S255S4ut/SWa5kMGKK6/8e\nC7V+V2z/4AlXgpEk11B59CWut056bt+fo7MTdm+GT9+CT9+BT992JZxQWSP2rQLralcpO7Rvhe3N\nvSeQlhpXTXfE2eFLZMZEUUwShIgkA5uBswA/sAy4TFXXhxzzJPBPVX1ARM4ArlXVq0TkZOCXwGe9\nQ98EblPVpb09X6IkiKWbdnHDwyspyErjwa/NZmJxLzOtBtpcXWkwIVSsdO0Cadkw/pTuLoNFhw/O\nIvCujW7g0gdPuqqulHQ4Yp6rhpp0VuT1rYE22L7aJYJP3gbfO92lpawRMO4kKDsRRk71GtRLXO8Q\nYxJErO4oNxvYqqrbvCAeA84D1occMxX4d295CfCst6xAOpCGGx6ZCvRxLP3Q99QKP7c8tYYjRuXw\nl2uPZ0ROSCOXKlRu6k4In/yvq+eXJFdlc+rNLiGMmTU0Bv2MOBLO/DGc8SPwvecSxbqnXZ1vej5M\nO98li7En791/vKUO/O+5ZPDpO1C+vLtRvXCSK4mMPdn1qy+YODiTozGDRDQTxBjAF7LuB07occz7\nwIW4aqgLgBwRKVTVt0VkCbAdlyDuUdUNPZ9AROYD8wHGju2H0ZSDgaqrjmhrcI1gbQ1oaz2LV2xh\n6Yqt3DoihStnFJC+4n+79tNc4z5E6yvcNQomwvSvuIQw/lTXEDpUicDYE9xj7p1uioU1T8CaJ2HF\nX10X2mkXuIbxT99yva60043wHT0dZn3dJYOxJw5Me4YxcSTW3SNuBu4RkWuAN4ByoENEJgFTgOBk\nKC+LyKmq+j+hJ6vqfcB94KqYBizq/hJoc9+MV/wFasvdh31bwz5dRAXXGHNOGlADvObtSM3snhun\nbLZLCBNPj98GzuRUmHyWe7Q1usFLa56Ad+91XW5Lj4fP/sAlg9Lj3ftijDlk0UwQ5UBZyHqpt62L\nqlbgShCISDZwkarWiMh1wDuq2uDtex44CdgrQQxZzTUuKbz7R9cddMRUN0Bor8nQsmlLyeIvyyp5\n/ZMWzppxGFfPOYqk9JBJ04biYKn+kpblusQefbGb7iFlmDXwGtPPopkglgGTRWQCLjFcClweeoCI\nFAFVqtoJ3Ibr0QTwKXCdiNyJ+wI9B7g7irEOjJpP4Z173bQJbQ2uh85598BhZ+5TF17b3M51Dy7n\nvY/y+NE5U7j21IkxCXlIsJKCMVERtQShqgERuRF4EdfNdaGqrhORBcByVX0OOA24U0QUV8X0be/0\nRcAZwAe4BusXVPUf0Yo16ra/D2/91nXhBDjqIjj5Rhh9TPjDa5u5ZuEytu1u4DeXzeTcY0oGMFhj\njHFsoFy0qMLWV+Gt37hJyNKy4bhr4IRvuv70vdiys56rF75HXUuA+646jpMn2X0bjDHRE6turokp\n0AZrF7kSw671bp78z/3MJYcD9CZa9nEV33hgOWkpSTx+/YlMK8kbmJiNMSYMSxD9pbnGdbt8997u\nhufz/wBHXRzRuIMX1u7gpsdWMWZ4Bg9cO5uyApv91BgTW5Yg+irQ6u5AtezPruF5whw49x6YtG/D\nc28eeucTbv/7Wo4py+fPVx9PQdYQGMhmjIl7liD6oqESHr/C3fnqqIvhM9/pteG5Ny+s3c6Pnl3L\nmUeO4J7Ljz202ViNMSYKLEEcql0b4JFLoGEXfPmvbjTvQdq6q4Gbn1zDMWX5/P7KYxmWYsnBGDN4\nWII4FFtegSevcXdJu2YxlB530JdobA3wzYdWkJaSxB+usORgjBl8YnOX7KHs3fvgkS/D8PFw3WuH\nlBxUlR88tYZtlQ3cc9lMSvJt9lBjzOBjJYhIdQTghVtg2f1u3v4L/3TII3j//OZH/GvNdm6dd6SN\nczDGDFqWICLRXAOLrnW3hTz5O/C5nx7yPEjvbNvDnc9vZO60UVz/WZs+wxgzeFmCOJCqbfDIV9zP\nc++BY6865EvtqG3hxkdWMq4wk19+eTpi9yIwxgxiliD255O34LErAIWrnoUJpx7ypdoCndzw8Aqa\n2jp49LoTyUm3mUeNMYObNVL3ZtXD8MC57v7D33i1T8kB4I5/rWflpzX88uJjmDwyp5+CNMaY6LES\nRE+dnfDaAnjzv9yo6EsegIzhfbrkM6v8PPD2J1x36gTOmT66nwI1xpjosgQRqq0RnrkeNvzDTa53\n9l19vgnN+oo6bnv6A06YUMAtc4/snziNMWYAWIIIqquARy+FHR/AF+6EE7/V5xva1za1882HVpCX\nkco9lx9LSrLV6Bljhg5LEAAVq+DRy6C1Hi57DA7/Qp8v2dmp/J8nVrO9tpnH5p9Ecc6wfgjUGGMG\njiWI3Vtg4TzIKoavvwQjp/XLZe9ZspXXNu5iwXnTOG5c39owjDEmFixBFE6COT+AmVdC9oh+ueSS\nTbv4r1c2c+HMMVx14rh+uaYxxgy0qFaKi8hcEdkkIltF5NYw+8eJyKsiskZElopIqbf9dBFZHfJo\nEZHzoxQknPrv/ZYcfFVNfPex1Rw5Kpc7LjjaBsMZY4asqCUIEUkGfgfMA6YCl4nI1B6H3QU8qKrT\ngQXAnQCqukRVZ6jqDOAMoAl4KVqx9peW9g6u/9sKVJV7r7R7OxhjhrZoliBmA1tVdZuqtgGPAef1\nOGYq8Jq3vCTMfoCLgedVtSlqkfYDVeWHz6xl/fY67r50BuMKs2IdkjHG9Ek0E8QYwBey7ve2hXof\nuNBbvgDIEZHCHsdcCjwa7glEZL6ILBeR5ZWVlf0Q8qF75L1PeWqln++cOZkzjhwZ01iMMaY/xLpj\n/s3AHBFZBcwByoGO4E4RGc5gIQ8AABfRSURBVA0cDbwY7mRVvU9VZ6nqrOLi4oGIN6xVn1bz0+fW\ncdoRxXz3zMkxi8MYY/pTNHsxlQNlIeul3rYuqlqBV4IQkWzgIlWtCTnkEuAZVW2PYpx90t7Rybcf\nXsnI3HTu/soMkpKsUdoYEx+iWYJYBkwWkQkikoarKnou9AARKRKRYAy3AQt7XOMyeqleGix8VU1U\n1LbwnTMnk5+ZFutwjDGm30QtQahqALgRVz20AXhCVdeJyAIROdc77DRgk4hsBkYCdwTPF5HxuBLI\n69GKsT/4qpsBGG+N0saYOBPVgXKquhhY3GPb7SHLi4BFvZz7Mfs2ag86virXuaqswO4rbYyJL7Fu\npB7yfNVNpCUnMTInPdahGGNMv7IE0Uf+qmbGDM+wxmljTNyxBNFH/uomSodb9ZIxJv5ElCBE5GkR\nOSekx5Hx+KqbKR2eGeswjDGm30X6gf974HJgi4j8XESOiGJMQ0Zja4CqxjZroDbGxKWIEoSqvqKq\nVwDHAh8Dr4jIWyJyrYj07Z6cQ5iv2uvBZCUIY0wcirjKyJsj6RrgG8Aq4L9xCePlqEQ2BPiq3BiI\nsgJLEMaY+BPROAgReQY4Avgb8CVV3e7telxElkcruMHO31WCsComY0z8iXSg3G9UdUm4Hao6qx/j\nGVJ8Vc1kpCZTkGVTbBhj4k+kVUxTRSQ/uCIiw0XkhijFNGT4qpsoK8iwu8YZY+JSpAniutBZVlW1\nGrguOiENHb6qJmugNsbErUgTRLKEfE32biea0PUqqoq/utkaqI0xcSvSNogXcA3Sf/TWr/e2Jaza\n5nYaWgM2itoYE7ciTRC34JLCt7z1l4H7oxLREBHs4mqjqI0x8SqiBKGqncAfvIchZJCcjaI2xsSp\nSMdBTAbuBKYCXfNaq+rEKMU16HXfB8JKEMaY+BRpI/VfcKWHAHA68CDwULSCGgp81U3kZaSSm56w\nM40YY+JcpAkiQ1VfBURVP1HVnwLnRC+swc/1YLLqJWNM/Io0QbR6U31vEZEbReQCIPtAJ4nIXBHZ\nJCJbReTWMPvHicirIrJGRJaKSGnIvrEi8pKIbBCR9d49qgcNX1UTpflWvWSMiV+RJoibgEzgO8Bx\nwJXA1fs7wRsr8TtgHq7t4jIRmdrjsLuAB1V1OrAA184R9CDwS1WdAswGdkUYa9R1j4GwEoQxJn4d\nMEF4H/RfUdUGVfWr6rWqepGqvnOAU2cDW1V1m6q2AY8B5/U4Zirwmre8JLjfSyQpqvoygPfcTZG/\nrOiqrG+lNdBpDdTGmLh2wAShqh3AKYdw7TGAL2Td720L9T5wobd8AZDjTSt+OFDj3clulYj80ktU\nexGR+SKyXESWV1ZWHkKIh8buA2GMSQSRVjGtEpHnROQqEbkw+OiH578ZmCMiq4A5QDnQget+e6q3\n/3hgIu5eFHtR1ftUdZaqziouLu6HcCLjrw7eB8KqmIwx8SvSkdTpwB7gjJBtCjy9n3PKgbKQ9VJv\nW/cFVCvwShAikg1cpKo1IuIHVqvqNm/fs8CJwJ8jjDeqgmMgxlgjtTEmjkU6kvraQ7j2MmCyiEzA\nJYZLcfe17iIiRUCVN1L7NmBhyLn5IlKsqpW4xDRobkzkq2qmKHsYGWn71HoZY0zciHQk9V9wJYa9\nqOrXejtHVQMiciPwIpAMLFTVdSKyAFiuqs8BpwF3iogCbwDf9s7tEJGbgVe9WWRXAH86qFcWRcH7\nQBhjTDyLtIrpnyHL6bgG5YoDnaSqi4HFPbbdHrK8CFjUy7kvA9MjjG9A+aqbmFk2PNZhGGNMVEVa\nxfRU6LqIPAq8GZWIBrlARyfba1o49xgrQRhj4lukvZh6mgyM6M9AhooddS0EOtWm+TbGxL1I2yDq\n2bsNYgfuHhEJJ3gfCBsDYYyJd5FWMeVEO5Chwu4DYYxJFBFVMYnIBSKSF7KeLyLnRy+swctf1USS\nQEm+JQhjTHyLtA3iJ6paG1xR1RrgJ9EJaXDzVzczOi+D1ORDbb4xxpihIdJPuXDHRdpFNq74qpsY\nM9xKD8aY+BdpglguIr8WkcO8x69xg9cSjq+q2RqojTEJIdIE8W9AG/A4btruFrxRz4mkNdDBzvoW\na6A2xiSESHsxNQL73BEu0ZRXN6NqXVyNMYkh0l5ML4tIfsj6cBF5MXphDU7d03xbgjDGxL9Iq5iK\nvJ5LAKhqNQk4kjo4BqLUGqmNMQkg0gTRKSJjgysiMp4ws7vGO19VM6nJwsjc9FiHYowxURdpV9Uf\nAm+KyOuA4O72Nj9qUQ1SvuomxuRnkJwksQ7FGGOiLtJG6hdEZBYuKawCngWaoxnYYOSvarL2B2NM\nwoh0sr5vADfhbhu6Gnf7z7fZ+xakcc9f3cznS/IOfKAxxsSBSNsgbgKOBz5R1dOBmUDN/k+JL42t\nAfY0tlkDtTEmYUSaIFpUtQVARIap6kbgiOiFNfhYF1djTKKJNEH4vXEQzwIvi8jfgU8OdJKIzBWR\nTSKyVUT2GWgnIuNE5FURWSMiS0WkNGRfh4is9h7PRfqCosVX5U3zbSUIY0yCiLSR+gJv8acisgTI\nA17Y3zkikgz8DjgL8APLROQ5VV0fcthdwIOq+oCInAHcCVzl7WtW1RmRv5To6r4PhJUgjDGJ4aBn\nZFXV1yM8dDawVVW3AYjIY8B5QGiCmAr8u7e8BFdCGZT81c1kpCZTmJUW61CMMWZARPOmBmMAX8i6\n39sW6n3gQm/5AiBHRAq99XQRWS4i7/R2cyIRme8ds7yysrI/Y9+Hr6qJ0uEZiNgYCGNMYoj1XW9u\nBuaIyCpgDlAOdHj7xqnqLOBy4G4ROaznyap6n6rOUtVZxcXFUQ3UV91s1UvGmIQSzQRRDpSFrJd6\n27qoaoWqXqiqM3GjtYN3q0NVy72f24CluK61MaGqbpCcNVAbYxJINBPEMmCyiEwQkTTgUmCv3kgi\nUiQiwRhuAxZ624eLyLDgMcBn2LvtYkDVNrdT3xqwEoQxJqFELUGoagC4EXgR2AA8oarrRGSBiJzr\nHXYasElENgMjgTu87VNwd7F7H9d4/fMevZ8GlK/KjYEotftAGGMSSFTvK62qi4HFPbbdHrK8CFgU\n5ry3gKOjGdvB8Ns038aYBBTrRuohwcZAGGMSkSWICPiqmslNTyEvIzXWoRhjzICxBBEBX7VN822M\nSTyWICLgq2qizBqojTEJxhLEAagq/upma6A2xiQcSxAHUNnQSmug06qYjDEJxxLEAQTHQJQVWAnC\nGJNYLEEcQHAMhLVBGGMSjSWIAwjeKMhGURtjEo0liAPwVzdTlJ1GRlpyrEMxxpgBZQniAHzVTVZ6\nMMYkJEsQB+CrsvtAGGMSkyWI/ejoVCpqmu0+EMaYhGQJYj+21zYT6FQrQRhjEpIliP3wVwfvA2El\nCGNM4rEEsR/BLq42BsIYk4gsQeyHr7oZESjJtxKEMSbxWILYD39VE6Nz00lLsbfJGJN4ovrJJyJz\nRWSTiGwVkVvD7B8nIq+KyBoRWSoipT3254qIX0TuiWacvfFVN1FqDdTGmAQVtQQhIsnA74B5wFTg\nMhGZ2uOwu4AHVXU6sAC4s8f+/wDeiFaMB+Kvbrb2B2NMwopmCWI2sFVVt6lqG/AYcF6PY6YCr3nL\nS0L3i8hxwEjgpSjG2KvWQAc76lqsB5MxJmFFM0GMAXwh635vW6j3gQu95QuAHBEpFJEk4FfAzft7\nAhGZLyLLRWR5ZWVlP4XtVNS0oIqNgTDGJKxYt77eDMwRkVXAHKAc6ABuABarqn9/J6vqfao6S1Vn\nFRcX92tg3V1crQRhjElMKVG8djlQFrJe6m3roqoVeCUIEckGLlLVGhE5CThVRG4AsoE0EWlQ1X0a\nuqPFF7wPhJUgjDEJKpoJYhkwWUQm4BLDpcDloQeISBFQpaqdwG3AQgBVvSLkmGuAWQOZHMA1UKcm\nCyNz0wfyaY0xZtCIWhWTqgaAG4EXgQ3AE6q6TkQWiMi53mGnAZtEZDOuQfqOaMVzsHxVTZTkZ5Cc\nJLEOxRhjYiKaJQhUdTGwuMe220OWFwGLDnCNvwJ/jUJ4++WzLq7GmAQX60bqQctf1URZgTVQG2MS\nlyWIMBpbA+xpbLM7yRljEpoliDDKa9w039aDyRiTyCxBhBEcA2GjqI0xicwSRBh2HwhjjLEEEZav\nupmM1GSKstNiHYoxxsSMJYgwfFVNlA7PQMTGQBhjEpcliDD81c3WQG2MSXiWIMLwVTdZA7UxJuFZ\nguihtqmd+paANVAbYxKeJYgeumdxtRKEMSaxWYLooXsMhJUgjDGJzRJED/5qG0VtjDFgCWIfvuom\nctJTyMtIjXUoxhgTU5YgevBVNVkDtTHGYAliH77qZmugNsYYLEHsRVXxV1sJwhhjwBLEXnY3tNHS\n3mkN1MYYQ5QThIjMFZFNIrJVRG4Ns3+ciLwqImtEZKmIlIZsXykiq0VknYh8M5pxBgXHQNgoamOM\niWKCEJFk4HfAPGAqcJmITO1x2F3Ag6o6HVgA3Olt3w6cpKozgBOAW0WkJFqxBnVN820lCGOMiWoJ\nYjawVVW3qWob8BhwXo9jpgKvectLgvtVtU1VW73tw6IcZ5fgGAgrQRhjTHQ/eMcAvpB1v7ct1PvA\nhd7yBUCOiBQCiEiZiKzxrvELVa3o+QQiMl9ElovI8srKyj4H7Ktqoig7jcy0lD5fyxhjhrpYN1Lf\nDMwRkVXAHKAc6ABQVZ9X9TQJuFpERvY8WVXvU9VZqjqruLi4z8H4q5ttig1jjPFEM0GUA2Uh66Xe\nti6qWqGqF6rqTOCH3raanscAa4FToxgrYNN8G2NMqGgmiGXAZBGZICJpwKXAc6EHiEiRiARjuA1Y\n6G0vFZEMb3k4cAqwKYqx0tGpVNTYjYKMMSYoaglCVQPAjcCLwAbgCVVdJyILRORc77DTgE0ishkY\nCdzhbZ8CvCsi7wOvA3ep6gfRihVgR10L7R1qg+SMMcYT1dZYVV0MLO6x7faQ5UXAojDnvQxMj2Zs\nPXV3cbUqJmOMgdg3Ug8aXdN8WwnCGGMASxBdfFVNiMDo/PRYh2KMMYOCJQiPr7qJUbnpDEtJjnUo\nxhgzKFiC8Pirmq16yRhjQliC8Piqmyi1BmpjjOliCQJoC3Syo67FShDGGBPCEgRQUdOMqk3SZ4wx\noSxB0H0fCBtFbYwx3SxBAL4qbwyEJQhjjOliCQJXgkhNFkbl2hgIY4wJsgSBGyRXkp9BcpLEOhRj\njBk0LEEQvA+ENVAbY0woSxCAv7rJurgaY0wPCZ8gmtoC7G5oswZqY4zpIeETRHNbB+ceU8L00rxY\nh2KMMYNKVO8HMRQUZg/jN5fNjHUYxhgz6CR8CcIYY0x4liCMMcaEFdUEISJzRWSTiGwVkVvD7B8n\nIq+KyBoRWSoipd72GSLytois8/Z9JZpxGmOM2VfUEoSIJAO/A+YBU4HLRGRqj8PuAh5U1enAAuBO\nb3sT8FVVnQbMBe4WkfxoxWqMMWZf0SxBzAa2quo2VW0DHgPO63HMVOA1b3lJcL+qblbVLd5yBbAL\nKI5irMYYY3qIZoIYA/hC1v3etlDvAxd6yxcAOSJSGHqAiMwG0oAPez6BiMwXkeUisryysrLfAjfG\nGBP7RuqbgTkisgqYA5QDHcGdIjIa+Btwrap29jxZVe9T1VmqOqu42AoYxhjTn6I5DqIcKAtZL/W2\ndfGqjy4EEJFs4CJVrfHWc4F/AT9U1XeiGKcxxpgwRFWjc2GRFGAzcCYuMSwDLlfVdSHHFAFVqtop\nIncAHap6u4ikAc8D/1DVuyN8vkrgkz6EXATs7sP50Wbx9Y3F1zcWX98M5vjGqWrYKpiolSBUNSAi\nNwIvAsnAQlVdJyILgOWq+hxwGnCniCjwBvBt7/RLgM8ChSJyjbftGlVdvZ/n61Mdk4gsV9VZfblG\nNFl8fWPx9Y3F1zeDPb7eRHWqDVVdDCzuse32kOVFwKIw5z0EPBTN2IwxxuxfrBupjTHGDFKWILrd\nF+sADsDi6xuLr28svr4Z7PGFFbVGamOMMUOblSCMMcaEZQnCGGNMWAmVICKYXXaYiDzu7X9XRMYP\nYGxlIrJERNZ7s9jeFOaY00SkVkRWe4/bw10rynF+LCIfeM+/PMx+EZHfeO/hGhE5dgBjOyLkvVkt\nInUi8t0exwzoeygiC0Vkl4isDdlWICIvi8gW7+fwXs692jtmi4hcPYDx/VJENnq/v2d6myjzQH8L\nUYzvpyJSHvI7PLuXc/f7/x7F+B4Pie1jEQnbPX8g3r8+U9WEeODGYnwITMTN7fQ+MLXHMTcA93rL\nlwKPD2B8o4FjveUc3CDDnvGdBvwzxu/jx0DRfvafjRvkKMCJwLsx/H3vwA0Citl7iBvPcyywNmTb\nfwK3esu3Ar8Ic14BsM37OdxbHj5A8X0eSPGWfxEuvkj+FqIY30+BmyP4/e/3/z1a8fXY/yvg9li9\nf319JFIJIpLZZc8DHvCWFwFniogMRHCqul1VV3rL9cAG9p3ccCg4DzeFu6qbIiXfm1NroJ0JfKiq\nfRld32eq+gZQ1WNz6N/ZA8D5YU79AvCyqlapajXwMm7q+6jHp6ovqWrAW30HN01OTPTy/kUikv/3\nPttffN5nxyXAo/39vAMlkRJEJLPLdh3j/YPUAoUMMK9qaybwbpjdJ4nI+yLyvIhMG9DAHAVeEpEV\nIjI/zP5I3ueBcCm9/2PG+j0cqarbveUdwMgwxwyW9/FruBJhOAf6W4imG70qsIW9VNENhvfvVGCn\nercuCCOW719EEilBDAniJi18Cviuqtb12L0SV2VyDPBb4NmBjg84RVWPxd0I6tsi8tkYxLBf3lxe\n5wJPhtk9GN7DLurqGgZlX3MR+SEQAB7u5ZBY/S38ATgMmAFsx1XjDEaXsf/Sw6D/X0qkBHHA2WVD\njxE32WAesGdAonPPmYpLDg+r6tM996tqnao2eMuLgVRxEx4OGFUt937uAp7BFeVDRfI+R9s8YKWq\n7uy5YzC8h8DOYLWb93NXmGNi+j6KmwPti8AVXhLbRwR/C1GhqjtVtUPdLQD+1Mvzxvr9S8HNVP14\nb8fE6v07GImUIJYBk0VkgvcN81LguR7HPAcEe4tcDLzW2z9Hf/PqK/8MbFDVX/dyzKhgm4i4Gykl\nMbAJLEtEcoLLuMbMtT0Oew74qteb6USgNqQ6ZaD0+s0t1u+hJ/Tv7Grg72GOeRH4vIgM96pQPu9t\nizoRmQv8ADhXVZt6OSaSv4VoxRfapnVBL88byf97NH0O2Kiq/nA7Y/n+HZRYt5IP5APXw2YzrnfD\nD71tC3D/CADpuGqJrcB7wMQBjO0UXFXDGmC19zgb+CbwTe+YG4F1uB4Z7wAnD/D7N9F77ve9OILv\nYWiMgrsX+YfAB8CsAY4xC/eBnxeyLWbvIS5RbQfacfXgX8e1a70KbAFeAQq8Y2cB94ec+zXvb3Er\n7qZZAxXfVlz9ffDvMNizrwRYvL+/hQGK72/e39Ya3If+6J7xeev7/L8PRHze9r8G/+ZCjh3w96+v\nD5tqwxhjTFiJVMVkjDHmIFiCMMYYE5YlCGOMMWFZgjDGGBOWJQhjjDFhWYIwZhDwZpn9Z6zjMCaU\nJQhjjDFhWYIw5iCIyJUi8p43h/8fRSRZRBpE5L/E3cfjVREp9o6dISLvhNxXYbi3fZKIvOJNGLhS\nRA7zLp8tIou8ezE8PFAzCRvTG0sQxkRIRKYAXwE+o6ozgA7gCtzo7eWqOg14HfiJd8qDwC2qOh03\n8je4/WHgd+omDDwZNxIX3Ay+3wWm4kbafibqL8qY/UiJdQDGDCFnAscBy7wv9xm4ifY66Z6U7SHg\naRHJA/JV9XVv+wPAk978O2NU9RkAVW0B8K73nnpz93h3IRsPvBn9l2VMeJYgjImcAA+o6m17bRT5\ncY/jDnX+mtaQ5Q7s/9PEmFUxGRO5V4GLRWQEdN1behzu/+hi75jLgTdVtRaoFpFTve1XAa+ru1ug\nX0TO964xTEQyB/RVGBMh+4ZiTIRUdb2I/Ah3F7Ak3Aye3wYagdnevl24dgpwU3nf6yWAbcC13var\ngD+KyALvGl8ewJdhTMRsNldj+khEGlQ1O9ZxGNPfrIrJGGNMWFaCMMYYE5aVIIwxxoRlCcIYY0xY\nliCMMcaEZQnCGGNMWJYgjDHGhPX/A4Vo0Yg5fRggAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYEOnl4_M5mD",
        "colab_type": "text"
      },
      "source": [
        "###【Try 01】load_mnistのone_hot_labelをFalseに変更しよう (error)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npwtBfhwH0gz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "outputId": "eacbb9e1-1923-4632-ff13-70e9dd5923a6"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from data.mnist import load_mnist\n",
        "\n",
        "(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=False)\n",
        "\n",
        "# 必要なライブラリのインポート、最適化手法はAdamを使う\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# モデル作成\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "# バッチサイズ、エポック数\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, d_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, d_test))\n",
        "loss = model.evaluate(x_test, d_test, verbose=0)\n",
        "print('Test loss:', loss[0])\n",
        "print('Test accuracy:', loss[1])\n",
        "#Accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.ylim(0, 1.0)\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b1b925bad9f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_23 to have shape (10,) but got array with shape (1,)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU_91x8eM-VG",
        "colab_type": "text"
      },
      "source": [
        "###【Try 02】誤差関数をsparse_categorical_crossentropyに変更しよう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omvv-FieH6j1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c56765b2-3252-4211-9b9f-d05508b3700b"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from data.mnist import load_mnist\n",
        "\n",
        "(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=False)\n",
        "\n",
        "# 必要なライブラリのインポート、最適化手法はAdamを使う\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# モデル作成\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "# バッチサイズ、エポック数\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, d_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, d_test))\n",
        "loss = model.evaluate(x_test, d_test, verbose=0)\n",
        "print('Test loss:', loss[0])\n",
        "print('Test accuracy:', loss[1])\n",
        "#Accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.ylim(0, 1.0)\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_27 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.2530 - acc: 0.9245 - val_loss: 0.1058 - val_acc: 0.9660\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1003 - acc: 0.9691 - val_loss: 0.0817 - val_acc: 0.9739\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0726 - acc: 0.9773 - val_loss: 0.0696 - val_acc: 0.9774\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0567 - acc: 0.9820 - val_loss: 0.0642 - val_acc: 0.9789\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0459 - acc: 0.9851 - val_loss: 0.0728 - val_acc: 0.9773\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0385 - acc: 0.9871 - val_loss: 0.0649 - val_acc: 0.9808\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0313 - acc: 0.9896 - val_loss: 0.0672 - val_acc: 0.9799\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0312 - acc: 0.9899 - val_loss: 0.0641 - val_acc: 0.9831\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0253 - acc: 0.9916 - val_loss: 0.0681 - val_acc: 0.9810\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0258 - acc: 0.9915 - val_loss: 0.0728 - val_acc: 0.9812\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0231 - acc: 0.9921 - val_loss: 0.0698 - val_acc: 0.9840\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0210 - acc: 0.9929 - val_loss: 0.0821 - val_acc: 0.9810\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0222 - acc: 0.9925 - val_loss: 0.0837 - val_acc: 0.9805\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0194 - acc: 0.9933 - val_loss: 0.0806 - val_acc: 0.9827\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0166 - acc: 0.9944 - val_loss: 0.0698 - val_acc: 0.9845\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0180 - acc: 0.9940 - val_loss: 0.0843 - val_acc: 0.9804\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0161 - acc: 0.9947 - val_loss: 0.0785 - val_acc: 0.9825\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0161 - acc: 0.9947 - val_loss: 0.0733 - val_acc: 0.9827\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0166 - acc: 0.9943 - val_loss: 0.0777 - val_acc: 0.9822\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 32us/step - loss: 0.0152 - acc: 0.9949 - val_loss: 0.0736 - val_acc: 0.9831\n",
            "Test loss: 0.07355222748909473\n",
            "Test accuracy: 0.9831\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhGQJwhhjTEj/HxOJ+WbYCHHZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-yOkb_eNdkM",
        "colab_type": "text"
      },
      "source": [
        "###【Try 03】Adamの引数の値を変更しよう"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX_15OagInVN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d31c930-04f4-4e8e-ac33-f4530dd09a29"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from data.mnist import load_mnist\n",
        "\n",
        "(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=False)\n",
        "\n",
        "# 必要なライブラリのインポート、最適化手法はAdamを使う\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# モデル作成\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "# バッチサイズ、エポック数\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer=Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, d_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, d_test))\n",
        "loss = model.evaluate(x_test, d_test, verbose=0)\n",
        "print('Test loss:', loss[0])\n",
        "print('Test accuracy:', loss[1])\n",
        "#Accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.ylim(0, 1.0)\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_42 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.6145 - acc: 0.8361 - val_loss: 0.2482 - val_acc: 0.9296\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.2513 - acc: 0.9274 - val_loss: 0.1827 - val_acc: 0.9444\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.1920 - acc: 0.9454 - val_loss: 0.1482 - val_acc: 0.9555\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.1551 - acc: 0.9552 - val_loss: 0.1240 - val_acc: 0.9631\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.1305 - acc: 0.9616 - val_loss: 0.1098 - val_acc: 0.9666\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.1121 - acc: 0.9671 - val_loss: 0.0996 - val_acc: 0.9692\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0973 - acc: 0.9709 - val_loss: 0.0890 - val_acc: 0.9726\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0868 - acc: 0.9740 - val_loss: 0.0805 - val_acc: 0.9742\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0771 - acc: 0.9769 - val_loss: 0.0764 - val_acc: 0.9760\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0685 - acc: 0.9792 - val_loss: 0.0718 - val_acc: 0.9768\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0613 - acc: 0.9813 - val_loss: 0.0695 - val_acc: 0.9781\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 2s 35us/step - loss: 0.0560 - acc: 0.9834 - val_loss: 0.0673 - val_acc: 0.9783\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0519 - acc: 0.9841 - val_loss: 0.0641 - val_acc: 0.9800\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0470 - acc: 0.9861 - val_loss: 0.0608 - val_acc: 0.9811\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0417 - acc: 0.9876 - val_loss: 0.0608 - val_acc: 0.9809\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0380 - acc: 0.9891 - val_loss: 0.0594 - val_acc: 0.9815\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0345 - acc: 0.9896 - val_loss: 0.0613 - val_acc: 0.9803\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0316 - acc: 0.9903 - val_loss: 0.0574 - val_acc: 0.9802\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 2s 34us/step - loss: 0.0288 - acc: 0.9916 - val_loss: 0.0567 - val_acc: 0.9823\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 2s 33us/step - loss: 0.0266 - acc: 0.9920 - val_loss: 0.0592 - val_acc: 0.9811\n",
            "Test loss: 0.0591983361560211\n",
            "Test accuracy: 0.9811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxKej7Sp2xeX",
        "colab_type": "text"
      },
      "source": [
        "## CNN分類 (mnist)\n",
        "#### 実行に時間がかかるため割愛"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56hURFjr2xeY",
        "colab_type": "code",
        "outputId": "2b1573da-44a7-43a6-b39a-f278c3aa4ae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from data.mnist import load_mnist\n",
        "\n",
        "(x_train, d_train), (x_test, d_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "\n",
        "# 行列として入力するための加工\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "\n",
        "# 必要なライブラリのインポート、最適化手法はAdamを使う\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "# バッチサイズ、エポック数\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "history = model.fit(x_train, d_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, d_test))\n",
        "\n",
        "#Accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.ylim(0, 1.0)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.2443 - acc: 0.9260 - val_loss: 0.0563 - val_acc: 0.9809\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0898 - acc: 0.9731 - val_loss: 0.0409 - val_acc: 0.9868\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0659 - acc: 0.9798 - val_loss: 0.0312 - val_acc: 0.9900\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0533 - acc: 0.9836 - val_loss: 0.0314 - val_acc: 0.9898\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0453 - acc: 0.9856 - val_loss: 0.0281 - val_acc: 0.9917\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0388 - acc: 0.9876 - val_loss: 0.0294 - val_acc: 0.9915\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0358 - acc: 0.9887 - val_loss: 0.0282 - val_acc: 0.9912\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0304 - acc: 0.9903 - val_loss: 0.0250 - val_acc: 0.9923\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0284 - acc: 0.9909 - val_loss: 0.0282 - val_acc: 0.9923\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0265 - acc: 0.9910 - val_loss: 0.0303 - val_acc: 0.9908\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0242 - acc: 0.9918 - val_loss: 0.0334 - val_acc: 0.9913\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0232 - acc: 0.9923 - val_loss: 0.0311 - val_acc: 0.9906\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0201 - acc: 0.9932 - val_loss: 0.0353 - val_acc: 0.9909\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0195 - acc: 0.9935 - val_loss: 0.0307 - val_acc: 0.9916\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0179 - acc: 0.9938 - val_loss: 0.0298 - val_acc: 0.9917\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0165 - acc: 0.9943 - val_loss: 0.0295 - val_acc: 0.9917\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0169 - acc: 0.9942 - val_loss: 0.0320 - val_acc: 0.9919\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0154 - acc: 0.9949 - val_loss: 0.0315 - val_acc: 0.9926\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0140 - acc: 0.9951 - val_loss: 0.0310 - val_acc: 0.9922\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0136 - acc: 0.9957 - val_loss: 0.0325 - val_acc: 0.9926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXySpACy2xea",
        "colab_type": "text"
      },
      "source": [
        "## cifar10\n",
        "#### 実行に時間がかかるため割愛\n",
        "データセット cifar10<br>\n",
        "32x32ピクセルのカラー画像データ<br>\n",
        "10種のラベル「飛行機、自動車、鳥、猫、鹿、犬、蛙、馬、船、トラック」<br>\n",
        "トレーニングデータ数:50000, テストデータ数:10000<br>\n",
        "http://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QpyfW9i2xeb",
        "colab_type": "code",
        "outputId": "61c0e538-c5a4-4c0e-e0f1-093ed894895e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "#CIFAR-10のデータセットのインポート\n",
        "from keras.datasets import cifar10\n",
        "(x_train, d_train), (x_test, d_test) = cifar10.load_data()\n",
        "\n",
        "#CIFAR-10の正規化\n",
        "from keras.utils import to_categorical\n",
        "  \n",
        "# 特徴量の正規化\n",
        "x_train = x_train/255.\n",
        "x_test = x_test/255.\n",
        " \n",
        "# クラスラベルの1-hotベクトル化\n",
        "d_train = to_categorical(d_train, 10)\n",
        "d_test = to_categorical(d_test, 10)\n",
        " \n",
        "# CNNの構築\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "import numpy as np\n",
        " \n",
        "model = Sequential()\n",
        " \n",
        "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        " \n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        " \n",
        "# コンパイル\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        " \n",
        "#訓練\n",
        "history = model.fit(x_train, d_train, epochs=20)\n",
        " \n",
        "# モデルの保存\n",
        "model.save('./CIFAR-10.h5')\n",
        " \n",
        "#評価 & 評価結果出力\n",
        "print(model.evaluate(x_test, d_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 12s 237us/step - loss: 1.5572 - acc: 0.4285\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 1.1500 - acc: 0.5922\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 1.0026 - acc: 0.6472\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.9168 - acc: 0.6782\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 11s 229us/step - loss: 0.8440 - acc: 0.7052\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 12s 232us/step - loss: 0.8023 - acc: 0.7189\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.7572 - acc: 0.7353\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 0.7309 - acc: 0.7418\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 0.7024 - acc: 0.7525\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.6815 - acc: 0.7592\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.6598 - acc: 0.7675\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 0.6403 - acc: 0.7754\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.6279 - acc: 0.7790\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 11s 226us/step - loss: 0.6063 - acc: 0.7859\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 11s 224us/step - loss: 0.5966 - acc: 0.7906\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 11s 225us/step - loss: 0.5807 - acc: 0.7941\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.5730 - acc: 0.7999\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 11s 228us/step - loss: 0.5566 - acc: 0.8030\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 0.5499 - acc: 0.8061\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 12s 231us/step - loss: 0.5443 - acc: 0.8089\n",
            "10000/10000 [==============================] - 1s 100us/step\n",
            "[0.6582889246463776, 0.7836]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsTzy5dQ2xee",
        "colab_type": "text"
      },
      "source": [
        "## RNN\n",
        "\n",
        "2進数足し算の予測\n",
        "\n",
        "Keras RNNのドキュメント\n",
        "https://keras.io/ja/layers/recurrent/#simplernn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBLhVkny2xef",
        "colab_type": "text"
      },
      "source": [
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "### [try]\n",
        "-  RNNの出力ノード数を128に変更\n",
        "-  RNNの出力活性化関数を sigmoid に変更\n",
        "-  RNNの出力活性化関数を tanh に変更\n",
        "-  最適化方法をadamに変更\n",
        "-  RNNの入力 Dropout を0.5に設定\n",
        "-  RNNの再帰 Dropout を0.3に設定\n",
        "-  RNNのunrollをTrueに設定\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouD9196W2xeh",
        "colab_type": "code",
        "outputId": "266de3a4-9242-45a6-bb06-b44999195382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout,Activation\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)], dtype=np.uint8).T,axis=1)[:, ::-1]\n",
        "\n",
        "\n",
        "# A, B初期化 (a + b = d)\n",
        "a_int = np.random.randint(largest_number/2, size=20000)\n",
        "a_bin = binary[a_int] # binary encoding\n",
        "b_int = np.random.randint(largest_number/2, size=20000)\n",
        "b_bin = binary[b_int] # binary encoding\n",
        "\n",
        "x_int = []\n",
        "x_bin = []\n",
        "for i in range(10000):\n",
        "    x_int.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int_test = []\n",
        "x_bin_test = []\n",
        "for i in range(10001, 20000):\n",
        "    x_int_test.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin_test.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int = np.array(x_int)\n",
        "x_bin = np.array(x_bin)\n",
        "x_int_test = np.array(x_int_test)\n",
        "x_bin_test = np.array(x_bin_test)\n",
        "\n",
        "\n",
        "# 正解データ\n",
        "d_int = a_int + b_int\n",
        "d_bin = binary[d_int][0:10000]\n",
        "d_bin_test = binary[d_int][10001:20000]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(units=16,\n",
        "               return_sequences=True,\n",
        "               input_shape=[8, 2],\n",
        "               go_backwards=False,\n",
        "               activation='relu',\n",
        "               # dropout=0.5,\n",
        "               # recurrent_dropout=0.3,\n",
        "               # unroll = True,\n",
        "            ))\n",
        "# 出力層\n",
        "model.add(Dense(1, activation='sigmoid', input_shape=(-1,2)))\n",
        "model.summary()\n",
        "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
        "# model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_bin, d_bin.reshape(-1, 8, 1), epochs=5, batch_size=2)\n",
        "\n",
        "# テスト結果出力\n",
        "score = model.evaluate(x_bin_test, d_bin_test.reshape(-1,8,1), verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_1 (SimpleRNN)     (None, 8, 16)             304       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 8, 1)              17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 37s 4ms/step - loss: 0.0825 - acc: 0.9092\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.0026 - acc: 1.0000\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 7.7327e-04 - acc: 1.0000\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 4.3752e-04 - acc: 1.0000\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 3.0088e-04 - acc: 1.0000\n",
            "Test loss: 0.00025880338073897566\n",
            "Test accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjL1OBwOlQbS",
        "colab_type": "text"
      },
      "source": [
        "### 【Try 01】] RNNの出力ノード数を128に変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLkbo6kAljSb",
        "colab_type": "code",
        "outputId": "92f73a94-e316-4427-ecd3-4df262978d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout,Activation\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)], dtype=np.uint8).T,axis=1)[:, ::-1]\n",
        "\n",
        "\n",
        "# A, B初期化 (a + b = d)\n",
        "a_int = np.random.randint(largest_number/2, size=20000)\n",
        "a_bin = binary[a_int] # binary encoding\n",
        "b_int = np.random.randint(largest_number/2, size=20000)\n",
        "b_bin = binary[b_int] # binary encoding\n",
        "\n",
        "x_int = []\n",
        "x_bin = []\n",
        "for i in range(10000):\n",
        "    x_int.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int_test = []\n",
        "x_bin_test = []\n",
        "for i in range(10001, 20000):\n",
        "    x_int_test.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin_test.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int = np.array(x_int)\n",
        "x_bin = np.array(x_bin)\n",
        "x_int_test = np.array(x_int_test)\n",
        "x_bin_test = np.array(x_bin_test)\n",
        "\n",
        "\n",
        "# 正解データ\n",
        "d_int = a_int + b_int\n",
        "d_bin = binary[d_int][0:10000]\n",
        "d_bin_test = binary[d_int][10001:20000]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(units=128,\n",
        "               return_sequences=True,\n",
        "               input_shape=[8, 2],\n",
        "               go_backwards=False,\n",
        "               activation='relu',\n",
        "               # dropout=0.5,\n",
        "               # recurrent_dropout=0.3,\n",
        "               # unroll = True,\n",
        "            ))\n",
        "# 出力層\n",
        "model.add(Dense(1, activation='sigmoid', input_shape=(-1,2)))\n",
        "model.summary()\n",
        "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
        "# model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_bin, d_bin.reshape(-1, 8, 1), epochs=5, batch_size=2)\n",
        "\n",
        "# テスト結果出力\n",
        "score = model.evaluate(x_bin_test, d_bin_test.reshape(-1,8,1), verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_2 (SimpleRNN)     (None, 8, 128)            16768     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 8, 1)              129       \n",
            "=================================================================\n",
            "Total params: 16,897\n",
            "Trainable params: 16,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 35s 4ms/step - loss: 0.0694 - acc: 0.9258\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 35s 4ms/step - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 6.5622e-04 - acc: 1.0000\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 35s 4ms/step - loss: 3.8880e-04 - acc: 1.0000\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 35s 3ms/step - loss: 2.7118e-04 - acc: 1.0000\n",
            "Test loss: 0.00023415865437302524\n",
            "Test accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qltwGiUTqGOR",
        "colab_type": "text"
      },
      "source": [
        "###【Try 02】RNNの出力活性化関数を sigmoid に変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwcyDUY7qQyW",
        "colab_type": "code",
        "outputId": "32cf8aba-27da-4ac0-90bf-1c52549f1997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout,Activation\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)], dtype=np.uint8).T,axis=1)[:, ::-1]\n",
        "\n",
        "\n",
        "# A, B初期化 (a + b = d)\n",
        "a_int = np.random.randint(largest_number/2, size=20000)\n",
        "a_bin = binary[a_int] # binary encoding\n",
        "b_int = np.random.randint(largest_number/2, size=20000)\n",
        "b_bin = binary[b_int] # binary encoding\n",
        "\n",
        "x_int = []\n",
        "x_bin = []\n",
        "for i in range(10000):\n",
        "    x_int.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int_test = []\n",
        "x_bin_test = []\n",
        "for i in range(10001, 20000):\n",
        "    x_int_test.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin_test.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int = np.array(x_int)\n",
        "x_bin = np.array(x_bin)\n",
        "x_int_test = np.array(x_int_test)\n",
        "x_bin_test = np.array(x_bin_test)\n",
        "\n",
        "\n",
        "# 正解データ\n",
        "d_int = a_int + b_int\n",
        "d_bin = binary[d_int][0:10000]\n",
        "d_bin_test = binary[d_int][10001:20000]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(units=16,\n",
        "               return_sequences=True,\n",
        "               input_shape=[8, 2],\n",
        "               go_backwards=False,\n",
        "               activation='sigmoid',\n",
        "               # dropout=0.5,\n",
        "               # recurrent_dropout=0.3,\n",
        "               # unroll = True,\n",
        "            ))\n",
        "# 出力層\n",
        "model.add(Dense(1, activation='sigmoid', input_shape=(-1,2)))\n",
        "model.summary()\n",
        "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
        "# model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_bin, d_bin.reshape(-1, 8, 1), epochs=5, batch_size=2)\n",
        "\n",
        "# テスト結果出力\n",
        "score = model.evaluate(x_bin_test, d_bin_test.reshape(-1,8,1), verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_10 (SimpleRNN)    (None, 8, 16)             304       \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 8, 1)              17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 38s 4ms/step - loss: 0.2497 - acc: 0.5160\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 37s 4ms/step - loss: 0.2474 - acc: 0.5542\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 37s 4ms/step - loss: 0.2399 - acc: 0.6316\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 37s 4ms/step - loss: 0.2077 - acc: 0.7247\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 37s 4ms/step - loss: 0.1325 - acc: 0.8410\n",
            "Test loss: 0.08293569208321089\n",
            "Test accuracy: 0.8922517252023225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F8yqWw_qRQp",
        "colab_type": "text"
      },
      "source": [
        "###【Try 03】RNNの出力活性化関数を tanh に変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvrDxfTzqTrP",
        "colab_type": "code",
        "outputId": "af47cc35-99da-4726-a85a-7eaf5bfab7e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout,Activation\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)], dtype=np.uint8).T,axis=1)[:, ::-1]\n",
        "\n",
        "\n",
        "# A, B初期化 (a + b = d)\n",
        "a_int = np.random.randint(largest_number/2, size=20000)\n",
        "a_bin = binary[a_int] # binary encoding\n",
        "b_int = np.random.randint(largest_number/2, size=20000)\n",
        "b_bin = binary[b_int] # binary encoding\n",
        "\n",
        "x_int = []\n",
        "x_bin = []\n",
        "for i in range(10000):\n",
        "    x_int.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int_test = []\n",
        "x_bin_test = []\n",
        "for i in range(10001, 20000):\n",
        "    x_int_test.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin_test.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int = np.array(x_int)\n",
        "x_bin = np.array(x_bin)\n",
        "x_int_test = np.array(x_int_test)\n",
        "x_bin_test = np.array(x_bin_test)\n",
        "\n",
        "\n",
        "# 正解データ\n",
        "d_int = a_int + b_int\n",
        "d_bin = binary[d_int][0:10000]\n",
        "d_bin_test = binary[d_int][10001:20000]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(units=16,\n",
        "               return_sequences=True,\n",
        "               input_shape=[8, 2],\n",
        "               go_backwards=False,\n",
        "               activation='tanh',\n",
        "               # dropout=0.5,\n",
        "               # recurrent_dropout=0.3,\n",
        "               # unroll = True,\n",
        "            ))\n",
        "# 出力層\n",
        "model.add(Dense(1, activation='sigmoid', input_shape=(-1,2)))\n",
        "model.summary()\n",
        "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
        "# model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_bin, d_bin.reshape(-1, 8, 1), epochs=5, batch_size=2)\n",
        "\n",
        "# テスト結果出力\n",
        "score = model.evaluate(x_bin_test, d_bin_test.reshape(-1,8,1), verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_4 (SimpleRNN)     (None, 8, 16)             304       \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 8, 1)              17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 40s 4ms/step - loss: 0.1097 - acc: 0.8375\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 41s 4ms/step - loss: 0.0016 - acc: 1.0000\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 40s 4ms/step - loss: 5.6286e-04 - acc: 1.0000\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 3.2989e-04 - acc: 1.0000\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 2.3008e-04 - acc: 1.0000\n",
            "Test loss: 0.0001967194647945645\n",
            "Test accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82cywIyOuTM6",
        "colab_type": "text"
      },
      "source": [
        "###【Try 04】最適化方法をadamに変更"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4XgGaZ4uYWP",
        "colab_type": "code",
        "outputId": "2c7cbfc8-37f1-4f58-b1a3-261010667f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout,Activation\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)], dtype=np.uint8).T,axis=1)[:, ::-1]\n",
        "\n",
        "\n",
        "# A, B初期化 (a + b = d)\n",
        "a_int = np.random.randint(largest_number/2, size=20000)\n",
        "a_bin = binary[a_int] # binary encoding\n",
        "b_int = np.random.randint(largest_number/2, size=20000)\n",
        "b_bin = binary[b_int] # binary encoding\n",
        "\n",
        "x_int = []\n",
        "x_bin = []\n",
        "for i in range(10000):\n",
        "    x_int.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int_test = []\n",
        "x_bin_test = []\n",
        "for i in range(10001, 20000):\n",
        "    x_int_test.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin_test.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int = np.array(x_int)\n",
        "x_bin = np.array(x_bin)\n",
        "x_int_test = np.array(x_int_test)\n",
        "x_bin_test = np.array(x_bin_test)\n",
        "\n",
        "\n",
        "# 正解データ\n",
        "d_int = a_int + b_int\n",
        "d_bin = binary[d_int][0:10000]\n",
        "d_bin_test = binary[d_int][10001:20000]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(units=16,\n",
        "               return_sequences=True,\n",
        "               input_shape=[8, 2],\n",
        "               go_backwards=False,\n",
        "               activation='relu',\n",
        "               # dropout=0.5,\n",
        "               # recurrent_dropout=0.3,\n",
        "               # unroll = True,\n",
        "            ))\n",
        "# 出力層\n",
        "model.add(Dense(1, activation='sigmoid', input_shape=(-1,2)))\n",
        "model.summary()\n",
        "#model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_bin, d_bin.reshape(-1, 8, 1), epochs=5, batch_size=2)\n",
        "\n",
        "# テスト結果出力\n",
        "score = model.evaluate(x_bin_test, d_bin_test.reshape(-1,8,1), verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_5 (SimpleRNN)     (None, 8, 16)             304       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 8, 1)              17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 39s 4ms/step - loss: 0.0897 - acc: 0.8976\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 38s 4ms/step - loss: 0.0018 - acc: 1.0000\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 39s 4ms/step - loss: 7.2939e-05 - acc: 1.0000\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 38s 4ms/step - loss: 4.5151e-06 - acc: 1.0000\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 38s 4ms/step - loss: 3.1585e-07 - acc: 1.0000\n",
            "Test loss: 6.801103505811634e-08\n",
            "Test accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lh7A0EFule9",
        "colab_type": "text"
      },
      "source": [
        "###【Try 05】RNNの入力 Dropout を0.5に設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol-hy-Qpuqdj",
        "colab_type": "code",
        "outputId": "a119f907-5820-44a1-93e7-b47583524092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout,Activation\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)], dtype=np.uint8).T,axis=1)[:, ::-1]\n",
        "\n",
        "\n",
        "# A, B初期化 (a + b = d)\n",
        "a_int = np.random.randint(largest_number/2, size=20000)\n",
        "a_bin = binary[a_int] # binary encoding\n",
        "b_int = np.random.randint(largest_number/2, size=20000)\n",
        "b_bin = binary[b_int] # binary encoding\n",
        "\n",
        "x_int = []\n",
        "x_bin = []\n",
        "for i in range(10000):\n",
        "    x_int.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int_test = []\n",
        "x_bin_test = []\n",
        "for i in range(10001, 20000):\n",
        "    x_int_test.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin_test.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int = np.array(x_int)\n",
        "x_bin = np.array(x_bin)\n",
        "x_int_test = np.array(x_int_test)\n",
        "x_bin_test = np.array(x_bin_test)\n",
        "\n",
        "\n",
        "# 正解データ\n",
        "d_int = a_int + b_int\n",
        "d_bin = binary[d_int][0:10000]\n",
        "d_bin_test = binary[d_int][10001:20000]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(units=16,\n",
        "               return_sequences=True,\n",
        "               input_shape=[8, 2],\n",
        "               go_backwards=False,\n",
        "               activation='relu',\n",
        "               dropout=0.5,\n",
        "               # recurrent_dropout=0.3,\n",
        "               # unroll = True,\n",
        "            ))\n",
        "# 出力層\n",
        "model.add(Dense(1, activation='sigmoid', input_shape=(-1,2)))\n",
        "model.summary()\n",
        "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
        "# model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_bin, d_bin.reshape(-1, 8, 1), epochs=5, batch_size=2)\n",
        "\n",
        "# テスト結果出力\n",
        "score = model.evaluate(x_bin_test, d_bin_test.reshape(-1,8,1), verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_6 (SimpleRNN)     (None, 8, 16)             304       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 8, 1)              17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.2352 - acc: 0.5796\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.2157 - acc: 0.6247\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.2098 - acc: 0.6300\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 35s 4ms/step - loss: 0.2080 - acc: 0.6280\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.2056 - acc: 0.6297\n",
            "Test loss: 0.20965691135250122\n",
            "Test accuracy: 0.6604160416041605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I57Zsjyu1en",
        "colab_type": "text"
      },
      "source": [
        "###【Try 06】RNNの再帰 Dropout を0.3に設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3qWC1JOvCxT",
        "colab_type": "code",
        "outputId": "b5a571b9-020d-4346-93bd-6774e0634f35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout,Activation\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)], dtype=np.uint8).T,axis=1)[:, ::-1]\n",
        "\n",
        "\n",
        "# A, B初期化 (a + b = d)\n",
        "a_int = np.random.randint(largest_number/2, size=20000)\n",
        "a_bin = binary[a_int] # binary encoding\n",
        "b_int = np.random.randint(largest_number/2, size=20000)\n",
        "b_bin = binary[b_int] # binary encoding\n",
        "\n",
        "x_int = []\n",
        "x_bin = []\n",
        "for i in range(10000):\n",
        "    x_int.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int_test = []\n",
        "x_bin_test = []\n",
        "for i in range(10001, 20000):\n",
        "    x_int_test.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin_test.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int = np.array(x_int)\n",
        "x_bin = np.array(x_bin)\n",
        "x_int_test = np.array(x_int_test)\n",
        "x_bin_test = np.array(x_bin_test)\n",
        "\n",
        "\n",
        "# 正解データ\n",
        "d_int = a_int + b_int\n",
        "d_bin = binary[d_int][0:10000]\n",
        "d_bin_test = binary[d_int][10001:20000]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(units=16,\n",
        "               return_sequences=True,\n",
        "               input_shape=[8, 2],\n",
        "               go_backwards=False,\n",
        "               activation='relu',\n",
        "               #dropout=0.5,\n",
        "               recurrent_dropout=0.3,\n",
        "               # unroll = True,\n",
        "            ))\n",
        "# 出力層\n",
        "model.add(Dense(1, activation='sigmoid', input_shape=(-1,2)))\n",
        "model.summary()\n",
        "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
        "# model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_bin, d_bin.reshape(-1, 8, 1), epochs=5, batch_size=2)\n",
        "\n",
        "# テスト結果出力\n",
        "score = model.evaluate(x_bin_test, d_bin_test.reshape(-1,8,1), verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_8 (SimpleRNN)     (None, 8, 16)             304       \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 8, 1)              17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 37s 4ms/step - loss: 0.1381 - acc: 0.8138\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.0317 - acc: 0.9781\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.0129 - acc: 0.9896\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.0111 - acc: 0.9891\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.0082 - acc: 0.9915\n",
            "Test loss: 0.016133127088035114\n",
            "Test accuracy: 0.9786853684951262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68wtDX1pvEiq",
        "colab_type": "text"
      },
      "source": [
        "###【Try 07】RNNのunrollをTrueに設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEueWcZHvLNr",
        "colab_type": "code",
        "outputId": "ee0f8b8d-5f69-4bf9-af6d-d9ee23bffa92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# logging levelを変更\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout,Activation\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
        "\n",
        "\n",
        "# データを用意\n",
        "# 2進数の桁数\n",
        "binary_dim = 8\n",
        "# 最大値 + 1\n",
        "largest_number = pow(2, binary_dim)\n",
        "\n",
        "# largest_numberまで2進数を用意\n",
        "binary = np.unpackbits(np.array([range(largest_number)], dtype=np.uint8).T,axis=1)[:, ::-1]\n",
        "\n",
        "\n",
        "# A, B初期化 (a + b = d)\n",
        "a_int = np.random.randint(largest_number/2, size=20000)\n",
        "a_bin = binary[a_int] # binary encoding\n",
        "b_int = np.random.randint(largest_number/2, size=20000)\n",
        "b_bin = binary[b_int] # binary encoding\n",
        "\n",
        "x_int = []\n",
        "x_bin = []\n",
        "for i in range(10000):\n",
        "    x_int.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int_test = []\n",
        "x_bin_test = []\n",
        "for i in range(10001, 20000):\n",
        "    x_int_test.append(np.array([a_int[i], b_int[i]]).T)\n",
        "    x_bin_test.append(np.array([a_bin[i], b_bin[i]]).T)\n",
        "\n",
        "x_int = np.array(x_int)\n",
        "x_bin = np.array(x_bin)\n",
        "x_int_test = np.array(x_int_test)\n",
        "x_bin_test = np.array(x_bin_test)\n",
        "\n",
        "\n",
        "# 正解データ\n",
        "d_int = a_int + b_int\n",
        "d_bin = binary[d_int][0:10000]\n",
        "d_bin_test = binary[d_int][10001:20000]\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(SimpleRNN(units=16,\n",
        "               return_sequences=True,\n",
        "               input_shape=[8, 2],\n",
        "               go_backwards=False,\n",
        "               activation='relu',\n",
        "               # dropout=0.5,\n",
        "               # recurrent_dropout=0.3,\n",
        "               unroll = True,\n",
        "            ))\n",
        "# 出力層\n",
        "model.add(Dense(1, activation='sigmoid', input_shape=(-1,2)))\n",
        "model.summary()\n",
        "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
        "# model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_bin, d_bin.reshape(-1, 8, 1), epochs=5, batch_size=2)\n",
        "\n",
        "# テスト結果出力\n",
        "score = model.evaluate(x_bin_test, d_bin_test.reshape(-1,8,1), verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_9 (SimpleRNN)     (None, 8, 16)             304       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 8, 1)              17        \n",
            "=================================================================\n",
            "Total params: 321\n",
            "Trainable params: 321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 18s 2ms/step - loss: 0.0868 - acc: 0.8979\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0022 - acc: 1.0000\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 7.2120e-04 - acc: 1.0000\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 4.1976e-04 - acc: 1.0000\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 17s 2ms/step - loss: 2.9092e-04 - acc: 1.0000\n",
            "Test loss: 0.00025165670896437533\n",
            "Test accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}